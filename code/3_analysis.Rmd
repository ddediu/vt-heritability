---
title: "The heritability of vocal tract structures estimated from structural MRI in a large cohort of Dutch twins"
subtitle: "Full analysis report"
author: "Dan Dediu [ddediu@gmail.com] and Emily Jennings (with input from Conor Dolan)"
date: "`r Sys.time()`"
output: 
  html_document: 
    toc: yes
    toc_depth: 6
    toc_float: yes
    highlight: textmate
    theme: readable
    df_print: kable
editor_options: 
  chunk_output_type: console
---

```{r eval=FALSE, include=FALSE}

# Analyse and plot the VT ph_ace estimates
#
# Copyright (C) 2019-2020, Emily Jennings
# checked and modified by Dan Dediu, 2021-2022
# 
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.


# Assuming the current directory is this script's directory!

```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, # default code chunk options
                      fig.width=9, fig.height=6, fig.align="center", comment=NA, # default figure dimensions
                      dpi=72, dev="jpeg", # please set dpi=300 and comment out dev="jpeg" for high resolution images but very big resulting HTML document
                      cache=TRUE, autodep=TRUE); # cache computations
```

```{r libraries and global options, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}
library(car);
library(dplyr);
library(grid);
library(ggplot2);
library(gridExtra);
library(reshape2);
library(irr);
library(parallel);
library(knitr);
library(kableExtra);
library(pander);
library(moments);
library(tidyr);
library(Hmisc);
library(DiagrammeR);
library(BlandAltmanLeh); # Bland–Altman plots


# Cache folder:
if( !dir.exists("../cache") ) dir.create("../cache", showWarnings=FALSE);
cat("This folder containes various intermediary computations cached for speed, and it is safe to delete at the end of the processing.\n", file="../cache/ReadMe.txt", append=FALSE);

# Final data:
if( !dir.exists("../data/final") ) dir.create("../data/final", showWarnings=FALSE);

# Various partial results cached for paper:
if( !dir.exists("./results_for_paper") ) dir.create("./results_for_paper", showWarnings=FALSE);

run_parallel <- TRUE; # run sequentially or in parallel?
if( run_parallel && !grepl("windows", Sys.info()['sysname'], ignore.case=TRUE) )
{
  no_cores <- parallel::detectCores(); if( no_cores > 1 ) no_cores <- no_cores-1; # try to use almost all cores on the system but feel free to override!
} else
{
  no_cores <- 1;
}

# Figure and Table caption adapted from https://stackoverflow.com/questions/37116632/rmarkdown-html-number-figures: 
outputFormat = opts_knit$get("rmarkdown.pandoc.to"); # determine the output format of the document
if( is.null(outputFormat) ) outputFormat = ""; # probably not run within knittr
capTabNo = 1; capFigNo = 1; # figure and table caption numbering, for HTML do it manually
#Function to add the Table Number
capTab = function(x){
  if(outputFormat == 'html'){
    x = paste0("***Table ",capTabNo,".*** _",x,"_")
    capTabNo <<- capTabNo + 1
  }; x
}
# Function to add the Figure Number
capFig = function(x){
  if(outputFormat == 'html'){
    x = paste0("***Figure ",capFigNo,".*** _",x,"_")
    capFigNo <<- capFigNo + 1
  }; x
}
```


# The data and methods

```{r}
# Load the data:
ph_metainfo <- read.csv("../data/input/phenotype_names_decriptions.csv", stringsAsFactors=FALSE); # phenotype metainfo
ph_mraw     <- read.csv("../data/input/measures.csv",                    stringsAsFactors=FALSE); # the raw phenotypic measurements
if( !file.exists("../data/intermediate/data_for_SEM.csv") ) source("./1_data_preparation.R", echo=FALSE); # run the data preparation first...
ph_mclean   <- read.csv("../data/intermediate/data_for_SEM.csv",         stringsAsFactors=FALSE); # the cleaned phenotypic measurements for fitting the SEM model
if( !file.exists("../data/intermediate/SEM_results.csv") ) source("./2_OpenMx_model.R", echo=FALSE); # run the OpenMX code first...
ph_ace      <- read.csv("../data/intermediate/SEM_results.csv",          stringsAsFactors=FALSE); # OpenMX SEM model results


# Add all the metainfo to ph_ace:
ph_ace <- merge(ph_metainfo[,c("short.names", "phenotype_full_name", "description", "domain", "type")], 
                ph_ace[,!(names(ph_ace) %in% c("phenotype_number", "phenotype_name"))], 
                by.x="short.names", by.y="phenotype_name_short", all=TRUE);
names(ph_ace)[ names(ph_ace) == "short.names" ] <- "short_name"; names(ph_ace)[ names(ph_ace) == "phenotype_full_name" ] <- "full_name";
ph_ace <- ph_ace[ order(ph_ace$domain, ph_ace$type, ph_ace$short_name), ]; 
rm(ph_metainfo); # not needed anymore


# Transform the raw phenotypic measures in the long format using short phenotype names as column names:
tmp1 <- ph_mraw[, c(1, grep("\\.1$", names(ph_mraw)), which(names(ph_mraw)=="FISNumber"):ncol(ph_mraw)) ]; 
s1 <- grep("\\.1$", names(tmp1)); names(tmp1)[s1] <- substring(names(tmp1)[s1], 1, nchar(names(tmp1)[s1])-2);
tmp2 <- ph_mraw[, c(1, grep("\\.2$", names(ph_mraw)), which(names(ph_mraw)=="FISNumber"):ncol(ph_mraw)) ]; 
s2 <- grep("\\.2$", names(tmp2)); names(tmp2)[s2] <- substring(names(tmp2)[s2], 1, nchar(names(tmp2)[s2])-2);
ph_mraw_long <- rbind(cbind("Rater"=1, tmp1),
                      cbind("Rater"=2, tmp2));

# Use short phenotype names:
s <- 3:(which(names(ph_mraw_long)=="FISNumber")-1);
names(ph_mraw_long)[s] <- vapply(names(ph_mraw_long)[s], function(x)
  {
    long_names <- tolower(ph_ace$full_name); x <- tolower(x);
    ss <- (long_names == x);
    if( sum(ss) == 1 )
    {
      return (ph_ace$short_name[ss]); # found
    } else if( sum(ss) == 0 )
    {
      # Compare using only the shared length
      min_len <- pmin(nchar(x), nchar(long_names));
      ss <- (substring(x, 1, min_len) == substring(long_names, 1, min_len));
      if( sum(ss) == 1 )
      {
        return (ph_ace$short_name[ss]); # found
      } else
      {
      stop(cat("Can't match '",x,"'!"));
      return (NA);
      }
    } else
    {
      stop(cat("More than one hits for '",x,"'!"));
      return (NA);
    }
  }, character(1));

# Rename and recode some variables:
ph_mraw_long$Study <- factor(ph_mraw_long$Study, levels=c(1,2,3,6,7), labels=c("ADHD", "OCS", "Depression", "Aging", "Obesity"));
names(ph_mraw_long)[names(ph_mraw_long) == "Age_MRI_1"] <- "Age_MRI";
names(ph_mraw_long)[names(ph_mraw_long) == "ICV_new"]   <- "ICV";
names(ph_mraw_long)[names(ph_mraw_long) == "multiple_type"]   <- "Multiple_type";
names(ph_mraw_long)[names(ph_mraw_long) == "birthorder"]   <- "Birthorder";
names(ph_mraw_long)[names(ph_mraw_long) == "sex"]   <- "Sex";
ph_mraw_long$Sex <- car::recode(ph_mraw_long$Sex, "1='male'; 2='female'");
names(ph_mraw_long)[names(ph_mraw_long) == "yob"]   <- "Year_birth";
names(ph_mraw_long)[names(ph_mraw_long) == "twzyg"]   <- "Twin_zygosity";
ph_mraw_long$Twin_type <- car::recode(ph_mraw_long$Twin_zygosity, "1='MZ'; 3='MZ'; 2='DZ'; 4:6='DZ'");
names(ph_mraw_long)[names(ph_mraw_long) == "twzyg_DNAdet"]   <- "Twin_zygosity_DNA";
ph_mraw_long$Twin_zygosity_DNA <- car::recode(ph_mraw_long$Twin_zygosity_DNA, "1='Yes'; 3='No'");
names(ph_mraw_long)[names(ph_mraw_long) == "mult_id_fam"]   <- "Mult_ID_Fam";
names(ph_mraw_long)[names(ph_mraw_long) == "bioprnt"]   <- "Biological_parent";
names(ph_mraw_long)[names(ph_mraw_long) == "biosib"]   <- "Biological_sibling";
ph_mraw_long$VT_code <- sprintf("VT%03d", ph_mraw_long$VT_code); # standardize the participant IDs

# Sort:
ph_mraw_long <- ph_mraw_long[ order(ph_mraw_long$VT_code, ph_mraw_long$Rater), ];


# Transform the cleaned phenotypic measures in the long format using short phenotype names as column names:
# Notation conventions: 
# - cervicalSpine_CS2H_atlas_c2base_distance.1_1 is phenotype.rater1_twin1. All phenotypes follow this notation. So:
# - phenotype.1_1 = phenotype.rater1_twin1
# - phenotype.2_1 = phenotype.rater2_twin1
# - phenotype.1_2 = phenotype.rater1_twin2
# - phenotype.2_2 = phenotype.rater2_twin2

# Keep only the columns we need:
ph_mclean$X <- NULL; # rownames are not needed
ph_mclean <- ph_mclean %>% select("FISNumber_1", "Sex_1", "FISNumber_2", "Sex_2", "Study", "ZYGMZDZ", "PedigreeNumber", 
                                  c("cervicalSpine_CS2H_atlas_c2base_distance.1_1":"general_GAPD_allPointSet_matlabProcDistance.2_1"),
                                  c("cervicalSpine_CS2H_atlas_c2base_distance.1_2":"general_GAPD_allPointSet_matlabProcDistance.2_2"));
ph_mclean$Study <- factor(ph_mclean$Study, levels=c(1,2,3,6,7), labels=c("ADHD", "OCS", "Depression", "Aging", "Obesity")); # recode study

# Transform in the long format:
# Rater 1 + twin 1:
tmp <- ph_mclean[, c(1, 2, 5:7, grep("\\.1_1$", names(ph_mclean))) ]; 
s1 <- grep("\\.1_1$", names(tmp)); names(tmp)[s1] <- substring(names(tmp)[s1], 1, nchar(names(tmp)[s1])-4); names(tmp)[1:2] <- c("FISNumber", "Sex");
tmp.1_1 <- cbind("Rater"=1, "Twin"=1, tmp);
# Rater 2 + twin 1:
tmp <- ph_mclean[, c(1, 2, 5:7, grep("\\.2_1$", names(ph_mclean))) ]; 
s1 <- grep("\\.2_1$", names(tmp)); names(tmp)[s1] <- substring(names(tmp)[s1], 1, nchar(names(tmp)[s1])-4); names(tmp)[1:2] <- c("FISNumber", "Sex");
tmp.2_1 <- cbind("Rater"=2, "Twin"=1, tmp);
# Rater 1 + twin 2:
tmp <- ph_mclean[, c(3, 4, 5:7, grep("\\.1_2$", names(ph_mclean))) ]; 
s1 <- grep("\\.1_2$", names(tmp)); names(tmp)[s1] <- substring(names(tmp)[s1], 1, nchar(names(tmp)[s1])-4); names(tmp)[1:2] <- c("FISNumber", "Sex");
tmp.1_2 <- cbind("Rater"=1, "Twin"=2, tmp);
# Rater 2 + twin 2:
tmp <- ph_mclean[, c(3, 4, 5:7, grep("\\.2_2$", names(ph_mclean))) ]; 
s1 <- grep("\\.2_2$", names(tmp)); names(tmp)[s1] <- substring(names(tmp)[s1], 1, nchar(names(tmp)[s1])-4); names(tmp)[1:2] <- c("FISNumber", "Sex");
tmp.2_2 <- cbind("Rater"=2, "Twin"=2, tmp);

# Concatenate them, consistency checks, and match to VT_code in the raw data:
ph_mclean_long <- rbind(tmp.1_1, tmp.2_1, tmp.1_2, tmp.2_2);
ph_mclean_long <- ph_mclean_long[ !is.na(ph_mclean_long$FISNumber), ]; # remove missing data
ph_mclean_long$VT_code <- vapply(1:nrow(ph_mclean_long), function(i) 
{
  s <- which(ph_mraw_long$Rater == ph_mclean_long$Rater[i] & ph_mraw_long$FISNumber == ph_mclean_long$FISNumber[i] & ph_mraw_long$Study == ph_mclean_long$Study[i]);
  if( length(s) == 0 ) stop(paste0("No match for datapoint ",i,"!\n"));
  if( length(s) > 1 )  stop(paste0("More than 1 match for datapoint ",i,"!\n"));
  return (ph_mraw_long$VT_code[s]);
}, character(1));

# Add other important covariates:
ph_mclean_long <- merge(ph_mclean_long, ph_mraw_long[,c("VT_code", "Rater", "Age_MRI", "Year_birth", "ICV", "Twin_zygosity_DNA")], 
                        by=c("VT_code", "Rater"), all.x=TRUE, all.y=FALSE);

# Rename, recode some variables and rearrange:
names(ph_mclean_long)[which(names(ph_mclean_long) == "ZYGMZDZ")] <- "Twin_type";
ph_mclean_long <- ph_mclean_long[, c(1:8, ncol(ph_mclean_long)-(0:3), 9:(ncol(ph_mclean_long)-4))];

# Use short phenotype names:
s <- (which(names(ph_mclean_long)=="Age_MRI")+1):ncol(ph_mclean_long);
names(ph_mclean_long)[s] <- vapply(names(ph_mclean_long)[s], function(x)
  {
    long_names <- tolower(ph_ace$full_name); x <- tolower(x);
    ss <- (long_names == x);
    if( sum(ss) == 1 )
    {
      return (ph_ace$short_name[ss]); # found
    } else if( sum(ss) == 0 )
    {
      # Compare using only the shared length
      min_len <- pmin(nchar(x), nchar(long_names));
      ss <- (substring(x, 1, min_len) == substring(long_names, 1, min_len));
      if( sum(ss) == 1 )
      {
        return (ph_ace$short_name[ss]); # found
      } else
      {
      stop(cat("Can't match '",x,"'!"));
      return (NA);
      }
    } else
    {
      stop(cat("More than one hits for '",x,"'!"));
      return (NA);
    }
  }, character(1));

# Sort:
ph_mclean_long <- ph_mclean_long[ order(ph_mclean_long$VT_code, ph_mclean_long$Rater), ];


# Consistency checks between raw and clean long data:
stopifnot((ncol(ph_mclean_long) - which(names(ph_mclean_long) == "Age_MRI")) == (which(names(ph_mraw_long)=="FISNumber")-3)) # number of phenotypic measures
# Relationships between corresponding data:
tmp <- merge(ph_mclean_long, ph_mraw_long, by=c("VT_code", "Rater"), suffixes=c(".clean", ".raw"), all=TRUE);
stopifnot(nrow(tmp) == nrow(ph_mraw_long)); # should be more raw than cleaned data
tmp <- tmp[ !is.na(tmp$FISNumber.clean), ]; # keep just the cleaned data
stopifnot(all(tmp$FISNumber.clean == tmp$FISNumber.raw)); # FISNumber should be identical...
stopifnot(all(tmp$Sex.clean == tmp$Sex.raw)); # Sex should be identical...
stopifnot(all(tmp$Study.clean == tmp$Study.raw)); # Study should be identical...
for(s in ph_ace$short_name) stopifnot(which(is.na(tmp[,paste0(s,".raw")])) %in% which(is.na(tmp[,paste0(s,".clean")]))); # There should be more missing data in the clean than the raw...
for(s in ph_ace$short_name) stopifnot(all(tmp[,paste0(s,".clean")] == tmp[,paste0(s,".raw")], na.rm=TRUE)); # Phenotypic measures should be identical...
# ... all checks passed, continue!

# Cache ph_mclean and ph_mclean_long for the main paper:
save(ph_mclean, ph_mclean_long, file="./results_for_paper/ph_mclean.RData", compress="xz", compression_level=9);
```


## The "raw" data

The "**raw**" data represents the measures taken by each of the two raters on each of the MRI scans of the individual twins in the study.
There are, in total, `r nrow(ph_ace)` measures, each measured independently by `r length(unique(ph_mraw_long$Rater))` raters in `r length(unique(ph_mraw_long$VT_code))` participants (N.B., some participants and  measurements were removed due to missing data).
However, some of these measurements have obvious outliers that would affect the analysis -- their identification and removal produced the "cleaned" data, as described below.
It is this "cleaned" data that will be used in the following analyses.


## The "cleaned" data

The data cleaning and preparation are contained in the accompanying `R` script [`1_data_preparation.R`](./1_data_preparation-v02.R) and is briefly described below:

1. the 39 cases with *unknown zygosity* (MZ/DZ) were removed, 
2. followed by the identification and removal of *duplicate cases*: 6 participants with same *FISNumber* number that participated in two different studies (*OCD* and *EMIF*) &rarr; we kept the *OCD* data,
3. for each phenotypic measure separately, we replaced all values farther than 3 standard deviations from the mean with missing data (i.e., all values *x* such that |*x* - *mean*(*x*)| > *sd*(*x*) became `NA`).


## Descriptives

Total number of participants: `r length(unique(ph_mclean_long$VT_code))`, of which `r s <- unique(ph_mclean_long[,c("VT_code", "Sex")]); sum(s$Sex == "female", na.rm=TRUE)` females (`r round(sum(s$Sex == "female", na.rm=TRUE) / sum(!is.na(s$Sex)) * 100, 1)`%) and `r sum(s$Sex == "male", na.rm=TRUE)` males (`r round(sum(s$Sex == "male", na.rm=TRUE) / sum(!is.na(s$Sex)) * 100, 1)`%).

```{r}
tmp <- table(ph_mclean_long$Sex, ph_mclean_long$Study);
pander(addmargins(tmp));
pander(addmargins(prop.table(tmp, margin=2)*100));
pander(chisq.test(tmp));
```

Total number of unique twin pairs: `r (n_unique_pairs <- length(unique(ph_mclean_long$PedigreeNumber)))`, of which `r s <- ph_mclean_long %>% group_by(PedigreeNumber) %>% summarise(n = length(unique(VT_code))); sum(s$n == 1)` have only one twin member with complete data (all from the *Obesity* study), and `r sum(s$n > 2)` are duplicated among studies (*Aging* and *OCD*); so, in fact we have `r sprintf("2 &times; %d [complete twin pairs] + 1 &times; %d [single-member twin pairs] + 2 &times; %d [duplicated complete twin pairs] = %d", sum(s$n > 1), sum(s$n == 1), sum(s$n > 2), (2*sum(s$n > 1) + 1*sum(s$n == 1) + 2*sum(s$n > 2)))`.

There are `r sum(ph_mclean$ZYGMZDZ == "MZ", na.rm=TRUE)` MZ twin pairs (`r round(sum(ph_mclean$ZYGMZDZ == "MZ", na.rm=TRUE) / sum(!is.na(ph_mclean$ZYGMZDZ)) * 100, 1)`%), and `r sum(ph_mclean$ZYGMZDZ == "DZ", na.rm=TRUE)` DZ twin pairs (`r round(sum(ph_mclean$ZYGMZDZ == "DZ", na.rm=TRUE) / sum(!is.na(ph_mclean$ZYGMZDZ)) * 100, 1)`%), of which `r sum(ph_mclean$ZYGMZDZ == "DZ" & ph_mclean$Sex_1 == ph_mclean$Sex_2 & ph_mclean$Sex_1 == "male", na.rm=TRUE)` are concordant-sex male DZ pairs (`r round(sum(ph_mclean$ZYGMZDZ == "DZ" & ph_mclean$Sex_1 == ph_mclean$Sex_2 & ph_mclean$Sex_1 == "male", na.rm=TRUE) / sum(ph_mclean$ZYGMZDZ == "DZ", na.rm=TRUE) * 100, 1)`%), `r sum(ph_mclean$ZYGMZDZ == "DZ" & ph_mclean$Sex_1 == ph_mclean$Sex_2 & ph_mclean$Sex_1 == "female", na.rm=TRUE)` are concordant-sex female DZ pairs (`r round(sum(ph_mclean$ZYGMZDZ == "DZ" & ph_mclean$Sex_1 == ph_mclean$Sex_2 & ph_mclean$Sex_1 == "female", na.rm=TRUE) / sum(ph_mclean$ZYGMZDZ == "DZ", na.rm=TRUE) * 100, 1)`%), and `r sum(ph_mclean$ZYGMZDZ == "DZ" & ph_mclean$Sex_1 != ph_mclean$Sex_2, na.rm=TRUE)` are discordant-sex DZ pairs (`r round(sum(ph_mclean$ZYGMZDZ == "DZ" & ph_mclean$Sex_1 != ph_mclean$Sex_2, na.rm=TRUE) / sum(ph_mclean$ZYGMZDZ == "DZ", na.rm=TRUE) * 100, 1)`%), with the remaining `r sum(ph_mclean$ZYGMZDZ == "DZ" & (is.na(ph_mclean$Sex_1) | is.na(ph_mclean$Sex_2)), na.rm=TRUE)` having only one non-missing pair member (`r round(sum(ph_mclean$ZYGMZDZ == "DZ" & (is.na(ph_mclean$Sex_1) | is.na(ph_mclean$Sex_2)), na.rm=TRUE) / sum(ph_mclean$ZYGMZDZ == "DZ", na.rm=TRUE) * 100, 1)`%).

Age: min=`r min(ph_mclean_long$Age_MRI, na.rm=TRUE)`, max=`r max(ph_mclean_long$Age_MRI, na.rm=TRUE)`, mean=`r round(mean(ph_mclean_long$Age_MRI, na.rm=TRUE),2)`, median=`r round(median(ph_mclean_long$Age_MRI, na.rm=TRUE),2)`, sd=`r round(sd(ph_mclean_long$Age_MRI, na.rm=TRUE),2)` and IQR=`r round(IQR(ph_mclean_long$Age_MRI, na.rm=TRUE),2)`.

```{r}
pander(t.test(Age_MRI ~ Sex, data=ph_mclean_long));
tmp <- aov(Age_MRI ~ Study, data=ph_mclean_long); pander(summary(tmp)); pander(TukeyHSD(tmp)[[1]]);
```

ICV (cm^3^): min=`r min(ph_mclean_long$ICV*0.001, na.rm=TRUE)`, max=`r max(ph_mclean_long$ICV*0.001, na.rm=TRUE)`, mean=`r round(mean(ph_mclean_long$ICV*0.001, na.rm=TRUE),2)`, median=`r round(median(ph_mclean_long$ICV*0.001, na.rm=TRUE),2)`, sd=`r round(sd(ph_mclean_long$ICV*0.001, na.rm=TRUE),2)` and IQR=`r round(IQR(ph_mclean_long$ICV*0.001, na.rm=TRUE),2)`.

```{r}
pander(t.test(ICV*0.001 ~ Sex, data=ph_mclean_long));
tmp <- aov(ICV*0.001 ~ Study, data=ph_mclean_long); pander(summary(tmp)); pander(TukeyHSD(tmp)[[1]]);
```

```{r descriptive plots, fig.width=2*5, fig.height=2*5, fig.cap=capFig("Descriptives for the paper.")}
# Main figure for all descriptive statistics:

# Distribution of twin pairs by Study (also by zygosity):
p1 <- ggplot(as.data.frame(table(ph_mclean$Study, ph_mclean$ZYGMZDZ, useNA="ifany")),
       aes(x=Var1, y=Freq, fill=Var2)) + 
  geom_bar(stat="identity", color="black") + 
  geom_text(aes(label=Freq), color="black", size=3.0, position=position_stack(vjust=0.5))+
  xlab("Study") + ylab("Count") + scale_fill_manual("Zygosity", values=c("DZ"="salmon", "MZ"="skyblue")) + 
  ggtitle("A. Zygosity by study") +
  NULL;

# Twin pair types:
p2 <- ggplot(as.data.frame(table(ph_mclean[ , c("ZYGMZDZ", "Sex_1", "Sex_2")], useNA="ifany")) %>% 
               mutate("pair_type"=if_else(is.na(Sex_1) | is.na(Sex_2), paste0("one member (",if_else(is.na(Sex_1),"",as.character(Sex_1)),if_else(is.na(Sex_2),"",as.character(Sex_2)),")"),
                                          if_else(Sex_1 == Sex_2, paste0("concordant (",Sex_1,")"), "discordant"))) %>%
               group_by(ZYGMZDZ, pair_type) %>%
               summarise(n=sum(Freq)), 
             aes(x=ZYGMZDZ, y=n, fill=pair_type)) + 
  geom_bar(stat="identity", color="black") + 
  geom_text(aes(label=n), color="black", size=3.0, position=position_stack(vjust=0.5)) +
  xlab("Zygosity") + ylab("Count") + scale_fill_manual("Pair type", values=c("concordant (female)"="firebrick", "concordant (male)"  ="dodgerblue3",
                                                                             "discordant"="yellow", 
                                                                             "one member (female)"="darkorange", "one member (male)"  ="lightblue")) + 
  ggtitle("B. Twin pair types across studies") +
  NULL;

# ICV:
p3 <- ggplot(ph_mclean_long, aes(x=ICV*0.001, fill=Sex, color=Sex)) + geom_density(alpha=0.25) +
  geom_density(data=ph_mclean_long, aes(x=ICV*0.001), fill="black", color="black", alpha=0.25) + 
  xlab(expression('ICV (cm'^3*')')) + ylab("Density") +
  ggtitle("C. ICV across studies") +
  NULL;

# Age:
p4 <- ggplot(ph_mclean_long, aes(y=Age_MRI, x=Study, fill=Study)) + geom_boxplot(alpha=0.25) + geom_violin(alpha=0.15) +
  #geom_density(data=ph_mclean_long, aes(x=Age_MRI), fill="black", color="black", alpha=0.25) + 
  ylab('Age at MRI (years)') + xlab("Study") + scale_fill_viridis_d() + scale_color_viridis_d() +
  ggtitle("D. Age at MRI by study") +
  NULL;


# Combine and show them them:
grid.arrange(p1, p2, p3, p4, nrow=2);
```
```{r results='hide'}
# Save the figure:

# As TIFF:
tiff(file="../figures/figure_01.tiff", width=2*5, height=2*5, units="in", res=600, compression="lzw");

# Distribution of twin pairs by Study (also by zygosity):
p1 <- ggplot(as.data.frame(table(ph_mclean$Study, ph_mclean$ZYGMZDZ, useNA="ifany")),
       aes(x=Var1, y=Freq, fill=Var2)) + 
  geom_bar(stat="identity", color="black") + 
  geom_text(aes(label=Freq), color="black", size=3.0, position=position_stack(vjust=0.5))+
  xlab("Study") + ylab("Count") + scale_fill_manual("Zygosity", values=c("DZ"="white", "MZ"="gray90")) + 
  ggtitle("A. Zygosity by study") + theme_bw() +
  NULL;

# Twin pair types:
p2 <- ggplot(as.data.frame(table(ph_mclean[ , c("ZYGMZDZ", "Sex_1", "Sex_2")], useNA="ifany")) %>% 
               mutate("pair_type"=if_else(is.na(Sex_1) | is.na(Sex_2), paste0("one member (",if_else(is.na(Sex_1),"",as.character(Sex_1)),if_else(is.na(Sex_2),"",as.character(Sex_2)),")"),
                                          if_else(Sex_1 == Sex_2, paste0("concordant (",Sex_1,")"), "discordant"))) %>%
               group_by(ZYGMZDZ, pair_type) %>%
               summarise(n=sum(Freq)), 
             aes(x=ZYGMZDZ, y=n, fill=pair_type)) + 
  geom_bar(stat="identity", color="black") + 
  geom_text(aes(label=n), color="black", size=3.0, position=position_stack(vjust=0.5)) +
  xlab("Zygosity") + ylab("Count") + scale_fill_manual("Pair type", values=c("concordant (female)"="salmon", "concordant (male)"  ="steelblue1",
                                                                             "discordant"="gray60", 
                                                                             "one member (female)"="red", "one member (male)"  ="royalblue1")) + 
  ggtitle("B. Twin pair types across studies") + theme_bw() +
  NULL;

# ICV:
p3 <- ggplot(ph_mclean_long, aes(x=ICV*0.001, fill=Sex, color=Sex)) + geom_density(alpha=0.25) +
  geom_density(data=ph_mclean_long, aes(x=ICV*0.001), fill="white", color="black", alpha=0.25) + 
  xlab(expression('ICV (cm'^3*')')) + ylab("Density") + 
  scale_fill_manual("Sex", values=c("female"="salmon", "male"="steelblue1")) + scale_color_manual("Sex", values=c("female"="salmon", "male"="steelblue1")) + 
  ggtitle("C. ICV across studies") + theme_bw() +
  NULL;

# Age:
p4 <- ggplot(ph_mclean_long, aes(y=Age_MRI, x=Study)) + 
  geom_boxplot(color="black") + #geom_violin(alpha=0.25, fill="gray10") +
  geom_point(alpha=0.10, color="gray50") +
  #geom_density(data=ph_mclean_long, aes(x=Age_MRI), fill="black", color="black", alpha=0.25) + 
  ylab('Age at MRI (years)') + xlab("Study") + 
  ggtitle("D. Age at MRI by study") + theme_bw() +
  NULL;

grid.arrange(p1, 
             p2, 
             p3, 
             p4, 
             nrow=2);
dev.off();

# ... and as JPEG:
jpeg(file="../figures/figure_01.jpg", width=2*5, height=2*5, units="in", res=150, quality=85);

# Distribution of twin pairs by Study (also by zygosity):
p1 <- ggplot(as.data.frame(table(ph_mclean$Study, ph_mclean$ZYGMZDZ, useNA="ifany")),
       aes(x=Var1, y=Freq, fill=Var2)) + 
  geom_bar(stat="identity", color="black") + 
  geom_text(aes(label=Freq), color="black", size=3.0, position=position_stack(vjust=0.5))+
  xlab("Study") + ylab("Count") + scale_fill_manual("Zygosity", values=c("DZ"="white", "MZ"="gray90")) + 
  ggtitle("A. Zygosity by study") + theme_bw() +
  NULL;

# Twin pair types:
p2 <- ggplot(as.data.frame(table(ph_mclean[ , c("ZYGMZDZ", "Sex_1", "Sex_2")], useNA="ifany")) %>% 
               mutate("pair_type"=if_else(is.na(Sex_1) | is.na(Sex_2), paste0("one member (",if_else(is.na(Sex_1),"",as.character(Sex_1)),if_else(is.na(Sex_2),"",as.character(Sex_2)),")"),
                                          if_else(Sex_1 == Sex_2, paste0("concordant (",Sex_1,")"), "discordant"))) %>%
               group_by(ZYGMZDZ, pair_type) %>%
               summarise(n=sum(Freq)), 
             aes(x=ZYGMZDZ, y=n, fill=pair_type)) + 
  geom_bar(stat="identity", color="black") + 
  geom_text(aes(label=n), color="black", size=3.0, position=position_stack(vjust=0.5)) +
  xlab("Zygosity") + ylab("Count") + scale_fill_manual("Pair type", values=c("concordant (female)"="salmon", "concordant (male)"  ="steelblue1",
                                                                             "discordant"="gray60", 
                                                                             "one member (female)"="red", "one member (male)"  ="royalblue1")) + 
  ggtitle("B. Twin pair types across studies") + theme_bw() +
  NULL;

# ICV:
p3 <- ggplot(ph_mclean_long, aes(x=ICV*0.001, fill=Sex, color=Sex)) + geom_density(alpha=0.25) +
  geom_density(data=ph_mclean_long, aes(x=ICV*0.001), fill="white", color="black", alpha=0.25) + 
  xlab(expression('ICV (cm'^3*')')) + ylab("Density") + 
  scale_fill_manual("Sex", values=c("female"="salmon", "male"="steelblue1")) + scale_color_manual("Sex", values=c("female"="salmon", "male"="steelblue1")) + 
  ggtitle("C. ICV across studies") + theme_bw() +
  NULL;

# Age:
p4 <- ggplot(ph_mclean_long, aes(y=Age_MRI, x=Study)) + 
  geom_boxplot(color="black") + #geom_violin(alpha=0.25, fill="gray10") +
  geom_point(alpha=0.10, color="gray50") +
  #geom_density(data=ph_mclean_long, aes(x=Age_MRI), fill="black", color="black", alpha=0.25) + 
  ylab('Age at MRI (years)') + xlab("Study") + 
  ggtitle("D. Age at MRI by study") + theme_bw() +
  NULL;

grid.arrange(p1, 
             p2, 
             p3, 
             p4, 
             nrow=2);
dev.off();
```


# The measures

There are `r nrow(ph_ace)` measures (bt please note that some were exact duplicates and were subsequently removed from the analysis -- please see below), each measured independently by `r length(unique(ph_mclean_long$Rater))` raters in `r length(unique(ph_mclean_long$VT_code))` participants.

```{r}
knitr::kable(ph_ace[,c("short_name", "domain", "type", "description", "full_name")], row.names=FALSE,
             col.names=c("code", "domain", "type", "description", "full name"),
             caption=capTab("Details about the phenotypes, including their short name (the **code**; codes with a star * represent deduplicated codes), the anatomical **domain** and **type**, their **description** and **full names**.")) %>%
  kable_styling() %>%
  column_spec(5, width_max="10em");
```


## Distributions and summaries

### Tables

#### By domain

**Counts:**
```{r}
pander(table(ph_ace$domain));
```

**Percents (%):**
```{r}
pander(prop.table(table(ph_ace$domain))*100); # proportions
```

#### By type

**Counts:**
```{r}
pander(table(ph_ace$type));
```

**Percents (%):**
```{r}
pander(prop.table(table(ph_ace$type))*100); # proportions
```


### Histograms (& QQ-plots)

#### Each measure separately

```{r fig.width=5*3, fig.height=ceiling(nrow(ph_ace)/5)*3, fig.cap=capFig("Histograms of the measures split by *sex* (red=females, blue=males) but not by *rater*. Please note that the *x* and *y* scales are independent between plots.")}
tmp <- mclapply(ph_ace$short_name, function(s)
{
  d <- ph_mclean_long[,c("Rater", "VT_code", s, "Study", "Age_MRI", "Sex", "Twin_type")]; names(d)[3] <- "measure";
  ggplot(d, aes(x=measure)) + geom_histogram(alpha=0.25, aes(color=Sex, fill=Sex), bins=30) + 
    xlab(s) + theme(legend.position="none") + scale_colour_manual(values=c("female"="red", "male"="blue"));
}, mc.cores=no_cores);
grid.arrange(grobs=tmp, ncol=5);
```

```{r fig.width=5*3, fig.height=ceiling(nrow(ph_ace)/5)*3, fig.cap=capFig("QQ-plots of the measures split by *sex* (red=females, blue=males) but not by *rater*. Please note that the *x* and *y* scales are independent between plots.")}
tmp <- mclapply(ph_ace$short_name, function(s)
{
  d <- ph_mclean_long[,c("Rater", "VT_code", s, "Study", "Age_MRI", "Sex", "Twin_type")]; names(d)[3] <- "measure";
  ggplot(d, aes(sample=measure, color=Sex)) + stat_qq(alpha=0.25) + stat_qq_line() + 
    xlab(s) + theme(legend.position="none") + scale_colour_manual(values=c("female"="red", "male"="blue"));
}, mc.cores=no_cores);
grid.arrange(grobs=tmp, ncol=5);
```

#### By domain

```{r fig.width=5*3, fig.height=ceiling(length(unique(ph_ace$domain))/5)*3, fig.cap=capFig("Histograms of the measures split by *sex* (red=females, blue=males) and *domain*. Please note that the *x* and *y* scales are independent between plots.")}
tmp <- mclapply(unique(ph_ace$domain), function(s)
{
  measures <- ph_ace$short_name[ ph_ace$domain == s ];
  d <- ph_mclean_long[,c("Sex", measures)] %>% pivot_longer(all_of(measures));
  ggplot(d, aes(x=value)) + geom_histogram(alpha=0.25, aes(color=Sex, fill=Sex), bins=30) + 
    xlab(s) + theme(legend.position="none") + scale_colour_manual(values=c("female"="red", "male"="blue"));
}, mc.cores=no_cores);
grid.arrange(grobs=tmp, ncol=5);
```

#### By type

```{r fig.width=5*3, fig.height=ceiling(length(unique(ph_ace$type))/5)*3, fig.cap=capFig("Histograms of the measures split by *sex* (red=females, blue=males) and *type*. Please note that the *x* and *y* scales are independent between plots.")}
tmp <- mclapply(unique(ph_ace$type), function(s)
{
  measures <- ph_ace$short_name[ ph_ace$type == s ];
  d <- ph_mclean_long[,c("Sex", measures)] %>% pivot_longer(all_of(measures));
  ggplot(d, aes(x=value)) + geom_histogram(alpha=0.25, aes(color=Sex, fill=Sex), bins=30) + 
    xlab(s) + theme(legend.position="none") + scale_colour_manual(values=c("female"="red", "male"="blue"));
}, mc.cores=no_cores);
grid.arrange(grobs=tmp, ncol=5);
```


### Summaries

```{r}
# Summary statistics for each measure:
measures_summaries <- do.call(rbind, lapply(ph_ace$short_name, function(s)
{
  d <- ph_mclean_long[,c("Rater", "VT_code", s, "Study", "Age_MRI", "Sex", "Twin_type")]; names(d)[3] <- "measure";
  data.frame(# all together:
             "all_min"         =min(d$measure, na.rm=TRUE), 
             "all_max"         =max(d$measure, na.rm=TRUE), 
             "all_mean"        =mean(d$measure, na.rm=TRUE), 
             "all_median"      =median(d$measure, na.rm=TRUE), 
             "all_sd"          =sd(d$measure, na.rm=TRUE), 
             "all_iqr"         =IQR(d$measure, na.rm=TRUE),
             "all_kurtosis"    =moments::kurtosis(d$measure, na.rm=TRUE),
             "all_skewness"    =moments::skewness(d$measure, na.rm=TRUE),
             "all_shapiro.p"   =shapiro.test(d$measure)$p.value,
             # Males only:
             "male_min"        =min(d$measure[ d$Sex == "male" ], na.rm=TRUE), 
             "male_max"        =max(d$measure[ d$Sex == "male" ], na.rm=TRUE), 
             "male_mean"       =mean(d$measure[ d$Sex == "male" ], na.rm=TRUE), 
             "male_median"     =median(d$measure[ d$Sex == "male" ], na.rm=TRUE), 
             "male_sd"         =sd(d$measure[ d$Sex == "male" ], na.rm=TRUE), 
             "male_iqr"        =IQR(d$measure[ d$Sex == "male" ], na.rm=TRUE),
             "male_kurtosis"   =moments::kurtosis(d$measure[ d$Sex == "male" ], na.rm=TRUE),
             "male_skewness"   =moments::skewness(d$measure[ d$Sex == "male" ], na.rm=TRUE),
             "male_shapiro.p"  =shapiro.test(d$measure[ d$Sex == "male" ])$p.value,
             # Females only:
             "female_min"      =min(d$measure[ d$Sex == "female" ], na.rm=TRUE), 
             "female_max"      =max(d$measure[ d$Sex == "female" ], na.rm=TRUE),
             "female_mean"     =mean(d$measure[ d$Sex == "female" ], na.rm=TRUE), 
             "female_median"   =median(d$measure[ d$Sex == "female" ], na.rm=TRUE), 
             "female_sd"       =sd(d$measure[ d$Sex == "female" ], na.rm=TRUE), 
             "female_iqr"      =IQR(d$measure[ d$Sex == "female" ], na.rm=TRUE),
             "female_kurtosis" =moments::kurtosis(d$measure[ d$Sex == "female" ], na.rm=TRUE),
             "female_skewness" =moments::skewness(d$measure[ d$Sex == "female" ], na.rm=TRUE),
             "female_shapiro.p"=shapiro.test(d$measure[ d$Sex == "female" ])$p.value); 
}));
rownames(measures_summaries) <- ph_ace$short_name;
```

#### Across all participants

```{r}
s <- names(measures_summaries)[ grep("^all_", names(measures_summaries)) ];
knitr::kable(measures_summaries[,s] %>% mutate(all_shapiro.p = sprintf("%.3g",all_shapiro.p)), 
             row.names=TRUE,
             col.names=substring(s, nchar("all_")+1), digits=2,
             caption=capTab("Summary statistics for all measures across all participants. Please note that, for a normal distribution, the expected skewness is 0.0 and kurtosis is 3.0. The *p*-values are those of the Shapiro-Wilk normality test.")) %>%
  kable_styling(); 
```

#### Males only

```{r}
s <- names(measures_summaries)[ grep("^male_", names(measures_summaries)) ];
knitr::kable(measures_summaries[,s] %>% mutate(male_shapiro.p = sprintf("%.3g",male_shapiro.p)), 
             row.names=TRUE,
             col.names=substring(s, nchar("male_")+1), digits=2,
             caption=capTab("Summary statistics for all measures across males only. Please note that, for a normal distribution, the expected skewness is 0.0 and kurtosis is 3.0. The *p*-values are those of the Shapiro-Wilk normality test.")) %>%
  kable_styling(); 
```

#### Females only

```{r}
s <- names(measures_summaries)[ grep("^female_", names(measures_summaries)) ];
knitr::kable(measures_summaries[,s] %>% mutate(female_shapiro.p = sprintf("%.3g",female_shapiro.p)), 
             row.names=TRUE,
             col.names=substring(s, nchar("female_")+1), digits=2,
             caption=capTab("Summary statistics for all measures across females only. Please note that, for a normal distribution, the expected skewness is 0.0 and kurtosis is 3.0. The *p*-values are those of the Shapiro-Wilk normality test.")) %>%
  kable_styling(); 
```


## Inter-correlations and similarities between measures

```{r}
# ++++++++++++++++++++++++++++
# flattenCorrMatrix
# ++++++++++++++++++++++++++++
# cormat : matrix of the correlation coefficients
# pmat : matrix of the correlation p-values
# From: http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software
flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}
r_measures <- rcorr(as.matrix(ph_mclean_long[,ph_ace$short_name]));
r_measures_long <- flattenCorrMatrix(r_measures$r, r_measures$P);
r_measures_long <- r_measures_long[ order(r_measures_long$cor, decreasing=TRUE), ];
r_measures_long$identical <- vapply(1:nrow(r_measures_long), 
                                    function(i) isTRUE(all.equal(ph_mclean_long[,r_measures_long$row[i]], ph_mclean_long[,r_measures_long$column[i]])), 
                                    logical(1));
# Check the ones that have a very high correlation for actual identity or very high similarity:
knitr::kable(r_measures_long[ r_measures_long$cor >= 0.90,] %>% mutate(identical=if_else(identical, "Yes", "No"),  p = sprintf("%.3g",p)), 
             row.names=FALSE,
             col.names=c("measure1", "measure2", "Pearson's *r*", "*p*", "Are they identical?"), 
             digits=c(NA, NA, 3, NA, NA),
             caption=capTab("Correlations between measures (showing those with Pearson's *r* >= 0.90).")) %>%
  kable_styling();
```

### Measures pefectly correlated

Here we manually check the *meaning* of those measures that have a correlation of 1.0 and are numerically identical.

```{r}
# Check the identical ones:
knitr::kable(ph_ace[ ph_ace$short_name %in% c("LNEP",  "SVTv"), c("short_name", "full_name", "description") ], row.names=FALSE,
             col.names=c("measure", "full name", "description"),
             caption=capTab("Comparing LNEP and SVTv: they are indeed the same thing, we'll keep SVTv.")) %>%
  kable_styling(); # keep SVTv

knitr::kable(ph_ace[ ph_ace$short_name %in% c("ASCG", "MCGM"), c("short_name", "full_name", "description") ], row.names=FALSE,
             col.names=c("measure", "full name", "description"),
             caption=capTab("Comparing ASCG and MCGM: they are indeed the same thing, we'll keep MCGM.")) %>%
  kable_styling(); # keep MCGM

knitr::kable(ph_ace[ ph_ace$short_name %in% c("HBPL",  "SBAP"), c("short_name", "full_name", "description") ], row.names=FALSE,
             col.names=c("measure", "full name", "description"),
             caption=capTab("Comparing HBPL and SBAP: they are indeed the same thing, we'll keep HBPL.")) %>%
  kable_styling(); # keep HBPL

knitr::kable(ph_ace[ ph_ace$short_name %in% c("SVTv*", "LNCT"), c("short_name", "full_name", "description") ], row.names=FALSE,
             col.names=c("measure", "full name", "description"),
             caption=capTab("Comparing SVTv* and LNCT: they are indeed the same thing, we'll keep SVTv*.")) %>%
  kable_styling(); # keep SVTv*

# Remove these measures:
ph_ace <- ph_ace[ !(ph_ace$short_name %in% c("LNEP", "ASCG", "SBAP", "LNCT")), ];
ph_mclean <- ph_mclean[ , -c(grep("LNEP",        names(ph_mclean), fixed=TRUE), 
                             grep("ASCG_gonion", names(ph_mclean), fixed=TRUE), # make sure it's the right ASCG (i.e., not ASCG*)
                             grep("SBAP",        names(ph_mclean), fixed=TRUE),
                             grep("LNCT",        names(ph_mclean), fixed=TRUE)) ];
ph_mclean_long <- ph_mclean_long[ , -c(grep("LNEP",  names(ph_mclean_long), fixed=TRUE), 
                                       grep("ASCG$", names(ph_mclean_long), fixed=FALSE), # don't also remove ASCG*
                                       grep("SBAP",  names(ph_mclean_long), fixed=TRUE),
                                       grep("LNCT",  names(ph_mclean_long), fixed=TRUE)) ];
```

Removing these four redundant measures (LNEP, ASCG, SBAP, LNCT) reduces the number of measures to `r nrow(ph_ace)`; however, this procedure leaves untouched the several very highly correlated measures, whose correlations seem to be substantively motivated but not _a priori_ trivial.


#### Distributions and summaries of the remaning measures

##### By domain

**Counts:**
```{r}
pander(table(ph_ace$domain));
```

**Percents (%):**
```{r}
pander(prop.table(table(ph_ace$domain))*100); # proportions
```

##### By type

**Counts:**
```{r}
pander(table(ph_ace$type));
```

**Percents (%):**
```{r}
pander(prop.table(table(ph_ace$type))*100); # proportions
```



## Correlations between the twins

Here we look, for each measure, at the relationship between the values of the members of the same twin pair.

```{r}
# Recast the data to highlight the twin pairs:
ph_mclean_twin_pairs <- do.call(rbind, lapply(unique(ph_mclean_long$PedigreeNumber), function(pedigree)
{
  tmp <- ph_mclean_long[ph_mclean_long$PedigreeNumber == pedigree, ];
  if( is.null(tmp) || nrow(tmp) != 4 ) return (NULL);
  raters <- sort(unique(tmp$Rater)); vtcodes <- sort(unique(tmp$VT_code));
  do.call(rbind, lapply(ph_ace$short_name, function(measure)
    data.frame("Rater"=raters, "Measure"=measure, "Pedigree"=pedigree, "Twin1_ID"=vtcodes[1], "Twin2_ID"=vtcodes[2], "Twin_type"=tmp$Twin_type[1],
               "Twin1_value"=vapply(raters, function(rater) tmp[ tmp$Rater == rater & tmp$VT_code == vtcodes[1], measure ], numeric(1)), 
               "Twin2_value"=vapply(raters, function(rater) tmp[ tmp$Rater == rater & tmp$VT_code == vtcodes[2], measure ], numeric(1)))));
}));
ph_mclean_twin_pairs <- ph_mclean_twin_pairs[ order(ph_mclean_twin_pairs$Rater, ph_mclean_twin_pairs$Measure, 
                                                    ph_mclean_twin_pairs$Twin_type, ph_mclean_twin_pairs$Pedigree), ];
```

### All twins together

```{r fig.width=5*3, fig.height=ceiling(nrow(ph_ace)/5)*3, fig.cap=capFig("Scatterplot of the values for the two twins in the same pair for each measure separately, for each rater (color) and together (black line). All twins (MZ and DZ) are considered. Please note that the *x* and *y* scales are independent between plots.")}
# tmp <- mclapply(ph_mclean_twin_pairs$Measure, function(s)
# {
#   d <- ph_mclean_twin_pairs[ ph_mclean_twin_pairs$Measure == s, ];
#   ggplot(d, aes(x=Twin1_value, y=Twin2_value, color=as.factor(Rater))) + ggtitle(paste0(s," (all twins)")) + xlab("1st twin value") + ylab("2nd twin value") + 
#     geom_point() + geom_smooth(method="lm", formula=y ~ x) + 
#     #geom_smooth(data=d, aes(x=Twin1_value, y=Twin2_value), method="lm", formula=y ~ x, color="black") + 
#     theme(legend.position="none") + #scale_colour_manual(values=c("1"="red", "2"="blue")) + 
#     NULL;
# }, mc.cores=no_cores);
# grid.arrange(grobs=tmp, ncol=5);
ggplot(ph_mclean_twin_pairs, aes(x=Twin1_value, y=Twin2_value, color=as.factor(Rater))) + 
  ggtitle(paste0(s," (all twins)")) + xlab("1st twin value") + ylab("2nd twin value") + 
  geom_point() + geom_smooth(method="lm", formula=y ~ x, fullrange=TRUE) + 
  geom_smooth(data=ph_mclean_twin_pairs, aes(x=Twin1_value, y=Twin2_value), method="lm", formula=y ~ x, color="black") + 
  theme(legend.position="none") + #scale_colour_manual(values=c("1"="red", "2"="blue")) + 
  facet_wrap(. ~ Measure, scales="free", ncol=5) +
  NULL;
```

### MZ twins only

```{r fig.width=5*3, fig.height=ceiling(nrow(ph_ace)/5)*3, fig.cap=capFig("Scatterplot of the values for the two twins in the same pair for each measure separately, for each rater (color) and together (black line). Only MZ twins are considered. Please note that the *x* and *y* scales are independent between plots.")}
ggplot(ph_mclean_twin_pairs[ ph_mclean_twin_pairs$Twin_type == "MZ", ], aes(x=Twin1_value, y=Twin2_value, color=as.factor(Rater))) + 
  ggtitle(paste0(s," (all twins)")) + xlab("1st twin value") + ylab("2nd twin value") + 
  geom_point() + geom_smooth(method="lm", formula=y ~ x, fullrange=TRUE) + 
  geom_smooth(data=ph_mclean_twin_pairs[ ph_mclean_twin_pairs$Twin_type == "MZ", ], aes(x=Twin1_value, y=Twin2_value), method="lm", formula=y ~ x, color="black") + 
  theme(legend.position="none") + #scale_colour_manual(values=c("1"="red", "2"="blue")) + 
  facet_wrap(. ~ Measure, scales="free", ncol=5) +
  NULL;
```

### DZ twins only

```{r fig.width=5*3, fig.height=ceiling(nrow(ph_ace)/5)*3, fig.cap=capFig("Scatterplot of the values for the two twins in the same pair for each measure separately, for each rater (color) and together (black line). Only DZ twins are considered. Please note that the *x* and *y* scales are independent between plots.")}
ggplot(ph_mclean_twin_pairs[ ph_mclean_twin_pairs$Twin_type == "DZ", ], aes(x=Twin1_value, y=Twin2_value, color=as.factor(Rater))) + 
  ggtitle(paste0(s," (all twins)")) + xlab("1st twin value") + ylab("2nd twin value") + 
  geom_point() + geom_smooth(method="lm", formula=y ~ x, fullrange=TRUE) + 
  geom_smooth(data=ph_mclean_twin_pairs[ ph_mclean_twin_pairs$Twin_type == "DZ", ], aes(x=Twin1_value, y=Twin2_value), method="lm", formula=y ~ x, color="black") + 
  theme(legend.position="none") + #scale_colour_manual(values=c("1"="red", "2"="blue")) + 
  facet_wrap(. ~ Measure, scales="free", ncol=5) +
  NULL;
```



## Inter-raters agreement

Given that all our data was landmarked in parallel by two raters, we can compute the inter-rater agreement for all our variables.
We used both *Krippendorff's &alpha;* and the intraclass correlations coefficient (*ICC*); for both, values closer to 1.0 indicate high agreement, 0.0 means randomness, and negative values indicate systematic disagreement.
Please note that the GSEM model used to estimate heritability (see Section [The SEM genetic model]) also allows us to estimate a measure of inter-rater agreement defined as (1 - {standardized rater error variance}) = (*A* + (*C* or *D*) + *E*)/{the observed phenotypic variance, *var*(phenotype)} -- we will denote this as *agr*(GSEM).

```{r}
# Compute the inter-rater agreement (quite computationally expensive, better to cache):
if( !file.exists("../cache/inter_rater_agreements.RData") )
{
  inter_rater_agreements <- do.call(rbind, mclapply(ph_ace$short_name, function(v)
  {
    # Get the data in the right format:
    d <- as.matrix(reshape2::dcast(ph_mclean_long, VT_code ~ Rater, value.var=v)[,-1]);
    
    # Compute ICCs:
    d.icc   <- irr::icc(d, model="oneway", unit="single");
    d.iccC1 <- irr::icc(d, model="twoway", type="consistency", unit="single");
    d.iccA1 <- irr::icc(d, model="twoway", type="agreement", unit="single");
    
    # Compute Krippendorff's α:
    d.ka    <- irr::kripp.alpha(t(d), method="ratio"); # arguably, all variables are on a "ratio" measurement scale...

    # Return the results:
    data.frame("variable"=v,
               "Krippendorff.alpha"= d.ka$value,
               "ICC"=d.icc$value, "ICC.p"=d.icc$p.value, "ICC.CI_low"=d.icc$lbound, "ICC.CI_high"=d.icc$ubound,
               "ICCc1"=d.iccC1$value, "ICCc1.p"=d.iccC1$p.value, "ICCc1.CI_low"=d.iccC1$lbound, "ICCc1.CI_high"=d.iccC1$ubound,
               "ICCA1"=d.iccA1$value, "ICCA1.p"=d.iccA1$p.value, "ICCA1.CI_low"=d.iccA1$lbound, "ICCA1.CI_high"=d.iccA1$ubound);
  }, mc.cores=no_cores));
  save(inter_rater_agreements, 
       file="../cache/inter_rater_agreements.RData", compress="xz", compression_level=9);
} else
{
  load("../cache/inter_rater_agreements.RData");
}

ph_ace <- merge(ph_ace, inter_rater_agreements, by.x=c("short_name"), by.y=c("variable"), all=TRUE);
```



### Bland–Altman plots

For a given measure, the Bland–Altman plot represents, for each measured participant, the relationship between the mean of the two raters (on the x-axis) and their difference (on the y axis). 
The plot also shows the mean difference (or the fixed bias between the two raters) and the ± 1.96 SD lines (allowing the identification of outlier participants in terms of the difference between the two raters).
If the range between these two lines, i.e., between (mean - 1.96 SD) and (mean + 1.96 SD) are not substantively important, the two raters can be considered as indistinguishable.

```{r fig.width=4*3, fig.height=ceiling(nrow(ph_ace)/4)*3, fig.cap=capFig("The Bland–Altman plots for each measure. The x-axis is the mean of the two raters, while the y-axis is the difference between the two raters (here, rater 1 - rater 2). The blue dotted line in the middle is the mean difference, while the two red dotted lines above and below it are the mean difference ± 1.96 SD. Please see text on how to interpret such plots."), eval=FALSE, include=FALSE}
par(mfrow=c(ceiling(nrow(ph_ace)/4),4));
# ba.results <- list();
# for(v in ph_ace$short_name)
# {
#   # Get the data in the right format:
#   d <- as.matrix(reshape2::dcast(ph_mclean_long, VT_code ~ Rater, value.var=v)[,-1]);
# 
#   # Compute the statistics and plot the Bland-Altman-Plot:
#   try(bland.altman.plot(d[,1], d[,2], graph.sys="base", conf.int=0.00, 
#                         col="skyblue", pch=1, cex=0.75, xlab="Mean", ylab="Difference", main=v,
#                         silent=FALSE), 
#       silent=TRUE); # plotting might fail in RStudio but be ok when knit
#   d.ba <- bland.altman.stats(d[,1], d[,2]);
#   
#   # Save the results:
#   ba.results[[ length(ba.results)+1 ]] <- data.frame("BA.lower.limit"        =d.ba$lines["lower.limit"], 
#                                                      "BA.lower.limit.CI_low" =d.ba$CI.lines["lower.limit.ci.lower"], 
#                                                      "BA.lower.limit.CI_high"=d.ba$CI.lines["lower.limit.ci.upper"],
#                                                      "BA.mean.diff"          =d.ba$lines["mean.diffs"],  
#                                                      "BA.mean.diff.CI_low"   =d.ba$CI.lines["mean.diff.ci.lower"],   
#                                                      "BA.mean.diff.CI_high"  =d.ba$CI.lines["mean.diff.ci.upper"],
#                                                      "BA.upper.limit"        =d.ba$lines["upper.limit"], 
#                                                      "BA.upper.limit.CI_low" =d.ba$CI.lines["upper.limit.ci.lower"], 
#                                                      "BA.upper.limit.CI_high"=d.ba$CI.lines["upper.limit.ci.upper"]);
# }
# ba.results <- do.call(rbind, ba.results); rownames(ba.results) <- NULL;
# ba.results <- list();
ba.results <- do.call(rbind, lapply(ph_ace$short_name, function(v)
{
  # Get the data in the right format:
  d <- as.matrix(reshape2::dcast(ph_mclean_long, VT_code ~ Rater, value.var=v)[,-1]);

  # Compute the statistics and plot the Bland-Altman-Plot:
  d.ba <- NULL;
  try(d.ba <- bland.altman.plot(d[,1], d[,2], graph.sys="base", conf.int=0.00, 
                                col="skyblue", pch=1, cex=0.75, xlab="Mean", ylab="Difference", main=v,
                                silent=FALSE), 
      silent=TRUE); # plotting might fail in RStudio but be ok when knit
  if( is.null(d.ba) ) d.ba <- bland.altman.stats(d[,1], d[,2]); # plotting failed (probably due to RStudio plotting restrictions); attempt to compute it again
  
  # Save the results:
  return (data.frame("BA.lower.limit"        =d.ba$lines["lower.limit"], 
                     "BA.lower.limit.CI_low" =d.ba$CI.lines["lower.limit.ci.lower"], 
                     "BA.lower.limit.CI_high"=d.ba$CI.lines["lower.limit.ci.upper"],
                     "BA.mean.diff"          =d.ba$lines["mean.diffs"],  
                     "BA.mean.diff.CI_low"   =d.ba$CI.lines["mean.diff.ci.lower"],   
                     "BA.mean.diff.CI_high"  =d.ba$CI.lines["mean.diff.ci.upper"],
                     "BA.upper.limit"        =d.ba$lines["upper.limit"], 
                     "BA.upper.limit.CI_low" =d.ba$CI.lines["upper.limit.ci.lower"], 
                     "BA.upper.limit.CI_high"=d.ba$CI.lines["upper.limit.ci.upper"]));
}));
rownames(ba.results) <- NULL;
par(mfrow=c(1,1));
```

```{r}
if( !all(file.exists("./bland_altman_plots.jpg", "../cache/bland_altman_stats.csv")) ) # cache as this is pretty expensive to do in RStudio
{
  # Plot as low-res JPEG for Rmarkdown + compute stats:
  plots_per_row <- 4;
  jpeg("./bland_altman_plots.jpg", width=plots_per_row*3, height=ceiling(nrow(ph_ace)/plots_per_row)*3, units="in", quality=95, res=150);
  par(mfrow=c(ceiling(nrow(ph_ace)/plots_per_row),plots_per_row));
  ba.results <- do.call(rbind, lapply(ph_ace$short_name, function(v)
  {
    # Get the data in the right format:
    d <- as.matrix(reshape2::dcast(ph_mclean_long, VT_code ~ Rater, value.var=v)[,-1]);
    
    # Compute the statistics and plot the Bland-Altman-Plot:
    d.ba <- NULL;
    try(d.ba <- bland.altman.plot(d[,1], d[,2], graph.sys="base", conf.int=0.00, 
                                  col="skyblue", pch=1, cex=0.75, xlab="Mean", ylab="Difference", main=v,
                                  silent=FALSE), 
        silent=TRUE); # plotting might fail in RStudio but be ok when knit
    if( is.null(d.ba) ) d.ba <- bland.altman.stats(d[,1], d[,2]); # plotting failed (probably due to RStudio plotting restrictions); attempt to compute it again
    
    # Save the results:
    return (data.frame("BA.lower.limit"        =d.ba$lines["lower.limit"], 
                       "BA.lower.limit.CI_low" =d.ba$CI.lines["lower.limit.ci.lower"], 
                       "BA.lower.limit.CI_high"=d.ba$CI.lines["lower.limit.ci.upper"],
                       "BA.mean.diff"          =d.ba$lines["mean.diffs"],  
                       "BA.mean.diff.CI_low"   =d.ba$CI.lines["mean.diff.ci.lower"],   
                       "BA.mean.diff.CI_high"  =d.ba$CI.lines["mean.diff.ci.upper"],
                       "BA.upper.limit"        =d.ba$lines["upper.limit"], 
                       "BA.upper.limit.CI_low" =d.ba$CI.lines["upper.limit.ci.lower"], 
                       "BA.upper.limit.CI_high"=d.ba$CI.lines["upper.limit.ci.upper"]));
  }));
  rownames(ba.results) <- NULL;
  dev.off();
  
  ## Plot as high-res TIFF as well:
  #plots_per_row <- 6;
  #tiff("../figures/bland_altman_plots.tiff", width=plots_per_row*2.5, height=ceiling(nrow(ph_ace)/plots_per_row)*2.5, units="in", compression="lzw", res=300);
  #par(mfrow=c(ceiling(nrow(ph_ace)/plots_per_row),plots_per_row));
  #tmp <- lapply(ph_ace$short_name, function(v)
  #{
  #  # Get the data in the right format:
  #  d <- as.matrix(reshape2::dcast(ph_mclean_long, VT_code ~ Rater, value.var=v)[,-1]);
  #  
  #  # CPlot the Bland-Altman-Plot:
  #  try(bland.altman.plot(d[,1], d[,2], graph.sys="base", conf.int=0.00, 
  #                        col="skyblue", pch=1, cex=0.75, xlab="Mean", ylab="Difference", main=v,
  #                        silent=TRUE), 
  #      silent=TRUE); # plotting might fail in RStudio but be ok when knit
  #  return (NULL);
  #});
  #dev.off();
  
  write.csv(ba.results, file="../cache/bland_altman_stats.csv", );
} else
{
  ba.results <- read.csv("../cache/bland_altman_stats.csv");
}
```

![`r capFig("The Bland–Altman plots for each measure. The x-axis is the mean of the two raters, while the y-axis is the difference between the two raters (here, rater 1 - rater 2). The blue dotted line in the middle is the mean difference, while the two red dotted lines above and below it are the mean difference ± 1.96 SD. Please see text on how to interpret such plots.")`](./bland_altman_plots.jpg)

Of the `r nrow(ba.results)` measures, `r sum(ba.results$BA.mean.diff.CI_low > 0)` have a significantly positive fixed bias (i.e., the 95% CI of the fixed bias is above 0, meaning that rater 1 systematically produced higher values than rater 2), `r sum(ba.results$BA.mean.diff.CI_high < 0)` have a significantly negative fixed bias, and the renaming `r sum(ba.results$BA.mean.diff.CI_low <= 0 & ba.results$BA.mean.diff.CI_high >= 0)` have a non-significant fixed bias. However, even the statistically significant fixed biases are small when compared with the range of the measures.

Inspecting the plots shows that for most measures there seems to be no problematic relationship between mean and difference, for very few measure there are potentially problematic patterns:

- GRPD: the difference seems to be larger at larger means
- PPW2, PPW3, PPW4, PPWC: perfect relationships between mean and difference

Taken together, these suggest that the two raters are indeed very much in agreement for the large majority of the measures.


### By measure

**ICC(C,1):**
```{r}
pander(summary(ph_ace$ICCc1)); cat("SD =",sd(ph_ace$ICCc1,na.rm=TRUE)," IQR =",IQR(ph_ace$ICCc1,na.rm=TRUE),"\n");
```

**Krippendorff's α:**
```{r}
pander(summary(ph_ace$Krippendorff.alpha)); cat("SD =",sd(ph_ace$Krippendorff.alpha,na.rm=TRUE)," IQR =",IQR(ph_ace$Krippendorff.alpha,na.rm=TRUE),"\n");
```

**agr(GSEM):**
```{r}
pander(summary(ph_ace$rreliability)); cat("SD =",sd(ph_ace$rreliability,na.rm=TRUE)," IQR =",IQR(ph_ace$rreliability,na.rm=TRUE),"\n");
```


```{r fig.width=4*4, fig.height=2*4, fig.cap=capFig(paste0("Histograms of Krippendorff's &alpha; (including and excluding the negative values, left and middle plots respectively), of ICC(C,1) in the middle, and of *agr*(GSEM) on the right, as well as the scatterplots of these measures (excluding the 1 extreme negative outlier for Krippendorff's &alpha;). Correlations: Krippendorff's &alpha; x ICC(C,1): Pearson's *r* = ", round((tmp3 <- cor.test(d$Krippendorff.alpha[ d$Krippendorff.alpha >= -1 ], d$ICCc1[ d$Krippendorff.alpha >= -1 ]))$estimate,2), ", *p* = ", sprintf("%.3g",tmp3$p.value), ", Spearman's *&rho;* = ", round((tmp3 <- cor.test(d$Krippendorff.alpha[ d$Krippendorff.alpha >= -1 ], d$ICCc1[ d$Krippendorff.alpha >= -1 ], method="spearman"))$estimate,2), ", *p* = ", sprintf("%.3g",tmp3$p.value), "; ", "Krippendorff's &alpha; x *agr*(GSEM): Pearson's *r* = ", round((tmp3 <- cor.test(d$Krippendorff.alpha[ d$Krippendorff.alpha >= -1 ], d$rreliability[ d$Krippendorff.alpha >= -1 ]))$estimate,2), ", *p* = ", sprintf("%.3g",tmp3$p.value), ", Spearman's *&rho;* = ", round((tmp3 <- cor.test(d$Krippendorff.alpha[ d$Krippendorff.alpha >= -1 ], d$rreliability[ d$Krippendorff.alpha >= -1 ], method="spearman"))$estimate,2), ", *p* = ", sprintf("%.3g",tmp3$p.value), "; ", "ICC(C,1) x *agr*(GSEM): Pearson's *r* = ", round((tmp3 <- cor.test(d$ICCc1[ d$Krippendorff.alpha >= -1 ], d$rreliability[ d$Krippendorff.alpha >= -1 ]))$estimate,2), ", *p* = ", sprintf("%.3g",tmp3$p.value), ", Spearman's *&rho;* = ", round((tmp3 <- cor.test(d$ICCc1[ d$Krippendorff.alpha >= -1 ], d$rreliability[ d$Krippendorff.alpha >= -1 ], method="spearman"))$estimate,2), ", *p* = ", sprintf("%.3g",tmp3$p.value), "."))}
d <- ph_ace;
ph1   <- ggplot(d, aes(x=Krippendorff.alpha)) + geom_histogram(bins=30, color="black", fill="gray") + xlab("Krippendorff's α") + theme(legend.position="none");
ph1a  <- ggplot(d[d$Krippendorff.alpha >= 0,], aes(x=Krippendorff.alpha)) + geom_histogram(bins=30, color="black", fill="gray") + xlab("Krippendorff's α (>=0 only)") + theme(legend.position="none");
ph2   <- ggplot(d, aes(x=ICCc1)) + geom_histogram(bins=30, color="black", fill="gray") + xlab("ICC(C,1)") + theme(legend.position="none");
ph3   <- ggplot(d, aes(x=rreliability)) + geom_histogram(bins=30, color="black", fill="gray") + xlab("agr(GSEM)") + theme(legend.position="none");
scp12 <- ggplot(d, aes(x=ICCc1, y=Krippendorff.alpha)) + geom_point(alpha=0.25) + ylim(-1,NA) + xlab("ICC(C,1)") + ylab("Krippendorff's α (>=0 only)") + geom_smooth(method="lm", color="blue") + geom_smooth(method="loess", color="red") + theme(legend.position="none");
scp13 <- ggplot(d, aes(x=rreliability, y=Krippendorff.alpha)) + geom_point(alpha=0.25) + ylim(-1,NA) + xlab("agr(GSEM)") + ylab("Krippendorff's α (>=0 only)") + geom_smooth(method="lm", color="blue") + geom_smooth(method="loess", color="red") + theme(legend.position="none");
scp23 <- ggplot(d, aes(x=rreliability, y=ICCc1)) + geom_point(alpha=0.25) + ylim(-1,NA) + xlab("agr(GSEM)") + ylab("ICC(C,1)") + geom_smooth(method="lm", color="blue") + geom_smooth(method="loess", color="red") + theme(legend.position="none");
grid.arrange(ph1, ph1a, ph2, ph3, 
             ggplot() + theme_void(), scp12, scp13, scp23, ncol=4); # plot it!
```

```{r fig.width=1*15, fig.height=2*5, fig.cap=capFig("Inter-rater reliability estimates ordered by decreasing ICC(C,1) values (blue triangle), also showing the Krippendorff's &alpha; (red circle) and *agr*(GSEM) as black squares. The plot is split in two for better fit horizontally.")}
d <- ph_ace[ order(ph_ace$ICCc1, decreasing=TRUE), ];
d$short_name <- factor(d$short_name, 
                       levels=unique(d$short_name[ order(d$ICCc1, decreasing=TRUE) ]), 
                       ordered=TRUE);
d_long <- melt(d, id.vars="short_name", measure.vars=c("Krippendorff.alpha", "ICCc1", "rreliability"), variable.name="agreement");
d_long$plot <- rep(c(1,2), each=round(nrow(ph_ace)/2));

p <- lapply(1:2, function(i)
  ggplot(d_long %>% filter(plot==i), aes(x=short_name, y=value, color=agreement, shape=agreement)) + 
    ylim(c(-1,1)) + ylab("Inter-rater agreement") + xlab("Measure") + 
    geom_point(alpha=0.5) + 
    geom_hline(yintercept=0.0, linetype="dotted", color="blue") +
    theme(axis.text.x = element_text(size=10, angle=45, hjust=0.5, vjust=0.5),
          axis.title.x = element_text(size=10),
          axis.text.y = element_text(size=12),
          axis.title.y = element_text(size=10),
          legend.position="none") + 
    scale_color_manual(values=c("Krippendorff.alpha"="red", "ICCc1"="blue", "rreliability"="black")) +
    scale_shape_manual(values=c("Krippendorff.alpha"=16,    "ICCc1"=17,     "rreliability"=15     )) +
    ggtitle(paste0(ifelse(i==1, 
                          paste0("First ", round(nrow(ph_ace)/2)), 
                          paste0("The remaning ", nrow(ph_ace) - round(nrow(ph_ace)/2))),
                   " measures")));
grid.arrange(grobs=p, ncol=1); # plot it!
```
```{r include=FALSE, eval=FALSE}
# Save as image:
tiff("../figures/inter_rater_agreement.tiff", width=1*15, height=2*5, units="in", res=600, compression="lzw");
grid.arrange(grobs=p, ncol=1);
dev.off();
```

```{r}
knitr::kable(ph_ace[,c("short_name", "ICCc1", "rreliability", "Krippendorff.alpha")] %>% arrange(desc(ICCc1), desc(rreliability), desc(Krippendorff.alpha)), 
             row.names=FALSE,
             col.names=c("measure", "ICC(C,1)", "*agr*(GSEM)", "Krippendorff's α"), 
             digits=2,
             caption=capTab("The measures ordered by decreasing ICC(C,1), *agr*(GSEM), and Krippendorff's &alpha;.")) %>%
  kable_styling(); 
```

It can be seen that while the three measures of agreement tend to roughly agree, *Krippendorff's &alpha;* has some undesirable properties on our data in the sense that:

  a) there is one extreme negative outlier (`r ph_ace$short_name[ which(ph_ace$Krippendorff.alpha < -1) ]` with *&alpha;* = `r round(ph_ace$Krippendorff.alpha[ which(ph_ace$Krippendorff.alpha < -1) ],2)`),
  b) there are `r sum(is.na(ph_ace$Krippendorff.alpha))` measures where the estimate is missing (`NaN`), and
  c) there are several measures where *&alpha;* is at (or very close to) the ceiling of 1.0, while *ICC*(*C*,1) and *agr*(GSEM) have much less extreme values (see the scatter plots above).
  
Moreover,  *ICC*(*C*,1) and *agr*(GSEM) are basically perfectly correlated, but while *ICC*(*C*,1) is a much more general measure of inter-rater agreement, *agr*(GSEM) is specific to our model (which means that it might better account for its particularities).

Focusing on those measure that have different estimates for *ICC*(*C*,1) and *agr*(GSEM), we first computed the "raw" difference Δ agreement = (ICC(C,1) - *agr*(GSEM)) and estimated which of these differences are significant (by comparing the 95% CIs of *ICC*(*C*,1) and *agr*(GSEM)), as shown in the table below:

```{r}
d.agr.diffs <- ph_ace;
d.agr.diffs$rreliability_CiL[ is.na(d.agr.diffs$rreliability_CiL) ] <- 0.0; # fix those missing 95CIs to avoid NA comparisons
d.agr.diffs <- cbind(d.agr.diffs,
                     "agr.diff"=(d.agr.diffs$ICCc1 - d.agr.diffs$rreliability),
                     "agr.diff.signif"=((d.agr.diffs$ICCc1.CI_low > d.agr.diffs$rreliability_CiH) | (d.agr.diffs$ICCc1.CI_high < d.agr.diffs$rreliability_CiL)));
d.agr.diffs$ICCc1.CI        <- sprintf("(%.2f, %.2f)", d.agr.diffs$ICCc1.CI_low, d.agr.diffs$ICCc1.CI_high);
d.agr.diffs$rreliability.CI <- sprintf("(%.2f, %.2f)", d.agr.diffs$rreliability_CiL, d.agr.diffs$rreliability_CiH);
#d.agr.diffs <- d.agr.diffs[order(!d.agr.diffs$agr.diff.signif, -abs(d.agr.diffs$agr.diff)),];

knitr::kable(d.agr.diffs[,c("short_name", "ICCc1", "ICCc1.CI", "rreliability", "rreliability.CI", "agr.diff", "agr.diff.signif")] %>% 
               arrange(desc(agr.diff.signif), desc(agr.diff)), 
             row.names=FALSE,
             col.names=c("measure", "ICC(C,1)", "95% CI", "*agr*(GSEM)", "95% CI", "Δ agreement", "Significant?"), 
             digits=2,
             caption=capTab("The measures ordered by Δ agreement = (ICC(C,1) - *agr*(GSEM)) and its significance (judged by comparing the 95%CIs of ICC(C,1) and *agr*(GSEM)).")) %>%
  kable_styling(); 
```

```{r results='hide'}
# Regressions of the two inter-rater agreements on each other:
reg.icc.agr <- lm(ICCc1 ~ rreliability, data=d.agr.diffs);
reg.agr.icc <- lm(rreliability ~ ICCc1, data=d.agr.diffs);
```

However, this tends to overestimate the number of disagreements if the two estimates of inter-rater agreement are highly correlated but systematically different (i.e., if there is a linear relationship between them with a non-zero intercept). 
Thus, we regressed linearly the one on the other (i.e., we performed two linear regressions, once *ICC*(*C*,1) on *agr*(GSEM), and separately *agr*(GSEM) on *ICC*(*C*,1)) and we obtained that both are highly significant, with a very high adjusted R^2^ = `r round(100*summary(reg.icc.agr)$adj.r.squared,1)`%, intercepts *&alpha;*=`r sprintf("%.2f (*p*=%.3g)", summary(reg.icc.agr)$coefficients["(Intercept)","Estimate"], summary(reg.icc.agr)$coefficients["(Intercept)","Pr(>|t|)"])` and `r sprintf("%.2f (*p*=%.3g)", summary(reg.agr.icc)$coefficients["(Intercept)","Estimate"], summary(reg.agr.icc)$coefficients["(Intercept)","Pr(>|t|)"])`, and slopes `r sprintf("%.2f (*p*=%.3g)", summary(reg.icc.agr)$coefficients["rreliability","Estimate"], summary(reg.icc.agr)$coefficients["rreliability","Pr(>|t|)"])` and `r sprintf("%.2f (*p*=%.3g)", summary(reg.agr.icc)$coefficients["ICCc1","Estimate"], summary(reg.agr.icc)$coefficients["ICCc1","Pr(>|t|)"])`, respectively, strongly suggesting an almost perfect identity relationship between them.

***ICC*(*C*,1) on *agr*(GSEM):**
```{r fig.width=2*5, fig.height=2*5, fig.cap=capFig("Outliers and influential observations for the linear regression of ICC(C,1) on *agr*(GSEM). Showing the top 10.")}
pander(summary(reg.icc.agr));
par(mfrow=c(2,2)); plot(reg.icc.agr, ask=FALSE, id.n=10, cex.id=0.5); par(mfrow=c(1,1));
#outlierTest(reg.icc.agr); # outliers
```

***agr*(GSEM) on *ICC*(*C*,1):**
```{r fig.width=2*5, fig.height=2*5, fig.cap=capFig("Outliers and influential observations for the linear regression of *agr*(GSEM) on ICC(C,1). Showing the top 10.")}
pander(summary(reg.agr.icc));
par(mfrow=c(2,2)); plot(reg.agr.icc, ask=FALSE, id.n=10, cex.id=0.5); par(mfrow=c(1,1));
#outlierTest(reg.agr.icc); # outliers
```

The only possible outlier (as identified by `outlierTest()`) is `r d.agr.diffs$short_name[145]`.

Given all these, it seems *ICC(C,1)* and *agr*(GSEM) are the best measures of agreement for us, and are virtually identical.

### By domain

Including ANOVA and the significant pair-wise differences after Tukey's HSD:

```{r fig.width=1*10, fig.height=3*5, fig.cap=capFig("Inter-rater agreements by domain.")}
d$domain <- reorder(d$domain, d$Krippendorff.alpha, function(x) -median(x,na.rm=TRUE));
pd1 <- ggplot(d, aes(x=domain, y=Krippendorff.alpha, color=domain)) + ylim(c(-1,1)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(size=12, angle=45, hjust=0.5, vjust=0.5)) + 
  ggtitle("Krippendorff's α by domain (ordered by median)");
d$domain <- reorder(d$domain, d$ICCc1, function(x) -median(x,na.rm=TRUE));
pd2 <- ggplot(d, aes(x=domain, y=ICCc1, color=domain)) + ylim(c(-1,1)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(size=12, angle=45, hjust=0.5, vjust=0.5)) + 
  ggtitle("ICC(C,1) by domain (ordered by median)");
d$domain <- reorder(d$domain, d$rreliability, function(x) -median(x,na.rm=TRUE));
pd3 <- ggplot(d, aes(x=domain, y=rreliability, color=domain)) + ylim(c(-1,1)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(size=12, angle=45, hjust=0.5, vjust=0.5)) + 
  ggtitle("agr(GSEM) by domain (ordered by median)");
grid.arrange(pd1, pd2, pd3, ncol=1);
```

#### Krippendorff's α
```{r }
a1 <- aov(Krippendorff.alpha ~ domain, data=d);
pander::pander(summary(a1)); 
```
```{r }
t1 <- TukeyHSD(a1); colnames(t1$domain)[4] <- "p.adj"; thsd <- t1$domain[ t1$domain[,"p.adj"] < 0.05, , drop=FALSE];
if( nrow(thsd) > 0 )
  knitr::kable(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE], row.names=TRUE, digits=c(2, 2, 2, 5),
               caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>%
  kable_styling();
```

#### ICC(C,1)
```{r }
a2 <- aov(ICCc1 ~ domain, data=d);
pander::pander(summary(a2)); 
```
```{r }
t2 <- TukeyHSD(a2); colnames(t2$domain)[4] <- "p.adj"; thsd <- t2$domain[ t2$domain[,"p.adj"] < 0.05, , drop=FALSE];
if( nrow(thsd) > 0 )
  knitr::kable(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE], row.names=TRUE, digits=c(2, 2, 2, 5),
               caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>%
  kable_styling();
```

#### agr(GSEM)
```{r }
a3 <- aov(rreliability ~ domain, data=d);
pander::pander(summary(a3)); 
```
```{r }
t3 <- TukeyHSD(a3); colnames(t3$domain)[4] <- "p.adj"; thsd <- t3$domain[ t3$domain[,"p.adj"] < 0.05, , drop=FALSE];
if( nrow(thsd) > 0 )
  knitr::kable(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE], row.names=TRUE, digits=c(2, 2, 2, 5),
               caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>%
  kable_styling();
```


### By type

Including ANOVA and the significant pair-wise differences after Tukey's HSD:

```{r fig.width=1*10, fig.height=3*5, fig.cap=capFig("Inter-rater agreement by type.")}
d$type <- reorder(d$type, d$Krippendorff.alpha, function(x) -median(x,na.rm=TRUE));
pt1 <- ggplot(d, aes(x=type, y=Krippendorff.alpha, color=type)) + ylim(c(-1,1)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(size=12, angle=45, hjust=0.5, vjust=0.5)) + 
  ggtitle("Krippendorff's α by type (ordered by median)");
d$type <- reorder(d$type, d$ICCc1, function(x) -median(x,na.rm=TRUE));
pt2 <- ggplot(d, aes(x=type, y=ICCc1, color=type)) + ylim(c(-1,1)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(size=12, angle=45, hjust=0.5, vjust=0.5)) + 
  ggtitle("ICC(C,1) by type (ordered by median)");
d$type <- reorder(d$type, d$rreliability, function(x) -median(x,na.rm=TRUE));
pt3 <- ggplot(d, aes(x=type, y=rreliability, color=type)) + ylim(c(-1,1)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(size=12, angle=45, hjust=0.5, vjust=0.5)) + 
  ggtitle("agr(GSEM) by type (ordered by median)");
grid.arrange(pt1, pt2, pt3, ncol=1);
```

#### Krippendorff's α
```{r }
a1 <- aov(Krippendorff.alpha ~ type, data=d);
pander::pander(summary(a1)); 
```
```{r }
t1 <- TukeyHSD(a1); colnames(t1$type)[4] <- "p.adj"; thsd <- t1$type[ t1$type[,"p.adj"] < 0.05, , drop=FALSE];
if( nrow(thsd) > 0 )
  knitr::kable(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE], row.names=TRUE, digits=c(2, 2, 2, 5),
               caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>%
  kable_styling();
```

#### ICC(C,1)
```{r }
a2 <- aov(ICCc1 ~ type, data=d);
pander::pander(summary(a2)); 
```
```{r }
t2 <- TukeyHSD(a2); colnames(t2$type)[4] <- "p.adj"; thsd <- t2$type[ t2$type[,"p.adj"] < 0.05, , drop=FALSE];
if( nrow(thsd) > 0 )
  knitr::kable(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE], row.names=TRUE, digits=c(2, 2, 2, 5),
               caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>%
  kable_styling();
```

#### agr(GSEM)
```{r }
a3 <- aov(rreliability ~ type, data=d);
pander::pander(summary(a3)); 
```
```{r }
t3 <- TukeyHSD(a3); colnames(t3$type)[4] <- "p.adj"; thsd <- t3$type[ t3$type[,"p.adj"] < 0.05, , drop=FALSE];
if( nrow(thsd) > 0 )
  knitr::kable(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE], row.names=TRUE, digits=c(2, 2, 2, 5),
               caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>%
  kable_styling();
```


```{r include=FALSE}
# Save as image:

# As TIFF:
tiff("../figures/figure_S01.tiff", width=2*4, height=1*4, units="in", res=600, compression="lzw");

d$domain <- reorder(d$domain, d$ICCc1, function(x) -median(x,na.rm=TRUE));
pd2 <- ggplot(d, aes(x=domain, y=ICCc1)) + ylim(c(0,1)) + 
  geom_boxplot(color="black") + geom_point(alpha=0.5, color="gray50") +
  theme(axis.text.x = element_text(size=12, angle=45, hjust=0.5, vjust=0.5));

d$type <- reorder(d$type, d$ICCc1, function(x) -median(x,na.rm=TRUE));
pt2 <- ggplot(d, aes(x=type, y=ICCc1)) + ylim(c(0,1)) + 
  geom_boxplot(color="black") + geom_point(alpha=0.5, color="gray50") +
  theme(axis.text.x = element_text(size=12, angle=45, hjust=0.5, vjust=0.5));

grid.arrange(pd2 +
               theme_bw() + coord_flip() +
               theme(axis.text.x = element_text(size=10, angle=45, hjust=0.5, vjust=0.5),
                     axis.title.x = element_text(size=12),
                     axis.text.y = element_text(size=10),
                     axis.title.y = element_text(size=12),
                     legend.text = element_text(size = 12),
                     legend.title = element_text(size = 12),
                     legend.position="none",
                     title = element_text(size = 13)) + 
               ggtitle(expression(italic("ICC")*"("*italic("C")*",1) by "*italic("domain"))) + labs(y=expression(italic("ICC")*"("*italic("C")*",1)")),
             pt2 + 
               theme_bw() + coord_flip() +
               theme(axis.text.x = element_text(size=10, angle=45, hjust=0.5, vjust=0.5),
                     axis.title.x = element_text(size=12),
                     axis.text.y = element_text(size=10),
                     axis.title.y = element_text(size=12),
                     legend.text = element_text(size = 12),
                     legend.title = element_text(size = 12),
                     legend.position="none",
                     title = element_text(size = 13)) + 
               ggtitle(expression(italic("ICC")*"("*italic("C")*",1) by "*italic("type"))) + labs(y=expression(italic("ICC")*"("*italic("C")*",1)")),
             ncol=2);

dev.off();

# ... and as JPG:
jpeg("../figures/figure_S01.jpg", width=2*4, height=1*4, units="in", res=150, quality=85);

d$domain <- reorder(d$domain, d$ICCc1, function(x) -median(x,na.rm=TRUE));
pd2 <- ggplot(d, aes(x=domain, y=ICCc1)) + ylim(c(0,1)) + 
  geom_boxplot(color="black") + geom_point(alpha=0.5, color="gray50") +
  theme(axis.text.x = element_text(size=12, angle=45, hjust=0.5, vjust=0.5));

d$type <- reorder(d$type, d$ICCc1, function(x) -median(x,na.rm=TRUE));
pt2 <- ggplot(d, aes(x=type, y=ICCc1)) + ylim(c(0,1)) + 
  geom_boxplot(color="black") + geom_point(alpha=0.5, color="gray50") +
  theme(axis.text.x = element_text(size=12, angle=45, hjust=0.5, vjust=0.5));

grid.arrange(pd2 +
               theme_bw() + coord_flip() +
               theme(axis.text.x = element_text(size=10, angle=45, hjust=0.5, vjust=0.5),
                     axis.title.x = element_text(size=12),
                     axis.text.y = element_text(size=10),
                     axis.title.y = element_text(size=12),
                     legend.text = element_text(size = 12),
                     legend.title = element_text(size = 12),
                     legend.position="none",
                     title = element_text(size = 13)) + 
               ggtitle(expression(italic("ICC")*"("*italic("C")*",1) by "*italic("domain"))) + labs(y=expression(italic("ICC")*"("*italic("C")*",1)")),
             pt2 + 
               theme_bw() + coord_flip() +
               theme(axis.text.x = element_text(size=10, angle=45, hjust=0.5, vjust=0.5),
                     axis.title.x = element_text(size=12),
                     axis.text.y = element_text(size=10),
                     axis.title.y = element_text(size=12),
                     legend.text = element_text(size = 12),
                     legend.title = element_text(size = 12),
                     legend.position="none",
                     title = element_text(size = 13)) + 
               ggtitle(expression(italic("ICC")*"("*italic("C")*",1) by "*italic("type"))) + labs(y=expression(italic("ICC")*"("*italic("C")*",1)")),
             ncol=2);

dev.off();
```


### Versus twin correlations

#### "Raw" twin correlations

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=3*4, fig.height=4, fig.cap=capFig("Inter-rater agreement vs raw twin correlations.")}
# used as a guide for correlation size interpretation: https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/11-correlation-and-regression
d <- ph_ace;

par(mfrow=c(1,3));

plot(d$ICCc1, d$rMZ, pch=1, col="red", xlab="ICC(C,1)", ylab="Twin correlation", xlim=c(-1,1), ylim=c(-1,1), main="ICC(C,1) using all twin pairs");
points(d$ICCc1, d$rDZ, pch=2, col="blue");
abline(lm(rMZ ~ ICCc1, data=d), lty="solid", lwd=1, col="red");
abline(lm(rDZ ~ ICCc1, data=d), lty="solid", lwd=1, col="blue");
rMZ <- cor.test(d$ICCc1, d$rMZ); rDZ <- cor.test(d$ICCc1, d$rDZ);
legend("bottomleft", legend=c(paste0("MZ (r=",sprintf("%.2f",rMZ$estimate),", p=",sprintf("%.3g",rMZ$p.value),")"),
                              paste0("DZ (r=",sprintf("%.2f",rDZ$estimate),", p=",sprintf("%.3g",rDZ$p.value),")")), 
       col=c("red", "blue"), pch=c(1,2), pt.cex=2, bty="n");

plot(d$rreliability, d$rMZ, pch=1, col="red", xlab="agr(GSEM)", ylab="Twin correlation", xlim=c(-1,1), ylim=c(-1,1), main="agr(GSEM) using all twin pairs");
points(d$rreliability, d$rDZ, pch=2, col="blue");
abline(lm(rMZ ~ rreliability, data=d), lty="solid", lwd=1, col="red");
abline(lm(rDZ ~ rreliability, data=d), lty="solid", lwd=1, col="blue");
rMZ <- cor.test(d$rreliability, d$rMZ); rDZ <- cor.test(d$rreliability, d$rDZ);
legend("bottomleft", legend=c(paste0("MZ (r=",sprintf("%.2f",rMZ$estimate),", p=",sprintf("%.3g",rMZ$p.value),")"),
                              paste0("DZ (r=",sprintf("%.2f",rDZ$estimate),", p=",sprintf("%.3g",rDZ$p.value),")")), 
       col=c("red", "blue"), pch=c(1,2), pt.cex=2, bty="n");

plot(d$Krippendorff.alpha, d$rMZ, pch=1, col="red", xlab="Krippendorff's α", ylab="Twin correlation", xlim=c(-1,1), ylim=c(-1,1), main="Krippendorff's α using all twin pairs");
points(d$Krippendorff.alpha, d$rDZ, pch=2, col="blue");
abline(lm(rMZ ~ Krippendorff.alpha, data=d), lty="solid", lwd=1, col="red");
abline(lm(rDZ ~ Krippendorff.alpha, data=d), lty="solid", lwd=1, col="blue");
rMZ <- cor.test(d$Krippendorff.alpha, d$rMZ); rDZ <- cor.test(d$Krippendorff.alpha, d$rDZ);
legend("bottomleft", legend=c(paste0("MZ (r=",sprintf("%.2f",rMZ$estimate),", p=",sprintf("%.3g",rMZ$p.value),")"),
                              paste0("DZ (r=",sprintf("%.2f",rDZ$estimate),", p=",sprintf("%.3g",rDZ$p.value),")")), 
       col=c("red", "blue"), pch=c(1,2), pt.cex=2, bty="n");

par(mfrow=c(1,1));
```

#### Corrected twin correlations

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=3*4, fig.height=4, fig.cap=capFig("Inter-rater agreement vs corrected twin correlations.")}
# used as a guide for correlation size interpretation: https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/11-correlation-and-regression
par(mfrow=c(1,3));

plot(d$ICCc1, d$twin_corr_rMZ, pch=1, col="red", xlab="ICC(C,1)", ylab="Twin correlation", xlim=c(-1,1), ylim=c(-1,1), main="ICC(C,1) using all twin pairs");
points(d$ICCc1, d$twin_corr_rDZ, pch=2, col="blue");
abline(lm(twin_corr_rMZ ~ ICCc1, data=d), lty="solid", lwd=1, col="red");
abline(lm(twin_corr_rDZ ~ ICCc1, data=d), lty="solid", lwd=1, col="blue");
rMZ <- cor.test(d$ICCc1, d$twin_corr_rMZ); rDZ <- cor.test(d$ICCc1, d$twin_corr_rDZ);
legend("bottomleft", legend=c(paste0("MZ (r=",sprintf("%.2f",rMZ$estimate),", p=",sprintf("%.3g",rMZ$p.value),")"),
                              paste0("DZ (r=",sprintf("%.2f",rDZ$estimate),", p=",sprintf("%.3g",rDZ$p.value),")")), 
       col=c("red", "blue"), pch=c(1,2), pt.cex=2, bty="n");

plot(d$rreliability, d$twin_corr_rMZ, pch=1, col="red", xlab="agr(GSEM)", ylab="Twin correlation", xlim=c(-1,1), ylim=c(-1,1), main="agr(GSEM) using all twin pairs");
points(d$rreliability, d$twin_corr_rDZ, pch=2, col="blue");
abline(lm(twin_corr_rMZ ~ rreliability, data=d), lty="solid", lwd=1, col="red");
abline(lm(twin_corr_rDZ ~ rreliability, data=d), lty="solid", lwd=1, col="blue");
rMZ <- cor.test(d$rreliability, d$twin_corr_rMZ); rDZ <- cor.test(d$rreliability, d$twin_corr_rDZ);
legend("bottomleft", legend=c(paste0("MZ (r=",sprintf("%.2f",rMZ$estimate),", p=",sprintf("%.3g",rMZ$p.value),")"),
                              paste0("DZ (r=",sprintf("%.2f",rDZ$estimate),", p=",sprintf("%.3g",rDZ$p.value),")")), 
       col=c("red", "blue"), pch=c(1,2), pt.cex=2, bty="n");

plot(d$Krippendorff.alpha, d$twin_corr_rMZ, pch=1, col="red", xlab="Krippendorff's α", ylab="Twin correlation", xlim=c(-1,1), ylim=c(-1,1), main="Krippendorff's α using all twin pairs");
points(d$Krippendorff.alpha, d$twin_corr_rDZ, pch=2, col="blue");
abline(lm(twin_corr_rMZ ~ Krippendorff.alpha, data=d), lty="solid", lwd=1, col="red");
abline(lm(twin_corr_rDZ ~ Krippendorff.alpha, data=d), lty="solid", lwd=1, col="blue");
rMZ <- cor.test(d$Krippendorff.alpha, d$twin_corr_rMZ); rDZ <- cor.test(d$Krippendorff.alpha, d$twin_corr_rDZ);
legend("bottomleft", legend=c(paste0("MZ (r=",sprintf("%.2f",rMZ$estimate),", p=",sprintf("%.3g",rMZ$p.value),")"),
                              paste0("DZ (r=",sprintf("%.2f",rDZ$estimate),", p=",sprintf("%.3g",rDZ$p.value),")")), 
       col=c("red", "blue"), pch=c(1,2), pt.cex=2, bty="n");

par(mfrow=c(1,1));
```


### Versus best model selected

Including ANOVA and the significant pair-wise differences after Tukey's HSD:

```{r fig.width=2*5, fig.height=1*5, fig.cap=capFig("Inter-rater agreement by the best genetic model selected.")}
d <- ph_ace;

d$genetic_model <- reorder(d$genetic_model, d$Krippendorff.alpha, function(x) -median(x,na.rm=TRUE));
pm1 <- ggplot(d, aes(x=genetic_model, y=Krippendorff.alpha, color=genetic_model)) + ylim(c(-1,1)) + ylab("Krippendorff's α") +
  geom_boxplot() +
  theme(axis.text.x = element_text(size=8, angle=45, hjust=0.5, vjust=0.5)) + 
  ggtitle("Krippendorff's α by model (ordered by median)");

d$genetic_model <- reorder(d$genetic_model, d$ICCc1, function(x) -median(x,na.rm=TRUE));
pm2 <- ggplot(d, aes(x=genetic_model, y=ICCc1, color=genetic_model)) + ylim(c(-1,1)) + ylab("ICC(C,1)") +
  geom_boxplot() +
  theme(axis.text.x = element_text(size=8, angle=45, hjust=0.5, vjust=0.5)) + 
  ggtitle("ICC(C,1) by model (ordered by median)");

d$genetic_model <- reorder(d$genetic_model, d$rreliability, function(x) -median(x,na.rm=TRUE));
pm3 <- ggplot(d, aes(x=genetic_model, y=rreliability, color=genetic_model)) + ylim(c(-1,1)) + ylab("agr(GSEM)") +
  geom_boxplot() +
  theme(axis.text.x = element_text(size=8, angle=45, hjust=0.5, vjust=0.5)) + 
  ggtitle("agr(GSEM) by model (ordered by median)");

grid.arrange(pm1, pm2, pm3, nrow=1);
```

#### Krippendorff's α
```{r }
a1 <- aov(Krippendorff.alpha ~ genetic_model, data=d);
pander::pander(summary(a1)); 
```
```{r }
t1 <- TukeyHSD(a1); colnames(t1$genetic_model)[4] <- "p.adj"; thsd <- t1$genetic_model[ t1$genetic_model[,"p.adj"] < 0.05, , drop=FALSE];
if( nrow(thsd) > 0 )
  knitr::kable(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE], row.names=TRUE, digits=c(2, 2, 2, 5),
               caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>%
  kable_styling();
```

#### ICC(C,1)
```{r }
a2 <- aov(ICCc1 ~ genetic_model, data=d);
pander::pander(summary(a2)); 
```
```{r }
t2 <- TukeyHSD(a2); colnames(t2$genetic_model)[4] <- "p.adj"; thsd <- t2$genetic_model[ t2$genetic_model[,"p.adj"] < 0.05, , drop=FALSE];
if( nrow(thsd) > 0 )
  knitr::kable(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE], row.names=TRUE, digits=c(2, 2, 2, 5),
               caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>%
  kable_styling();
```

#### agr(GSEM)
```{r }
a3 <- aov(rreliability ~ genetic_model, data=d);
pander::pander(summary(a3)); 
```
```{r }
t3 <- TukeyHSD(a3); colnames(t3$genetic_model)[4] <- "p.adj"; thsd <- t3$genetic_model[ t3$genetic_model[,"p.adj"] < 0.05, , drop=FALSE];
if( nrow(thsd) > 0 )
  knitr::kable(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE], row.names=TRUE, digits=c(2, 2, 2, 5),
               caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>%
  kable_styling();
```


### Versus *A*, *C* or *D*, and *E* estimates

```{r fig.width=3*4, fig.height=1*4, fig.cap=capFig("Inter-rater agreement vs *A*, *C* or *D*, and *E* estimates. Showing the Pearson's correlations and linear regression lines (solid if the corresponding correlation is significant, dotted otherwise).")}
d <- ph_ace;

par(mfrow=c(1,3));

plot(d$A, d$ICCc1, pch=1, col="red", ylab="ICC", xlab="component estimate", xlim=c(-1,1), ylim=c(0,1), main="ICC(C,1) using all twin pairs");
points(d$CD, d$ICCc1, pch=ifelse(d$CD_meaning == "C", 2, 3), col=ifelse(d$CD_meaning == "C", "blue", "black"));
points(d$E, d$ICCc1, pch=4, col="gray");
rA <- cor.test(d$ICCc1, d$A); 
rC <- cor.test(d[d$CD_meaning == "C",]$ICCc1, d[d$CD_meaning == "C",]$CD); 
rD <- cor.test(d[d$CD_meaning == "D",]$ICCc1, d[d$CD_meaning == "D",]$CD); 
rE <- cor.test(d$ICCc1, d$E);
abline(lm(ICCc1 ~ A, data=d), lty=ifelse(rA$p.value<0.05,"solid","dotted"), lwd=1, col="red");
abline(lm(ICCc1 ~ CD, data=d[d$CD_meaning == "C",]), lty=ifelse(rC$p.value<0.05,"solid","dotted"), lwd=1, col="blue");
abline(lm(ICCc1 ~ CD, data=d[d$CD_meaning == "D",]), lty=ifelse(rD$p.value<0.05,"solid","dotted"), lwd=1, col="black");
abline(lm(ICCc1 ~ E, data=d), lty=ifelse(rE$p.value<0.05,"solid","dotted"), lwd=1, col="gray");
legend("topleft", legend=c(paste0("A (r=",sprintf("%.2f",rA$estimate),", p=",sprintf("%.3g",rA$p.value),")"),
                           paste0("C (r=",sprintf("%.2f",rC$estimate),", p=",sprintf("%.3g",rC$p.value),")"),
                           paste0("D (r=",sprintf("%.2f",rD$estimate),", p=",sprintf("%.3g",rD$p.value),")"),
                           paste0("E (r=",sprintf("%.2f",rE$estimate),", p=",sprintf("%.3g",rE$p.value),")")), 
       col=c("red", "blue", "black", "gray"), pch=c(1,2, 3,4), pt.cex=2, bty="n");

plot(d$A, d$rreliability, pch=1, col="red", ylab="agr(GSEM)", xlab="component estimate", xlim=c(-1,1), ylim=c(0,1), main="agr(GSEM) using all twin pairs");
points(d$CD, d$rreliability, pch=ifelse(d$CD_meaning == "C", 2, 3), col=ifelse(d$CD_meaning == "C", "blue", "black"));
points(d$E, d$rreliability, pch=4, col="gray");
rA <- cor.test(d$rreliability, d$A); 
rC <- cor.test(d[d$CD_meaning == "C",]$rreliability, d[d$CD_meaning == "C",]$CD); 
rD <- cor.test(d[d$CD_meaning == "D",]$rreliability, d[d$CD_meaning == "D",]$CD); 
rE <- cor.test(d$rreliability, d$E);
abline(lm(rreliability ~ A, data=d), lty=ifelse(rA$p.value<0.05,"solid","dotted"), lwd=1, col="red");
abline(lm(rreliability ~ CD, data=d[d$CD_meaning == "C",]), lty=ifelse(rC$p.value<0.05,"solid","dotted"), lwd=1, col="blue");
abline(lm(rreliability ~ CD, data=d[d$CD_meaning == "D",]), lty=ifelse(rD$p.value<0.05,"solid","dotted"), lwd=1, col="black");
abline(lm(rreliability ~ E, data=d), lty=ifelse(rE$p.value<0.05,"solid","dotted"), lwd=1, col="gray");
legend("topleft", legend=c(paste0("A (r=",sprintf("%.2f",rA$estimate),", p=",sprintf("%.3g",rA$p.value),")"),
                           paste0("C (r=",sprintf("%.2f",rC$estimate),", p=",sprintf("%.3g",rC$p.value),")"),
                           paste0("D (r=",sprintf("%.2f",rD$estimate),", p=",sprintf("%.3g",rD$p.value),")"),
                           paste0("E (r=",sprintf("%.2f",rE$estimate),", p=",sprintf("%.3g",rE$p.value),")")), 
       col=c("red", "blue", "black", "gray"), pch=c(1,2, 3,4), pt.cex=2, bty="n");

plot(d$A, d$Krippendorff.alpha, pch=1, col="red", ylab="Krippendorff's α", xlab="component estimate", xlim=c(-1,1), ylim=c(0,1), main="Krippendorff's α using all twin pairs");
points(d$CD, d$Krippendorff.alpha, pch=ifelse(d$CD_meaning == "C", 2, 3), col=ifelse(d$CD_meaning == "C", "blue", "black"));
points(d$E, d$Krippendorff.alpha, pch=4, col="gray");
rA <- cor.test(d$Krippendorff.alpha, d$A); 
rC <- cor.test(d[d$CD_meaning == "C",]$Krippendorff.alpha, d[d$CD_meaning == "C",]$CD); 
rD <- cor.test(d[d$CD_meaning == "D",]$Krippendorff.alpha, d[d$CD_meaning == "D",]$CD); 
rE <- cor.test(d$Krippendorff.alpha, d$E);
abline(lm(Krippendorff.alpha ~ A, data=d), lty=ifelse(rA$p.value<0.05,"solid","dotted"), lwd=1, col="red");
abline(lm(Krippendorff.alpha ~ CD, data=d[d$CD_meaning == "C",]), lty=ifelse(rC$p.value<0.05,"solid","dotted"), lwd=1, col="blue");
abline(lm(Krippendorff.alpha ~ CD, data=d[d$CD_meaning == "D",]), lty=ifelse(rD$p.value<0.05,"solid","dotted"), lwd=1, col="black");
abline(lm(Krippendorff.alpha ~ E, data=d), lty=ifelse(rE$p.value<0.05,"solid","dotted"), lwd=1, col="gray");
legend("topleft", legend=c(paste0("A (r=",sprintf("%.2f",rA$estimate),", p=",sprintf("%.3g",rA$p.value),")"),
                           paste0("C (r=",sprintf("%.2f",rC$estimate),", p=",sprintf("%.3g",rC$p.value),")"),
                           paste0("D (r=",sprintf("%.2f",rD$estimate),", p=",sprintf("%.3g",rD$p.value),")"),
                           paste0("E (r=",sprintf("%.2f",rE$estimate),", p=",sprintf("%.3g",rE$p.value),")")), 
       col=c("red", "blue", "black", "gray"), pch=c(1,2, 3,4), pt.cex=2, bty="n");

par(mfrow=c(1,1));
```


### Versus narrow-sense heritability (*h*^2^), broad-sense heritability (*H*^2^) or familiality (*F*^2^), and environmental variance (*e*^2^)

```{r fig.width=3*4, fig.height=1*4, fig.cap=capFig("Inter-rater agreement vs *h*^2^, *H*^2^ or *F*^2^, and *e*^2^ estimates. Showing the Pearson's correlations and linear regression lines (solid if the corresponding correlation is significant, dotted otherwise).")}
d <- ph_ace;

par(mfrow=c(1,3));

plot(d$h2, d$ICCc1, pch=1, col="red", ylab="ICC", xlab="component estimate", xlim=c(-1,1), ylim=c(0,1), main="ICC(C,1) using all twin pairs");
points(d$H2, d$ICCc1, pch=ifelse(d$CD_meaning == "C", 2, 3), col=ifelse(d$CD_meaning == "C", "blue", "black"));
points(d$e2, d$ICCc1, pch=4, col="gray");
rA <- cor.test(d$ICCc1, d$h2); 
rC <- cor.test(d[d$CD_meaning == "C",]$ICCc1, d[d$CD_meaning == "C",]$H2); 
rD <- cor.test(d[d$CD_meaning == "D",]$ICCc1, d[d$CD_meaning == "D",]$H2); 
rE <- cor.test(d$ICCc1, d$e2);
abline(lm(ICCc1 ~ h2, data=d), lty=ifelse(rA$p.value<0.05,"solid","dotted"), lwd=1, col="red");
abline(lm(ICCc1 ~ H2, data=d[d$CD_meaning == "C",]), lty=ifelse(rC$p.value<0.05,"solid","dotted"), lwd=1, col="blue");
abline(lm(ICCc1 ~ H2, data=d[d$CD_meaning == "D",]), lty=ifelse(rD$p.value<0.05,"solid","dotted"), lwd=1, col="black");
abline(lm(ICCc1 ~ e2, data=d), lty=ifelse(rE$p.value<0.05,"solid","dotted"), lwd=1, col="gray");
legend("topleft", legend=c(paste0("h (r=",sprintf("%.2f",rA$estimate),", p=",sprintf("%.3g",rA$p.value),")"),
                           paste0("H (r=",sprintf("%.2f",rC$estimate),", p=",sprintf("%.3g",rC$p.value),")"),
                           paste0("F (r=",sprintf("%.2f",rD$estimate),", p=",sprintf("%.3g",rD$p.value),")"),
                           paste0("e (r=",sprintf("%.2f",rE$estimate),", p=",sprintf("%.3g",rE$p.value),")")), 
       col=c("red", "blue", "black", "gray"), pch=c(1,2, 3,4), pt.cex=2, bty="n");

plot(d$h2, d$rreliability, pch=1, col="red", ylab="agr(GSEM)", xlab="component estimate", xlim=c(-1,1), ylim=c(0,1), main="agr(GSEM) using all twin pairs");
points(d$H2, d$rreliability, pch=ifelse(d$CD_meaning == "C", 2, 3), col=ifelse(d$CD_meaning == "C", "blue", "black"));
points(d$e2, d$rreliability, pch=4, col="gray");
rA <- cor.test(d$rreliability, d$h2); 
rC <- cor.test(d[d$CD_meaning == "C",]$rreliability, d[d$CD_meaning == "C",]$H2); 
rD <- cor.test(d[d$CD_meaning == "D",]$rreliability, d[d$CD_meaning == "D",]$H2); 
rE <- cor.test(d$rreliability, d$e2);
abline(lm(rreliability ~ h2, data=d), lty=ifelse(rA$p.value<0.05,"solid","dotted"), lwd=1, col="red");
abline(lm(rreliability ~ H2, data=d[d$CD_meaning == "C",]), lty=ifelse(rC$p.value<0.05,"solid","dotted"), lwd=1, col="blue");
abline(lm(rreliability ~ H2, data=d[d$CD_meaning == "D",]), lty=ifelse(rD$p.value<0.05,"solid","dotted"), lwd=1, col="black");
abline(lm(rreliability ~ e2, data=d), lty=ifelse(rE$p.value<0.05,"solid","dotted"), lwd=1, col="gray");
legend("topleft", legend=c(paste0("h (r=",sprintf("%.2f",rA$estimate),", p=",sprintf("%.3g",rA$p.value),")"),
                           paste0("H (r=",sprintf("%.2f",rC$estimate),", p=",sprintf("%.3g",rC$p.value),")"),
                           paste0("F (r=",sprintf("%.2f",rD$estimate),", p=",sprintf("%.3g",rD$p.value),")"),
                           paste0("e (r=",sprintf("%.2f",rE$estimate),", p=",sprintf("%.3g",rE$p.value),")")), 
       col=c("red", "blue", "black", "gray"), pch=c(1,2, 3,4), pt.cex=2, bty="n");

plot(d$h2, d$Krippendorff.alpha, pch=1, col="red", ylab="Krippendorff's α", xlab="component estimate", xlim=c(-1,1), ylim=c(0,1), main="Krippendorff's α using all twin pairs");
points(d$H2, d$Krippendorff.alpha, pch=ifelse(d$CD_meaning == "C", 2, 3), col=ifelse(d$CD_meaning == "C", "blue", "black"));
points(d$e2, d$Krippendorff.alpha, pch=4, col="gray");
rA <- cor.test(d$Krippendorff.alpha, d$h2); 
rC <- cor.test(d[d$CD_meaning == "C",]$Krippendorff.alpha, d[d$CD_meaning == "C",]$H2); 
rD <- cor.test(d[d$CD_meaning == "D",]$Krippendorff.alpha, d[d$CD_meaning == "D",]$H2); 
rE <- cor.test(d$Krippendorff.alpha, d$e2);
abline(lm(Krippendorff.alpha ~ h2, data=d), lty=ifelse(rA$p.value<0.05,"solid","dotted"), lwd=1, col="red");
abline(lm(Krippendorff.alpha ~ H2, data=d[d$CD_meaning == "C",]), lty=ifelse(rC$p.value<0.05,"solid","dotted"), lwd=1, col="blue");
abline(lm(Krippendorff.alpha ~ H2, data=d[d$CD_meaning == "D",]), lty=ifelse(rD$p.value<0.05,"solid","dotted"), lwd=1, col="black");
abline(lm(Krippendorff.alpha ~ e2, data=d), lty=ifelse(rE$p.value<0.05,"solid","dotted"), lwd=1, col="gray");
legend("topleft", legend=c(paste0("h (r=",sprintf("%.2f",rA$estimate),", p=",sprintf("%.3g",rA$p.value),")"),
                           paste0("H (r=",sprintf("%.2f",rC$estimate),", p=",sprintf("%.3g",rC$p.value),")"),
                           paste0("F (r=",sprintf("%.2f",rD$estimate),", p=",sprintf("%.3g",rD$p.value),")"),
                           paste0("e (r=",sprintf("%.2f",rE$estimate),", p=",sprintf("%.3g",rE$p.value),")")), 
       col=c("red", "blue", "black", "gray"), pch=c(1,2, 3,4), pt.cex=2, bty="n");

par(mfrow=c(1,1));
```


### Summary for inter-rater agreement

**First**, which measure of inter-rater agreement should we use?
*Krippendorff’s &alpha;* seems to have estimation issues for some measures (`NaN` for `r sum(is.na(ph_ace$Krippendorff.alpha))` and 1 extremely negative value of `r round(min(ph_ace$Krippendorff.alpha, na.rm=TRUE),2)`), and seems to be at ceiling for most (at or very close to 1.0), while *ICC*(*C*,1) and *agr*(GSEM) are always estimated (quite robustly) and show much more inter-measure variation. 
Moreover, *ICC*(*C*,1) and *agr*(GSEM) correlate very well (`r r <- cor.test(ph_ace$rreliability, ph_ace$ICCc1); sprintf("Pearson's *r*=%.2f, *p*=%.2g", r$estimate, r$p.value)`), but much less so with *Krippendorff’s &alpha;* (*ICC*(*C*,1): `r r <- cor.test(ph_ace$Krippendorff.alpha, ph_ace$ICCc1); sprintf("Pearson's *r*=%.2f, *p*=%.2g", r$estimate, r$p.value)`; *agr*(GSEM): `r r <- cor.test(ph_ace$Krippendorff.alpha, ph_ace$rreliability); sprintf("Pearson's *r*=%.2f, *p*=%.2g", r$estimate, r$p.value)`), which is in good part due to those measures at ceiling for *&alpha;* but not for the other two.
Therefore, we will use ***ICC*(*C*,1)** and ***agr*(GSEM)** as measures of inter-rather agreement.

**Second**, a higher *ICC*(*C*,1):  

  - is reached for the *mandible*, "*general*", *hyoid* and *skull* (while the oral, hard palate, and pharynx have the lowest agreement);
  
  - is reached for *distances* and *angles* (while the lowest is for Procrustes distances and curvatures);
  
  - is *positively and significantly correlated* with higher MZ (very strongly) and DZ (moderately) twin correlations;
  
  - does not differ between the ACE and ADE models;
  
  - is *positively and significantly correlated* with all unstandardized genetic components, particularly so with the additive and dominant genetic variances A and D,
  
  - is *correlated (positively)* only with the narrow-sense heritability, *h*^2^.
  
A higher *agr*(GSEM) has pretty much the same properties as *ICC*(*C*,1):  

  - is reached for the *mandible*, "*general*", *hyoid* and *skull* (while the oral, hard palate, and pharynx have the lowest agreement);
  
  - is reached for *distances* and *angles* (while the lowest is for Procrustes distances and curvatures);
  
  - is *positively and significantly correlated* with higher MZ (very strongly) but not at all with DZ twin correlations;
  
  - does not differ between the ACE and ADE models;
  
  - is *positively and significantly correlated* with all unstandardized genetic components, particularly so with the additive and dominant genetic variances A and D,
  
  - is *correlated (positively)* only with the narrow-sense heritability, *h*^2^.
  
Given the general nature of *ICC*(*C*,1), we will use it as our measure of inter-rater agreement, keeping in mind that *agr*(GSEM) is virtually identical and may better account for the particularities of our design, but might be more sensitive to the unbalanced number of MZ and DZ twins in our data as well.

```{r include=FALSE}
# Select using 0.75 as a cut-off for the ICC:
ph_ace$ICCc1_0.75        <- (ph_ace$ICCc1 >= 0.75);        # ICC(C,1) > 0.75
ph_ace$ICCc1_0.75_strict <- (ph_ace$ICCc1.CI_low >= 0.75); # 95% CI ICC(C,1) > 0.75

# Select using 0.75 as a cut-off for the agr(GSEM):
ph_ace$rreliability_0.75        <- (ph_ace$rreliability >= 0.75);                                       # agr(GSEM) > 0.75
ph_ace$rreliability_0.75_strict <- (!is.na(ph_ace$rreliability_CiL) & ph_ace$rreliability_CiL >= 0.75); # 95% CI agr(GSEM) > 0.75

## Checks:
#table(ph_ace$ICCc1_0.75, ph_ace$rreliability_0.75, deparse.level=2);
#table(ph_ace$ICCc1_0.75_strict, ph_ace$rreliability_0.75_strict, deparse.level=2);
```
  
**Third**, following guidelines for the interpretation of *ICC*(*C*,1) and using 0.75 as a cut-off point, there are `r sum(ph_ace$ICCc1_0.75)` measures with *ICC*(*C*,1) >= 0.75, and `r sum(ph_ace$ICCc1_0.75_strict)` with the lower bound of the 95% CI of the *ICC*(*C*,1) >= 0.75:

```{r}
d <- ph_ace[ph_ace$ICCc1_0.75, c("short_name", "domain", "type", 
                                 "ICCc1", "ICCc1.CI_low", "ICCc1.CI_high", "ICCc1_0.75", "ICCc1_0.75_strict", 
                                 "rreliability", "rreliability_CiL", "rreliability_CiH", "rreliability_0.75", "rreliability_0.75_strict")];
d$ICCc1.CI        <- sprintf("[%.3f, %.3f]", d$ICCc1.CI_low,     d$ICCc1.CI_high);
d$rreliability.CI <- sprintf("[%.3f, %.3f]", d$rreliability_CiL, d$rreliability_CiH);
d <- d[ order(d$ICCc1, d$rreliability, decreasing=TRUE), ];
d$ICCc1_0.75        <- ifelse(d$ICCc1_0.75,        "Yes", "No"); d$ICCc1_0.75_strict        <- ifelse(d$ICCc1_0.75_strict,        "Yes", "No")
d$rreliability_0.75 <- ifelse(d$rreliability_0.75, "Yes", "No"); d$rreliability_0.75_strict <- ifelse(d$rreliability_0.75_strict, "Yes", "No")
knitr::kable(d[,c("short_name", "domain", "type", "ICCc1", "ICCc1.CI", "ICCc1_0.75", "ICCc1_0.75_strict", "rreliability", "rreliability.CI", "rreliability_0.75", "rreliability_0.75_strict")], 
             row.names=FALSE,
             col.names=c("measure", "domain", "type", "ICC(C,1)", "95% CI", "ICC(C,1) >= 0.75", "95% CI >= 0.75", "agr(GSEM)", "95% CI", "agr(GSEM) >= 0.75", "95% CI >= 0.75"), 
             digits=3,
             caption=capTab("Measures with good intra-rates agreement. 95% CI is the 95% confidence interval of *ICC*(*C*,1), and 95% CI >= 0.75 means that this 95% CI is located above the 0.75 threshold. We also show for these the corresponding *agr*(GSEM).")) %>%
  kable_styling(); 
```

In decreasing order of *ICC*(*C*,1): `r paste0(d$short_name," (",round(d$ICCc1,2)," ",d$ICCc1.CI,")",collapse=", ")`.


## The twin correlations

### "Raw" (i.e., uncorrected) correlations

#### By measure

```{r echo=FALSE, message=FALSE, warning=FALSE}
d <- ph_ace;
```

##### rMZ
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=4, fig.height=4, fig.cap=capFig("Histogram of MZ correlations.")}
hist(d$rMZ, col="lightgray", main="MZ correlations", xlab="MZ correlation", xlim=c(-1,1));

pander::pander(summary(d$rMZ)); 
```
*SD* = `r round(sd(d$rMZ),2)`, *IQR* = `r round(IQR(d$rMZ),2)`. 

##### rDZ
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=4, fig.height=4, fig.cap=capFig("Histogram of DZ correlations.")}
hist(d$rDZ, col="lightgray", main="DZ correlations", xlab="DZ correlation", xlim=c(-1,1));

pander::pander(summary(d$rDZ)); 
```
*SD* = `r round(sd(d$rDZ),2)`, *IQR* = `r round(IQR(d$rDZ),2)`. 

##### rMZ vs rDZ
```{r fig.height=2*5, fig.width=15, fig.cap=capFig("Plots of MZ and DZ correlations for each phenotype by measure (sorted in decreasing order of MZ correlation). For each phenotype we show the MZ correlation (yellow circle) and the DZ correlation (red arrow). The colored squared close to the bottom of the plots show the type of the measures.")}
d <- ph_ace[ order(ph_ace$rMZ, decreasing=TRUE), ];
d$short_name <- factor(d$short_name, 
                       levels=unique(d$short_name[ order(d$rMZ, decreasing=TRUE) ]), 
                       ordered=TRUE);
d$plot <- rep(c(1,2), each=round(nrow(ph_ace)/2));

p <- lapply(1:2, function(i)
  ggplot(d[d$plot==i,]) + 
    ylim(c(-1.0, 1.0)) + xlab("Phenotype") + ylab("Twin-pair correlation") +  
    geom_segment(aes(x=short_name, y=rMZ, xend=short_name, yend=rDZ), arrow = arrow(type="open", length=unit(0.1, "inch")), alpha=0.5, size=1, color="red") + 
    geom_point(aes(x=short_name, y=rMZ), shape=21, color="black", fill="yellow", size=3) +
    geom_hline(yintercept=0.0,  color=gray(0.50), linetype="dashed") + 
    geom_hline(yintercept=1.0,  color=gray(0.25), linetype="dotted") + 
    geom_hline(yintercept=-1.0, color=gray(0.25), linetype="dotted") + 
    geom_point(aes(x=short_name, fill=type), y=-1.05, color="black", size=3, shape=22) +
    theme(axis.text.x = element_text(size=10, angle=45, hjust=0.5, vjust=0.5),
          axis.title.x = element_text(size=10),
          axis.text.y = element_text(size=12),
          axis.title.y = element_text(size=10),
          legend.position="none") + 
    ggtitle(paste0(ifelse(i==1, 
                          paste0("First ", round(nrow(ph_ace)/2)), 
                          paste0("The remaning ", nrow(ph_ace) - round(nrow(ph_ace)/2))),
                   " measures")) +
    NULL);
grid.arrange(grobs=p, ncol=1); # plot it!
```
```{r include=FALSE, eval=FALSE}
# Save as image:
tiff("../figures/twin_correlations.tiff", width=1*15, height=2*5, units="in", res=600, compression="lzw");
grid.arrange(grobs=p, ncol=1);
dev.off();
```

```{r}
# Look at those measures with very high MZ correlations:
d <- ph_ace[ ph_ace$rMZ > 0.90, c("short_name", "domain", "type", "rMZ", "rDZ", "Krippendorff.alpha", "ICCc1", "ICCc1.CI_low", "ICCc1.CI_high", "rreliability", "rreliability_CiL", "rreliability_CiH")];
d <- d[order(d$rMZ, decreasing=TRUE),];
d$ICCc1.CI <- sprintf("[%.3f, %.3f]", d$ICCc1.CI_low, d$ICCc1.CI_high);
d$rreliability.CI <- sprintf("[%.3f, %.3f]", d$rreliability_CiL, d$rreliability_CiH);
knitr::kable(d[,c("short_name", "domain", "type", "rMZ", "rDZ", "Krippendorff.alpha", "ICCc1", "ICCc1.CI", "rreliability", "rreliability.CI")], 
             row.names=FALSE,
             col.names=c("measure", "domain", "type", "r~MZ~", "r~DZ~", "Krippendorff α", "ICC(C,1)", "95% CI", "agr(GSEM)", "95% CI"), 
             digits=c(NA, NA, NA, 4, 4, 2, 2, NA, 2, NA),
             caption=capTab("Measures with *r~MZ~* > 0.90 ordered decreasingly by *r~MZ~*.")) %>%
  kable_styling(); 
```


#### Comparing *r~MZ~* and *r~DZ~*

```{r}
d <- ph_ace;
```

Out of a total of `r nrow(d)` measures, *r~MZ~* > *r~DZ~* for `r sum(d$rMZ > d$rDZ, na.rm=TRUE)` measures (`r round(sum(d$rMZ > d$rDZ, na.rm=TRUE) / nrow(d) *100,1)`%) and, of those, *r~MZ~* > 2*r~DZ~* for `r sum(d$rMZ > 2*d$rDZ, na.rm=TRUE)` measures (`r round(sum(d$rMZ > 2*d$rDZ, na.rm=TRUE) / sum(d$rMZ > d$rDZ, na.rm=TRUE) *100,1)`%).


### Corrected correlations

These are derived from the SEM phentypic model (see below for details).

#### By measure

```{r echo=FALSE, message=FALSE, warning=FALSE}
d <- ph_ace[ ph_ace$twin_correlations == "corrected", ]; # these should be all of them anyways...
```

##### rMZ
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=4, fig.height=4, fig.cap=capFig("Histogram of MZ correlations.")}
hist(d$twin_corr_rMZ, col="lightgray", main="MZ correlations", xlab="MZ correlation", xlim=c(-1,1));

pander::pander(summary(d$twin_corr_rMZ)); 
```
*SD* = `r round(sd(d$twin_corr_rMZ),2)`, *IQR* = `r round(IQR(d$twin_corr_rMZ),2)`.
There are `r sprintf("%d (%.1f%%)", sum(d$twin_corr_rMZ > 1.0), sum(d$twin_corr_rMZ > 1.0)*100/nrow(d))` measures with rMZ > 1.0: `r paste0(d$short_name[d$twin_corr_rMZ > 1.0]," (",round(d$twin_corr_rMZ[d$twin_corr_rMZ > 1.0],3),")", collapse=", ")`, but it seems that for all them this could be due to numeric errors (as a reminder, the latent twin covariance matrices are estimated freely, without any constraints).

##### rDZ
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=4, fig.height=4, fig.cap=capFig("Histogram of DZ correlations.")}
hist(d$twin_corr_rDZ, col="lightgray", main="DZ correlations", xlab="DZ correlation", xlim=c(-1,1));

pander::pander(summary(d$twin_corr_rDZ)); 
```
*SD* = `r round(sd(d$twin_corr_rDZ),2)`, *IQR* = `r round(IQR(d$twin_corr_rDZ),2)`. 
There are `r sprintf("%d (%.1f%%)", sum(d$twin_corr_rDZ > 1.0), sum(d$twin_corr_rDZ > 1.0)*100/nrow(d))` measures with rDZ > 1.0: `r paste0(d$short_name[d$twin_corr_rDZ > 1.0]," (",round(d$twin_corr_rDZ[d$twin_corr_rDZ > 1.0],3),")", collapse=", ")`. The first two (HCCP and HMDC) are clearly too large to be just rounding error and suggest that they violate various assumptions of the model and should be flaged as problematic(see next section).

##### rMZ vs rDZ
```{r fig.height=2*5, fig.width=15, fig.cap=capFig("Plots of MZ and DZ correlations for each phenotype by measure (sorted in decreasing order of MZ correlation). For each phenotype we show the MZ correlation (yellow circle) and the DZ correlation (red arrow). The colored squared close to the bottom of the plots show the type of the measures.")}
d <- ph_ace[ order(ph_ace$twin_corr_rMZ, decreasing=TRUE), ];
d$short_name <- factor(d$short_name, 
                       levels=unique(d$short_name[ order(d$twin_corr_rMZ, decreasing=TRUE) ]), 
                       ordered=TRUE);
d$plot <- rep(c(1,2), each=round(nrow(ph_ace)/2));

p <- lapply(1:2, function(i)
  ggplot(d[d$plot==i,]) + 
    ylim(c(-1.0, 1.0)) + xlab("Phenotype") + ylab("Twin-pair correlation") +  
    geom_segment(aes(x=short_name, y=twin_corr_rMZ, xend=short_name, yend=twin_corr_rDZ), arrow = arrow(type="open", length=unit(0.1, "inch")), alpha=0.5, size=1, color="red") + 
    geom_point(aes(x=short_name, y=twin_corr_rMZ), shape=21, color="black", fill="yellow", size=3) +
    geom_hline(yintercept=0.0,  color=gray(0.50), linetype="dashed") + 
    geom_hline(yintercept=1.0,  color=gray(0.25), linetype="dotted") + 
    geom_hline(yintercept=-1.0, color=gray(0.25), linetype="dotted") + 
    geom_point(aes(x=short_name, fill=type), y=-1.05, color="black", size=3, shape=22) +
    theme(axis.text.x = element_text(size=10, angle=45, hjust=0.5, vjust=0.5),
          axis.title.x = element_text(size=10),
          axis.text.y = element_text(size=12),
          axis.title.y = element_text(size=10),
          legend.position="none") + 
    ggtitle(paste0(ifelse(i==1, 
                          paste0("First ", round(nrow(ph_ace)/2)), 
                          paste0("The remaning ", nrow(ph_ace) - round(nrow(ph_ace)/2))),
                   " measures")) +
    NULL);
grid.arrange(grobs=p, ncol=1); # plot it!
```

```{r}
# Look at those measures with very high MZ correlations:
d <- ph_ace[ ph_ace$twin_corr_rMZ > 0.90, c("short_name", "domain", "type", "twin_corr_rMZ", "twin_corr_rDZ", "Krippendorff.alpha", "ICCc1", "ICCc1.CI_low", "ICCc1.CI_high", "rreliability", "rreliability_CiL", "rreliability_CiH")];
d <- d[order(d$twin_corr_rMZ, decreasing=TRUE),];
d$ICCc1.CI <- sprintf("[%.3f, %.3f]", d$ICCc1.CI_low, d$ICCc1.CI_high);
d$rreliability.CI <- sprintf("[%.3f, %.3f]", d$rreliability_CiL, d$rreliability_CiH);
knitr::kable(d[,c("short_name", "domain", "type", "twin_corr_rMZ", "twin_corr_rDZ", "Krippendorff.alpha", "ICCc1", "ICCc1.CI", "rreliability", "rreliability.CI")], 
             row.names=FALSE,
             col.names=c("measure", "domain", "type", "r~MZ~", "r~DZ~", "Krippendorff α", "ICC(C,1)", "95% CI", "agr(GSEM)", "95% CI"), 
             digits=c(NA, NA, NA, 4, 4, 2, 2, NA, 2, NA),
             caption=capTab("Measures with *r~MZ~* > 0.90 ordered decreasingly by *r~MZ~*.")) %>%
  kable_styling(); 
```


#### Comparing *r~MZ~* and *r~DZ~*

```{r}
d <- ph_ace;
```

Out of a total of `r nrow(d)` measures, *r~MZ~* > *r~DZ~* for `r sum(d$twin_corr_rMZ > d$twin_corr_rDZ, na.rm=TRUE)` measures (`r round(sum(d$twin_corr_rMZ > d$twin_corr_rDZ, na.rm=TRUE) / nrow(d) *100,1)`%) and, of those, *r~MZ~* > 2*r~DZ~* for `r sum(d$twin_corr_rMZ > 2*d$twin_corr_rDZ, na.rm=TRUE)` measures (`r round(sum(d$twin_corr_rMZ > 2*d$twin_corr_rDZ, na.rm=TRUE) / sum(d$twin_corr_rMZ > d$twin_corr_rDZ, na.rm=TRUE) *100,1)`%).


## Measurements with warning flags

While we present below the estimates for all valid measurements (except for the exact duplicates) in all participants with usable data, there are several phenotypic measurements that should be treated with care given that they violate in various ways and to various degrees the assumptions of the model.
More precisely, we computed a subjective "warning score" based on:

- the visual inspection of the histograms and QQ-plots, particularly focusing on high skewness, kurtosis and signs of bi-modality,
- weird latent twin correlations from the phenotypic model (see previous section),
- the comparison of the estimated skewness against -1 and 1 (high skewness) and (-1,-0.5) and (0.5,1) (moderate skewness),
- the comparison of kurtosis to (2,5), and
- the formal Shapiro-Wilk normality test (please note that this is highly sensitive, especially for large samples).

This composite subjective "warning score" should be used to weight the interpretation of the results for each individual measure, with values &leq; 3 probably posing no problems, and only scores &geq; 5 raising potentially serious issues.

```{r}
# Which measures raise warning flags:
#   score = 1 (very weak reasons) to 10 (very strong reasons)

# Manual inspection of the histograms and QQ-plots + weird latent twin correlations:
measures_with_warnings <- read.table(text="
measure; score; comments
DDAP;    2;     Seems skewed
GAPD;    4;     Seems skewed
GRPD;    4;     Seems skewed
HARF;    4;     Seems skewed
HDMP;    6;     Sugests high kurtosis
HMAC;    3;     Seems skewed
HACL;    2;     Seems bimodal
HMTC;    3;     Seems bimodal
HCMP;    4;     Seems skewed
HCPP;    5;     Seems skewed
HMSP;    3;     Seems skewed
L2EA;    2;     Seems skewed
LACT;    1;     Seems skewed
OCLW;    3;     Seems skewed
PPW2;    8;     Sugests high kurtosis
PPW3;    8;     Sugests high kurtosis
PPW4;    6;     Sugests high kurtosis
PPW5;    3;     Sugests high kurtosis
PPW6;    2;     Sugests high kurtosis
PPWC;    8;     Sugests high kurtosis
PWTP;    2;     Seems skewed
AANP;    3;     Seems skewed
ALNS;    1;     Seems skewed
HCCP;    8;     Latent rDZ correlation much larger than 1.0
HMDC;    8;     Latent rDZ correlation much larger than 1.0
", sep=";", quote="", header=TRUE, comment.char="#");

# Automatic flagging of variables with skewness, kurtosis and/or limited variance:
.flag_measure <- function(measure, score, comments)
{
  if( measure %in% measures_with_warnings$measure )
  {
    # Already exists: update its entry:
    measures_with_warnings[ measures_with_warnings$measure == measure, "score" ] <<- max(measures_with_warnings[ measures_with_warnings$measure == measure, "score" ], score);
    measures_with_warnings[ measures_with_warnings$measure == measure, "comments" ] <<- paste0(measures_with_warnings[ measures_with_warnings$measure == measure, "comments" ], ", ", comments);
  } else
  {
    # Add new entry:
    measures_with_warnings <<- rbind(measures_with_warnings, data.frame("measure"=measure, "score"=score, "comments"=comments));
  }
}
for( s in ph_ace$short_name )
{
  ss <- measures_summaries[ rownames(measures_summaries) == s, ]; # get the summaries for this particular measure
  if( nrow(ss) != 1 ) stop(paste0("Error matching phenotype ",s,"!\n")); # checks
  
  # Skewness (expected is 0.0):
  if( ss$all_skewness < -1 || ss$all_skewness > 1 )
  {
    .flag_measure(s, 8, "highly skewed");
  } else if( (ss$all_skewness >= -1 && ss$all_skewness < -0.5) || (ss$all_skewness <= 1 && ss$all_skewness > 0.5) )
  {
    .flag_measure(s, 3, "moderately skewed");
  }
  
  # Kurtosis (expected is 3.0):
  if( ss$all_kurtosis < 2 )
  {
    .flag_measure(s, 5, "platykurtic");
  } else if( ss$all_kurtosis > 5 )
  {
    .flag_measure(s, 5, "leptokurtic");
  }
  
  # Formal tests:
  if( ss$all_shapiro.p < 0.01 )
  {
    .flag_measure(s, 1, "Shapiro-Wilk significant"); # highly sensitive to deviations from normality, especially for large samples
  }
}

# Sort by decreasing warning score:
measures_with_warnings <- measures_with_warnings[ order(-measures_with_warnings$score, measures_with_warnings$measure), ];

# Save them for the main paper:
save(measures_with_warnings, file="./results_for_paper/measures_with_warnings.RData", compress="xz", compression_level=9);
```

```{r}
tmp <- measures_with_warnings; # for display with colors and font styles
tmp$measure <- kableExtra::cell_spec(tmp$measure, 
                                     color=ifelse(tmp$score < 3, "black",
                                                  ifelse(tmp$score < 5, "blue", "red")),
                                     bold=(tmp$score >= 5));
knitr::kable(tmp %>% arrange(desc(score)), escape=FALSE, 
             row.names=FALSE,
             col.names=c("measure", "warning score", "reasons"), 
             digits=0,
             caption=capTab("Measures with warnings that shuld be interpretated with care. The *score* goes from 1 (very weak reasons to worry) to 10 (very strong reasons to worry); probably only scores > 3 might pose problems, and only ≥ 5 probably pose serious problems...")) %>%
  kable_styling(); 
```


# The SEM genetic model

## Description of the SEM model

### Introduction and notations

The SEM model is fitted using [`OpenMX`](https://openmx.ssri.psu.edu/) (called from `R` using the `OpenMx` library).

As a reminder, for each individual measure, *m*, we have the values observed for the two twins of each twin pair (denoted as *twin 1* and *twin 2*, respectively), by each of the two raters (denoted as *rater 1* and *rater 2*, respectively), such that we have, in fact, four types of values: those measured by rater 1 for twin 1 denoted as *m*<sub>11</sub>, those measured by rater 1 for twin 2 denoted as *m*<sub>12</sub>, those measured by rater 2 for twin 1 denoted as *m*<sub>21</sub>, and those measured by rater 2 for twin 2 denoted as *m*<sub>22</sub> (thus, the general convention is *m*<sub>*rt*</sub>, where *r* is the rater and *t* the twin). 
We *normalize* (i.e., *z*-score) the measure *m* separately by rater, but for a given rater, across both twins in all twin pairs and across MZ and DZ twins; that is, we compute *m*'<sub>*r.*</sub> = (*m*<sub>*r.*</sub> - *mean*(*m*<sub>*r.*</sub>)) / *sd*(*m*<sub>*r.*</sub>), where *r* &in; {1,2} is the rater, and the notation <sub>*r.*</sub> means the values for both twins.


### Modelling the two raters

*A priori* we can image at least four ways to model our two raters, *rater 1* and *rater 2*, depending on how we consider their (latent) means and error variances:

- **IMIV**: the two raters have identical means and error variances: this model assumes that the two raters are essentially identical (i.e., they make essentially the same judgments barring some random noise), and has the smallest number of free parameters;
- **DMIV**: the two raters have different means but identical error variances: this model assumes that the raters have different latent "true scores", but identical error rates;
- **IMDV**: the two raters have identical means but different error variances: this model assumes that the raters have the same "true scores", but different error rates;
- **DMDV**: the two raters have different means and error variances: this model assumes that the raters may be different in both respects, and has the largest number of free parameters.

Before seeing the data, in an ideal world we might want to fit the least constrained model **DMDV** (i.e., metaphotically, let the data decide), but this comes with too many free parameters for our sample.
At the other extreme, while the two raters were trained in the same way and did discuss edge cases between them, making sure their criteria stay in sync, they were emphatically not clones of each others and debriefing during and after the landmarking revealed subtle differences and perceptual biases, potentially suggesting that the **IMIV** might be too simplistic.

However, it is difficult to decide between these four possibilities based only on *a priori* considerations, so we first examined the correlations (Pearson's and Spearman) and the differences between the values obtained by the first and second rater for the same individual and measure.
As can be seen in the figure below, the two raters tend to agree rather well on the *mean* of the "raw" measurements (3rd histogram, narrowly centered on 0.0, and 2nd scatterplot), while their correlations are medium to high.
This suggests that the two models that assume identical means might be retained, but it is still hard to decide if the rater error variances should be considered equal or different.

![`r capFig("Deciding between alernative ways to model the two raters. From top-left to bottom-right: first row: histograms of the correlations between the two raters (Pearson's and Spearman's), the histogram of the differences in mean estimates between the raters, scatterplot between the mean differences and inter-rater Pearson's correlations; second row: scatterplots between mean rater differences. Please note that these were computed on the \"raw\" (i.e., not *z*-scored) measurements across twin pairs, zygosity types and measures.")`](../figures/rater_models.jpg)

To help settle this, for each measure *m*, we fitted two SEM models (for details, please see next section), one with one rater error variance (denoted as *M*<sub>*m*,1*r*</sub>) and the other with two rater error variances (denoted *M*<sub>*m*,2*r*</sub>).
Please note that we are not interested here in deciding for each individual measure *m* what rater model fits best, but rather in obtaining the overall distribution of the the best fitting model across all the measures, and to combine this with the *a priori* reasoning and the exploratory plots discussed above to decide on a single rater model to apply to all measures.
Please note that while having a different rater model for each measure might seem the best approach, this inflates the number of tests performed, requiring a stricter multiple testing correction which, on our database, would drastically reduce our power to detect significant effects.
Moreover, arguably, given that the measures are derived, using more or less complex procedures, from the actual landmarks and semilandmarks that were placed by each rater in "one go", it seems reasonable to use the same rater model across measures.
In particular, we used both [Akaike's Information Criterion](https://en.wikipedia.org/wiki/Akaike_information_criterion) or *AIC* (in fact, the AIC is corrected using the "Parameters Penalty" as implemented by `OpenMx`, which uses the number of free parameters in the model rather than the degrees of freedom; please see the help pages for `summary` and `mxCompare` for details) and the likelihood ratio test (again, please see `mxCompare` in `OpenMx`), and the summaries over all measures are as follows (please note that the comparison is performed between the 2-raters and 1-rater model, which means that the difference in AIC scores, ΔAIC, is negative if an only if the 2-rater model has a lower AIC score than the 1-rater model -- i.e., it is the better model --  and it is positive otherwise):

```{r}
d_rater_model <- read.csv("../data/intermediate/SEM_results_2vs1_raters.csv");
# Remove the duplicated measures:
d_rater_model <- d_rater_model[ !(d_rater_model$phenotype_name_short %in% c("LNEP", "ASCG", "SBAP", "LNCT")), ];
```
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=4, fig.height=4, fig.cap=capFig("Histogram of the ΔAIC differences in AIC scores between the 2-raters and 1-rate models (i.e., negative ΔAIC means that the 2-rater model fits the data better) across all measures. Please note that the dashed vertical lines marking the 2 (red) and 10 (blue) AIC points thresholds are barely visible.")}
hist(d_rater_model$deltaAIC, col="lightgray", main="ΔAIC 2-raters vs 1-rater", xlab="ΔAIC differences");
abline(v=c(-2,2), col="red", lty="dashed");
abline(v=c(-10,10), col="blue", lty="dashed");

pander::pander(summary(d_rater_model$deltaAIC));
```

- using a cutoff of 2 AIC points for "different enough", we have:

  + `r (x <- sum(d_rater_model$deltaAIC < -2, na.rm=TRUE))` (`r round(x/nrow(d_rater_model)*100,1)`%) measures supporting the 2-raters model (i.e., with ΔAIC < -2),
  + `r (x <- sum(d_rater_model$deltaAIC >= -2 & d_rater_model$deltaAIC <= 2, na.rm=TRUE))` (`r round(x/nrow(d_rater_model)*100,1)`%) measures for which the two models are equivalent (i.e., -2 <= ΔAIC <= 2), and
  + `r (x <- sum(d_rater_model$deltaAIC > 2, na.rm=TRUE))` (`r round(x/nrow(d_rater_model)*100,1)`%) measures supporting the 1-rater model (i.e., with ΔAIC > 2).

- adding a more stringent cutoff of 10 AIC points for "overwhelmingly different", we have:

  + `r (x <- sum(d_rater_model$deltaAIC < -10, na.rm=TRUE))` (`r round(x/nrow(d_rater_model)*100,1)`%) measures overwhelmingly supporting the 2-raters model (i.e., with ΔAIC < -),
  + `r (x <- sum(d_rater_model$deltaAIC >= -10 & d_rater_model$deltaAIC <= 10, na.rm=TRUE))` (`r round(x/nrow(d_rater_model)*100,1)`%) measures for which the two models are equivalent (i.e., -10 <= ΔAIC <= 10), and
  + `r (x <- sum(d_rater_model$deltaAIC > 10, na.rm=TRUE))` (`r round(x/nrow(d_rater_model)*100,1)`%) measures overwhelmingly supporting the 1-rater model (i.e., with ΔAIC > 10).
  
- finally, using the likelihood test and an *&alpha;*-level of 0.05 for judging significance:

  + `r (x <- sum(d_rater_model$p < 0.05, na.rm=TRUE))` (`r round(x/nrow(d_rater_model)*100,1)`%) measures show a significant difference between the two models (i.e., *p* < 0.05), of which:
    - `r (x <- sum(d_rater_model$p < 0.05 & d_rater_model$deltaAIC < 0, na.rm=TRUE))` (`r round(x/sum(d_rater_model$p < 0.05, na.rm=TRUE)*100,1)`%) favour the 2-raters model (i.e., ΔAIC < 0) and 
    - `r (x <- sum(d_rater_model$p < 0.05 & d_rater_model$deltaAIC > 0, na.rm=TRUE))` (`r round(x/sum(d_rater_model$p < 0.05, na.rm=TRUE)*100,1)`%) favour the 1-rater model (i.e., ΔAIC > 0).

Taking everything together, it is clear that *modelling the two raters as being essentially identical* (i.e., with the same latent mean and error variances), **IMIV**, is the best choice we can make.


### The phenotypic model

The first SEM model that we define is at the *phenotypic* level, where we model the two raters and the effects of the various covariates on the measurements.

For a given measure *m* and twin pair (MZ or DZ) with twins 1 and 2, for a particular member of this pair, *i*, we model these covariates as:

<!-- $$m_{i} \sim \mu + \beta_{s}sex_{i} + \beta_{a}age_{i} + \beta_{a2}age_{i}^2 + \beta_{b}ICV_{i} + \beta_{as}age_{i}sex_{i} + \beta_{bs}ICV_{i}sex_{i}$$ -->

*m*<sub>*i*</sub> ~ *&mu;* + *&beta;*<sub>*s*</sub>*sex*<sub>*i*</sub> + *&beta;*<sub>*a*</sub>*age*<sub>*i*</sub> + *&beta;*<sub>*a*2</sub>*age*<sub>*i*</sub><sup>2</sup> + *&beta;*<sub>*b*</sub>*ICV*<sub>*i*</sub> + *&beta;*<sub>*as*</sub>*age*<sub>*i*</sub>*sex*<sub>*i*</sub> + *&beta;*<sub>*bs*</sub>*ICV*<sub>*i*</sub>*sex*<sub>*i*</sub>

where:

- the symbol ~ stands for linear regression,
- *&mu;* is the intercept, modeled as the same for twin type and twin pair member,
- the covariates for the twin member considered *i* are *sex*<sub>*i*</sub>, *age*<sub>*i*</sub> and *age*<sub>*i*</sub><sup>2</sup> at scan (the squared age models non-linear developmental and aging effects), and intracranial brain volume *ICV*<sub>*i*</sub>, each with its own regression slope *&beta;*<sub>*s*</sub>, *&beta;*<sub>*a*</sub>, *&beta;*<sub>*a2*</sub> and *&beta;*<sub>*b*</sub>,
- in principle, we can also model some potentially relevant interactions such between age and sex, and ICV and sex, but given our small sample size we decided to not do that here (i.e., we forced their slopes, *&beta;*<sub>*as*</sub> and *&beta;*<sub>*bs*</sub>, to be 0.0).

Please note that:

a) there is a single intercept in the model, reflecting the fact that we have no *a priori* reasons to believe that there should be differences in intercept between twin pair members and zygosity types (i.e., between MZ and DZ twins),
b) likewise, we have no reason to assume that the slopes differ between twin types and twin pair members as well, 
c) we do not model here the interactions between covariates do to the size of our sample.

With these, the SEM model is:

![`r capFig("The phenotypic SEM model. Given a measure *m* (not explicitely shwon here), *f1* and *f2* are the latent values of this measure for the two members of a twin pair, *1* and *2*, as measured each by the two raters. This produces 4 observed values, 2 per twin pair member, denoted as *Ph11* for the first rater's value for the first twin and as *Ph21* for the second rater's value for the first twin, and as *Ph12* for the first rater's value for the second twin and as *Ph22* for the second rater's value for the second twin, respectively. *s<sub>f</sub><sup>2</sup>* is the rater's unique error variance, *s<sub>e</sub><sup>2</sup>* is the mesurement error, and *s<sub>12mz</sub>* and *s<sub>12dz</sub>* represent the correlations between the two twins wen they are MZ and DZ twins, respectively. ")`](../code/SEM_path_01.jpg)

We derive from this model the latent phenotype correlations for MZ and DZ twins respectively, *r*<sub>*MZ*</sub> and *r*<sub>*DZ*</sub>, which we use to decide if we should further fit an ADE model (if and only if *r*<sub>*MZ*</sub> > 2*r*<sub>*DZ*</sub>) or and ACE model (otherwise).

(*N.B.* Please note that for `r sum(ph_ace$Comments != "OK", na.rm=TRUE)` phenotypes there were some issues obtaining a estimate of these latent correlations, and we had to "fall back" on using the "raw" MZ and DZ correlations when making this heuristic decision; nevertheless, as our main interest resides with the additive component *A*, this should not affect our results too much, a point supported by checks using different phenotypic models.)


### Fitting the ADE or ACE models

With these, we further fitted the suggested model (ACE or ADE):

![`r capFig("The genetic SEM model. Most conventions are as in the phenotypic SEM model above, except that now the latent measurements *f1* and *f2* is each decomposed into the effects of the additive genetic variance *A*, of the non-shared environment *E*, and of the dominance genetic variance *D* or the shared environment *C*, as appropriate. The correlation between the additive components *A* of the two twins differs between MZ (1.0) and DZ (0.5) twins, as does the correlations between dominance effects *D* (1.0 for MZ and 0.25 for DZ), but that for the shared environment is the same (1.0). ")`](../code/SEM_path_02.jpg)

Besides fitting this model, we also fit models where we fix each of the components *A*, *E* and *C* or *D* to 0, in order to statistically test their contributions. 


## Results for the SEM models

With these, we focus now on the results of fitting these models for each measure independently.
We report both the *unstandardized* components *A*, *C* or *D*, and *E*, as well as the *standardized* measures of interest *A*~std~ (or narrow-sense heritability, *h*^2^), *C*~std~ (and associated familiality, *F*^2^) or *D*~std~ (and associated broad-sense heritability, *H*^2^), and *A*~std~ (or non-shared environmental variance, *e*^2^).
The results of main interest are the latter.

Please note that we show here all the measures, irrespective of their warning flag values, but that we will remove those with warnings ≥ 5 later on...


### By measure

```{r}
d <- ph_ace[, c("short_name", "domain", "type", "genetic_model", "ICCc1", "ICCc1_0.75", "ICCc1_0.75_strict")];
d <- d[ order(!d$ICCc1_0.75_strict, !d$ICCc1_0.75, d$genetic_model, -d$ICCc1), ];
```

There are `r sum(d$genetic_model=="ACE",na.rm=TRUE)` measures where *ACE* seems the appropriate model (of which `r sum(d$genetic_model=="ACE" & d$ICCc1_0.75,na.rm=TRUE)` have *ICC(C,1)* >= 0.75 and `r sum(d$genetic_model=="ACE" & d$ICCc1_0.75_strict,na.rm=TRUE)` have 95% CI *ICC(C,1)* low >= 0.75), and `r sum(d$genetic_model=="ADE",na.rm=TRUE)` where *ADE* seems the appropriate model (of which `r sum(d$genetic_model=="ADE" & d$ICCc1_0.75,na.rm=TRUE)` have *ICC(C,1)* >= 0.75 and `r sum(d$genetic_model=="ADE" & d$ICCc1_0.75_strict,na.rm=TRUE)` have 95% CI *ICC(C,1)* low >= 0.75):

```{r}
knitr::kable(d %>% mutate(ICCc1_0.75=if_else(ICCc1_0.75, "Yes", "No"), ICCc1_0.75_strict=if_else(ICCc1_0.75_strict, "Yes", "No")), 
             row.names=FALSE,
             col.names=c("measure", "domain", "type", "genetic model", "ICC(C,1)", "ICC(C,1) >= 0.75", "95% ICC(C,1) low >= 0.75"), 
             digits=2,
             caption=capTab("The genetic models for all measures, showing first those with *ACE*, ordered by agreement.")) %>%
  kable_styling(); 
```


### The standardized and unstandardied estimates

```{r}
# Prepare them for plotting:
d <- ph_ace[ c("short_name", "domain", "type", 
               "ICCc1", "ICCc1_0.75", "ICCc1_0.75_strict", 
               "genetic_model", 
               "A_CiL", "A", "A_CiH", "CD_CiL", "CD", "CD_CiH", "E_CiL", "E", "E_CiH", 
               "h2", "h2_CiL", "h2_CiH", "cd2", "cd2_CiL", "cd2_CiH", "H2", "H2_CiL", "H2_CiH", "e2", "e2_CiL", "e2_CiH")];
d_long_estimates <- reshape2::melt(d, id.vars=c("short_name", "domain", "type", "ICCc1", "ICCc1_0.75", "ICCc1_0.75_strict", "genetic_model"), 
                                   measure.vars=c("A", "CD", "E", "h2", "cd2", "H2", "e2"), variable.name="component", value.name="estimate");
d_long_low       <- reshape2::melt(d, id.vars=c("short_name", "domain", "type", "ICCc1", "ICCc1_0.75", "ICCc1_0.75_strict", "genetic_model"), 
                                   measure.vars=c("A_CiL", "CD_CiL", "E_CiL", "h2_CiL", "cd2_CiL", "H2_CiL", "e2_CiL"), variable.name="component", value.name="low");
d_long_low$component <- vapply(strsplit(as.character(d_long_low$component), "_", fixed=TRUE), function(x) x[1], character(1));
d_long_high     <- reshape2::melt(d, id.vars=c("short_name", "domain", "type", "ICCc1", "ICCc1_0.75", "ICCc1_0.75_strict", "genetic_model"), 
                                  measure.vars=c("A_CiH", "CD_CiH", "E_CiH", "h2_CiH", "cd2_CiH", "H2_CiH", "e2_CiH"), variable.name="component", value.name="high");
d_long_high$component <- vapply(strsplit(as.character(d_long_low$component), "_", fixed=TRUE), function(x) x[1], character(1));
d_long <- merge(merge(d_long_estimates, d_long_low), d_long_high);
d_long$component <- as.character(d_long$component); 
s <- (d_long$component == "CD");  d_long$component[s] <- ifelse(d_long$genetic_model[s] == "ACE", "C", "D");
s <- (d_long$component == "cd2"); d_long$component[s] <- ifelse(d_long$genetic_model[s] == "ACE", "c2", "d2");
```


#### *ACE*

##### All phenotypes

###### Unstandardized components

```{r}
# Prepare for plotting:
d1 <- d_long[ d_long$genetic_model == "ACE" & d_long$component %in% c("A", "C", "E"), ];
d1$short_name <- reorder(d1$short_name, rep(d1$estimate[ d1$component == "A" ], each=length(unique(d1$component))), function(x) median(x,na.rm=TRUE));
d1$low[ is.na(d1$low) ] <- 0.0; d1$high[ is.na(d1$high) ] <- 1.0; # make the unestimated bounds as large as possible
```
```{r fig.height=length(unique(d1$short_name))*0.4, fig.width=8, fig.cap=capFig("*A*, *C* and *E* components (with 95% CI) for all measures for which *ACE* is the best-fitting model ordered by decreasing *A* estimate.")}
ggplot(d1, aes(x=short_name, y=estimate, fill=component)) + coord_flip() + xlab("Phenotype") + ylab("Component estimate with 95%CI") + ylim(0,1) +
  geom_bar(position=position_dodge(), stat="identity") +
  geom_errorbar(aes(ymin=low, ymax=high), width=.2, position=position_dodge(.9), color="gray20", alpha=0.5) + 
  scale_fill_viridis_d();
```

###### Standardized components

```{r}
# Prepare for plotting:
d1 <- d_long[ d_long$genetic_model == "ACE" & d_long$component %in% c("h2", "c2", "H2", "e2"), ];
d1$short_name <- reorder(d1$short_name, rep(d1$estimate[ d1$component == "h2" ], each=length(unique(d1$component))), function(x) median(x,na.rm=TRUE));
d1$low[ is.na(d1$low) ] <- 0.0; d1$high[ is.na(d1$high) ] <- 1.0; # make the unestimated bounds as large as possible
```
```{r fig.height=length(unique(d1$short_name))*0.4, fig.width=8, fig.cap=capFig("*h*^2^ (aka *a*^2^), *c*^2^ and *e*^2^ components (with 95% CI) for all measures for which *ACE* is the best-fitting model ordered by decreasing *h*^2^ estimate.")}
ggplot(d1, aes(x=short_name, y=estimate, fill=component)) + coord_flip() + xlab("Phenotype") + ylab("Component estimate with 95%CI") + ylim(0,1) +
  geom_bar(position=position_dodge(), stat="identity") +
  geom_errorbar(aes(ymin=low, ymax=high), width=.2, position=position_dodge(.9), color="gray20", alpha=0.5) + 
  scale_fill_viridis_d(labels=c(expression("c"^2),expression("e"^2), expression("h"^2), expression("F"^2)));
```

##### Inter-rater reliable phenotypes

```{r}
# Prepare for plotting only those with high inter-rater agreement:
d1 <- d_long[ d_long$genetic_model == "ACE" & d_long$ICCc1_0.75 & d_long$component %in% c("h2", "c2", "H2", "e2"), ];
d1$short_name <- reorder(d1$short_name, rep(d1$estimate[ d1$component == "h2" ], each=length(unique(d1$component))), function(x) median(x,na.rm=TRUE));
d1$low[ is.na(d1$low) ] <- 0.0; d1$high[ is.na(d1$high) ] <- 1.0; # make the unestimated bounds as large as possible
```
```{r fig.height=length(unique(d1$short_name))*0.4, fig.width=8, fig.cap=capFig("*h*^2^ (aka *a*^2^), *c*^2^, *F*^2^ and *e*^2^ components (with 95% CI) for all measures for which *ACE* is the best-fitting model ordered by decreasing *h*^2^ estimate, only for the measures with good inter-rater agreement (i.e., *ICC(C,1)* >= 0.75).")}
ggplot(d1, aes(x=short_name, y=estimate, fill=component)) + coord_flip() + xlab("Phenotype") + ylab("Component estimate with 95%CI") + ylim(0,1) +
  geom_bar(position=position_dodge(), stat="identity") +
  geom_errorbar(aes(ymin=low, ymax=high), width=.2, position=position_dodge(.9)) + 
  scale_fill_viridis_d(labels=c(expression("c"^2),expression("e"^2), expression("h"^2), expression("F"^2)));
```


#### *ADE*

##### All phenotypes

###### Unstandardized components

```{r}
# Prepare for plotting:
d1 <- d_long[ d_long$genetic_model == "ADE" & d_long$component %in% c("A", "D", "E"), ];
d1$short_name <- reorder(d1$short_name, rep(d1$estimate[ d1$component == "A" ], each=length(unique(d1$component))), function(x) median(x,na.rm=TRUE));
d1$low[ is.na(d1$low) ] <- 0.0; d1$high[ is.na(d1$high) ] <- 1.0; # make the unestimated bounds as large as possible
```
```{r fig.height=length(unique(d1$short_name))*0.4, fig.width=8, fig.cap=capFig("*A*, *D* and *E* components (with 95% CI) for all measures for which *ACE* is the best-fitting model ordered by decreasing *A* estimate.")}
ggplot(d1, aes(x=short_name, y=estimate, fill=component)) + coord_flip() + xlab("Phenotype") + ylab("Component estimate with 95%CI") + ylim(0,1) +
  geom_bar(position=position_dodge(), stat="identity") +
  geom_errorbar(aes(ymin=low, ymax=high), width=.2, position=position_dodge(.9), color="gray20", alpha=0.5) + 
  scale_fill_viridis_d();
```

###### Standardized components

```{r}
# Prepare for plotting:
d1 <- d_long[ d_long$genetic_model == "ADE" & d_long$component %in% c("h2", "d2", "H2", "e2"), ];
d1$short_name <- reorder(d1$short_name, rep(d1$estimate[ d1$component == "h2" ], each=length(unique(d1$component))), function(x) median(x,na.rm=TRUE));
d1$low[ is.na(d1$low) ] <- 0.0; d1$high[ is.na(d1$high) ] <- 1.0; # make the unestimated bounds as large as possible
```
```{r fig.height=length(unique(d1$short_name))*0.4, fig.width=8, fig.cap=capFig("*h*^2^ (aka *a*^2^), *d*^2^, *H*^2^, and *e*^2^ components (with 95% CI) for all measures for which *ACE* is the best-fitting model ordered by decreasing *h*^2^ estimate.")}
ggplot(d1, aes(x=short_name, y=estimate, fill=component)) + coord_flip() + xlab("Phenotype") + ylab("Component estimate with 95%CI") + ylim(0,1) +
  geom_bar(position=position_dodge(), stat="identity") +
  geom_errorbar(aes(ymin=low, ymax=high), width=.2, position=position_dodge(.9), color="gray20", alpha=0.5) + 
  scale_fill_viridis_d(labels=c(expression("d"^2),expression("e"^2), expression("h"^2), expression("H"^2)));
```

##### Inter-rater reliable phenotypes

```{r}
# Prepare for plotting only those with high inter-rater agreement:
d1 <- d_long[ d_long$genetic_model == "ADE" & d_long$ICCc1_0.75 & d_long$component %in% c("h2", "d2", "H2", "e2"), ];
d1$short_name <- reorder(d1$short_name, rep(d1$estimate[ d1$component == "h2" ], each=length(unique(d1$component))), function(x) median(x,na.rm=TRUE));
d1$low[ is.na(d1$low) ] <- 0.0; d1$high[ is.na(d1$high) ] <- 1.0; # make the unestimated bounds as large as possible
```
```{r fig.height=length(unique(d1$short_name))*0.4, fig.width=8, fig.cap=capFig("*h*^2^ (aka *a*^2^), *d*^2^, *H*^2^ and *e*^2^ components (with 95% CI) for all measures for which *ACE* is the best-fitting model ordered by decreasing *h*^2^ estimate, only for the measures with good inter-rater agreement (i.e., *ICC(C,1)* >= 0.75).")}
ggplot(d1, aes(x=short_name, y=estimate, fill=component)) + coord_flip() + xlab("Phenotype") + ylab("Component estimate with 95%CI") + ylim(0,1) +
  geom_bar(position=position_dodge(), stat="identity") +
  geom_errorbar(aes(ymin=low, ymax=high), width=.2, position=position_dodge(.9)) + 
  scale_fill_viridis_d(labels=c(expression("d"^2),expression("e"^2), expression("h"^2), expression("H"^2)));
```


#### Both *ACE* and *ADE* together

##### All measures

###### Unstandardized components

```{r}
# Prepare for plotting:
d1 <- d_long[ d_long$component %in% c("A", "C", "D", "E"), ]; d1$component[ d1$component %in% c("C","D") ] <- "C or D";
d1$short_name <- reorder(d1$short_name, rep(d1$estimate[ d1$component == "A" ], each=length(unique(d1$component))), function(x) median(x,na.rm=TRUE));
d1$low[ is.na(d1$low) ] <- 0.0; d1$high[ is.na(d1$high) ] <- 1.0; # make the unestimated bounds as large as possible
```
```{r fig.height=length(unique(d1$short_name))*0.4, fig.width=8, fig.cap=capFig("*A*, *C*/*D* and *E* components (with 95% CI) for all measures ordered by decreasing *A* estimate.")}
ggplot(d1, aes(x=short_name, y=estimate, fill=component)) + coord_flip() + xlab("Phenotype") + ylab("Component estimate with 95%CI") + ylim(0,1) +
  geom_bar(position=position_dodge(), stat="identity") +
  geom_errorbar(aes(ymin=low, ymax=high), width=.2, position=position_dodge(.9), color="gray20", alpha=0.5) + 
  scale_fill_viridis_d();
```

###### Standardized components

```{r}
# Prepare for plotting:
d1 <- d_long[ d_long$component %in% c("h2", "c2", "d2", "F2", "H2", "e2"), ];  
d1$component[ d1$component %in% c("c2","d2") ] <- "c2 or d2";
d1$component[ d1$component %in% c("F2","H2") ] <- "F2 or H2";
d1$short_name <- reorder(d1$short_name, rep(d1$estimate[ d1$component == "h2" ], each=length(unique(d1$component))), function(x) median(x,na.rm=TRUE));
d1$low[ is.na(d1$low) ] <- 0.0; d1$high[ is.na(d1$high) ] <- 1.0; # make the unestimated bounds as large as possible
```
```{r fig.height=length(unique(d1$short_name))*0.4, fig.width=8, fig.cap=capFig("*h*^2^ (aka *a*^2^), *d*^2^, *H*^2^, and *e*^2^ components (with 95% CI) for all measures for which *ACE* is the best-fitting model ordered by decreasing *h*^2^ estimate.")}
ggplot(d1, aes(x=short_name, y=estimate, fill=component)) + coord_flip() + xlab("Phenotype") + ylab("Component estimate with 95%CI") + ylim(0,1) +
  geom_bar(position=position_dodge(), stat="identity") +
  geom_errorbar(aes(ymin=low, ymax=high), width=.2, position=position_dodge(.9), color="gray20", alpha=0.5) + 
  scale_fill_viridis_d(labels=c(expression("c"^2~"or"~"d"^2),expression("e"^2), expression("F"^2~"or"~"H"^2), expression("h"^2)));
```

##### Inter-rater reliable measures

```{r}
# Prepare for plotting:
d1 <- d_long[ d_long$ICCc1_0.75 & d_long$component %in% c("h2", "c2", "d2", "F2", "H2", "e2"), ];  
d1$component[ d1$component %in% c("c2","d2") ] <- "c2 or d2";
d1$component[ d1$component %in% c("F2","H2") ] <- "F2 or H2";
d1$short_name <- reorder(d1$short_name, rep(d1$estimate[ d1$component == "h2" ], each=length(unique(d1$component))), function(x) median(x,na.rm=TRUE));
d1$low[ is.na(d1$low) ] <- 0.0; d1$high[ is.na(d1$high) ] <- 1.0; # make the unestimated bounds as large as possible
```
```{r fig.height=length(unique(d1$short_name))*0.4, fig.width=8, fig.cap=capFig("*h*^2^ (aka *a*^2^), *d*^2^, *H*^2^, and *e*^2^ components (with 95% CI) for all measures for which *ACE* is the best-fitting model ordered by decreasing *h*^2^ estimate.")}
ggplot(d1, aes(x=short_name, y=estimate, fill=component)) + coord_flip() + xlab("Phenotype") + ylab("Component estimate with 95%CI") + ylim(0,1) +
  geom_bar(position=position_dodge(), stat="identity") +
  geom_errorbar(aes(ymin=low, ymax=high), width=.2, position=position_dodge(.9), color="gray20", alpha=0.5) + 
  scale_fill_viridis_d(labels=c(expression("c"^2~"or"~"d"^2),expression("e"^2), expression("F"^2~"or"~"H"^2), expression("h"^2)));
```


#### Measures by components

The significant contribution of a component is judged from the AIC and likelihood ratio test (LRT) against the model with that component fixed to 0.0 (i.e., for the ΔAIC this must be > 2, and for the test, *p* < 0.05 -- we did not apply any multiple testing correction here).


##### *A* and *h*^2^

```{r}
d <- ph_ace;
d$A_aic   <- (!is.na(d$A_deltaAIC) & d$A_deltaAIC > 2); # phenotypes with A significantly larger than 0 (i.e., Delta_AIC > 2)
d$A_lrtp  <- (!is.na(d$A_p) & d$A_p < 0.05); # phenotypes with A significantly larger than 0 (i.e., likelihood ratio test p < 0.05)
d$h2_gt50 <- (d$h2 >= 0.50); # phenotypes with h2 estimate > 50%
d$h2_gt20 <- (d$h2 >= 0.20); # phenotypes with h2 estimate > 20%
d$h2_sign <- (!is.na(d$h2_CiL) & d$h2_CiL > 0.00); # phenotypes with h2 estimate significantly different from 0
```

Relationship between the significance of *A* judged by AIC and LRT is perfect:
```{r}
pander(table(d$A_aic, d$A_lrtp)); # perfect
```

but that between AIC (or, equivalently, LRT) and the inclusion of 0 within the 95%CI of *h*^2^ is not, with the latter being more liberal (i.e., finding more measures with a significant *h*^2^):
```{r}
pander(table(d$A_aic, d$h2_sign)); # 95%CI h^2 is less strict
```

```{r}
# Prepare for pretty printing:
d$A_print   <- sprintf("%.2f (%.2f, %.2f)", d$A, ifelse(is.na(d$A_CiL),0,d$A_CiL), ifelse(is.na(d$A_CiH),1,d$A_CiH));
d$h2_print  <- sprintf("%.2f (%.2f, %.2f)", d$h2, ifelse(is.na(d$h2_CiL),0,d$h2_CiL), ifelse(is.na(d$h2_CiH),1,d$h2_CiH));
d$ICC_print <- sprintf("%.2f (%.2f, %.2f)", d$ICCc1, ifelse(is.na(d$ICCc1.CI_low),0,d$ICCc1.CI_low), ifelse(is.na(d$ICCc1.CI_high),1,d$ICCc1.CI_high));
d$A_p_corr  <- p.adjust(d$A_p, method="holm");

# Prepare for printing:
d <- d[ order(d$A_p_corr, !d$A_aic, !d$A_lrtp, !d$ICCc1_0.75_strict, !d$ICCc1_0.75, !d$h2_gt50, !d$h2_gt20, -d$h2), ];
d$short_name <- kableExtra::cell_spec(d$short_name, 
                                      color=ifelse(!is.na(d$A_p_corr) & d$A_p_corr < 0.05, "darkblue", ifelse(d$A_lrtp, "blue", ifelse(d$h2_gt20, "black", "gray"))),
                                      bold=d$ICCc1_0.75, italic=d$ICCc1_0.75_strict);
kable(d[, c("short_name", "domain", "type", "ICC_print", "genetic_model", "A_print", "A_deltaAIC", "A_p", "A_p_corr", "h2_print", "h2_sign")],
      escape=FALSE, row.names=FALSE,
      col.names=c("measure", "domain", "type", "*ICC*(*C*,1)", "genetic model", "*A*", "ΔAIC", "*p*", "*p*(Holm)", "*h*^2^", "*h*^2^>0"),
      digits   =c(NA,        NA,       NA,     NA,             NA,              NA,    2,      4,     4,           NA,       NA),
      caption=paste0("Measures with a significant *A* component, ordered by the decreasing strength of evidence for *A*, inter-rater agreement and estimate of *h*^2^. In *dark blue* measures with a significant *A* component after Holm's correction (",sum(!is.na(d$A_p_corr) & d$A_p_corr < 0.05),"), while in *blue* those only nominally significant (",sum(d$A_lrtp & !(!is.na(d$A_p_corr) & d$A_p_corr < 0.05)),"); in *bold* measures with *ICC(C,1)* > 0.75 (",sum(d$ICCc1_0.75),"), in *bold italic* mesures with the lower 95%CI of *ICC(C,1)* > 0.75 (",sum(d$ICCc1_0.75_strict),"); in gray those with *h*^2^ < 0.20 (",sum(!d$h2_gt20),"). Column *h*^2^ > 0 is TRUE if and only if 0 is not included in the 95% CI of *h*^2^ (this is a much less strict test than ΔAIC and LTR)."))  %>%
  kable_styling("striped", full_width=FALSE);
```


##### *C* and *c*^2^

```{r}
d <- ph_ace[ ph_ace$genetic_model == "ACE", ];
d$C_aic   <- (!is.na(d$CD_deltaAIC) & d$CD_deltaAIC > 2); # phenotypes with C significantly larger than 0 (i.e., Delta_AIC > 2)
d$C_lrtp  <- (!is.na(d$CD_p) & d$CD_p < 0.05); # phenotypes with C significantly larger than 0 (i.e., likelihood ratio test p < 0.05)
d$c2_gt50 <- (d$cd2 >= 0.50); # phenotypes with c2 estimate > 50%
d$c2_gt20 <- (d$cd2 >= 0.20); # phenotypes with c2 estimate > 20%
d$c2_sign <- (!is.na(d$cd2_CiL) & d$cd2_CiL > 0.00); # phenotypes with c2 estimate significantly different from 0
```

Relationship between the significance of *C* judged by AIC and LRT is almost perfect:
```{r}
pander(table(d$C_aic, d$C_lrtp)); # perfect
```

but that between AIC( (or, equivalently, LRT) and the inclusion of 0 within the 95%CI of *c*^2^ is not, with the latter being more liberal (i.e., finding more measures with a significant *c*^2^):
```{r}
pander(table(d$C_aic, d$c2_sign)); # 95%CI c^2 is less strict
```

```{r}
# Prepare for pretty printing:
d$C_print   <- sprintf("%.2f (%.2f, %.2f)", d$CD, ifelse(is.na(d$CD_CiL),0,d$CD_CiL), ifelse(is.na(d$CD_CiH),1,d$CD_CiH));
d$c2_print  <- sprintf("%.2f (%.2f, %.2f)", d$cd2, ifelse(is.na(d$cd2_CiL),0,d$cd2_CiL), ifelse(is.na(d$cd2_CiH),1,d$cd2_CiH));
d$ICC_print <- sprintf("%.2f (%.2f, %.2f)", d$ICCc1, ifelse(is.na(d$ICCc1.CI_low),0,d$ICCc1.CI_low), ifelse(is.na(d$ICCc1.CI_high),1,d$ICCc1.CI_high));
d$C_p_corr  <- p.adjust(d$CD_p, method="holm");

# Prepare for printing:
d <- d[ order(d$C_p_corr, !d$C_aic, !d$C_lrtp, !d$ICCc1_0.75_strict, !d$ICCc1_0.75, !d$c2_gt50, !d$c2_gt20, -d$cd2), ];
d$short_name <- kableExtra::cell_spec(d$short_name, 
                                      color=ifelse(!is.na(d$C_p_corr) & d$C_p_corr < 0.05, "darkblue", ifelse(d$C_lrtp, "blue", ifelse(d$c2_gt20, "black", "gray"))),
                                      bold=d$ICCc1_0.75, italic=d$ICCc1_0.75_strict);
kable(d[, c("short_name", "domain", "type", "ICC_print", "genetic_model", "C_print", "CD_deltaAIC", "CD_p", "C_p_corr", "c2_print", "c2_sign")],
      escape=FALSE, row.names=FALSE,
      col.names=c("measure", "domain", "type", "*ICC*(*C*,1)", "genetic model", "*C*", "ΔAIC", "*p*", "*p*(Holm)", "*c*^2^", "*c*^2^>0"),
      digits   =c(NA,        NA,       NA,     NA,             NA,              NA,    2,      4,     4,           NA,       NA),
      caption=paste0("Measures with a significant *C* component, ordered by the decreasing strength of evidence for *C*, inter-rater agreement and estimate of *c*^2^. In *dark blue* measures with a significant *C* component after Holm's correction (",sum(!is.na(d$C_p_corr) & d$C_p_corr < 0.05),"), while in *blue* those only nominally significant (",sum(d$C_lrtp & !(!is.na(d$C_p_corr) & d$C_p_corr < 0.05)),"); in *bold* measures with *ICC(C,1)* > 0.75 (",sum(d$ICCc1_0.75),"), in *bold italic* mesures with the lower 95%CI of *ICC(C,1)* > 0.75 (",sum(d$ICCc1_0.75_strict),"); in gray those with *c*^2^ < 0.20 (",sum(!d$c2_gt20),"). Column *c*^2^ > 0 is TRUE if and only if 0 is not included in the 95% CI of *c*^2^ (this is a much less strict test than ΔAIC and LTR)."))  %>%
  kable_styling("striped", full_width=FALSE);
```


##### *D* and *d*^2^

```{r}
d <- ph_ace[ ph_ace$genetic_model == "ADE", ];
d$D_aic   <- (!is.na(d$CD_deltaAIC) & d$CD_deltaAIC > 2); # phenotypes with C significantly larger than 0 (i.e., Delta_AIC > 2)
d$D_lrtp  <- (!is.na(d$CD_p) & d$CD_p < 0.05); # phenotypes with C significantly larger than 0 (i.e., likelihood ratio test p < 0.05)
d$d2_gt50 <- (d$cd2 >= 0.50); # phenotypes with d2 estimate > 50%
d$d2_gt20 <- (d$cd2 >= 0.20); # phenotypes with d2 estimate > 20%
d$d2_sign <- (!is.na(d$cd2_CiL) & d$cd2_CiL > 0.00); # phenotypes with d2 estimate significantly different from 0
```

Relationship between the significance of *D* judged by AIC and LRT is perfect:
```{r}
pander(table(d$D_aic, d$D_lrtp)); # perfect
```

but that between AIC( (or, equivalently, LRT) and the inclusion of 0 within the 95%CI of *d*^2^ is not, with the latter being more liberal (i.e., finding more measures with a significant *d*^2^):
```{r}
pander(table(d$D_aic, d$d2_sign)); # 95%CI d^2 is less strict
```

```{r}
# Prepare for pretty printing:
d$D_print   <- sprintf("%.2f (%.2f, %.2f)", d$CD, ifelse(is.na(d$CD_CiL),0,d$CD_CiL), ifelse(is.na(d$CD_CiH),1,d$CD_CiH));
d$d2_print  <- sprintf("%.2f (%.2f, %.2f)", d$cd2, ifelse(is.na(d$cd2_CiL),0,d$cd2_CiL), ifelse(is.na(d$cd2_CiH),1,d$cd2_CiH));
d$ICC_print <- sprintf("%.2f (%.2f, %.2f)", d$ICCc1, ifelse(is.na(d$ICCc1.CI_low),0,d$ICCc1.CI_low), ifelse(is.na(d$ICCc1.CI_high),1,d$ICCc1.CI_high));
d$D_p_corr  <- p.adjust(d$CD_p, method="holm");

# Prepare for printing:
d <- d[ order(d$D_p_corr, !d$D_aic, !d$D_lrtp, !d$ICCc1_0.75_strict, !d$ICCc1_0.75, !d$d2_gt50, !d$d2_gt20, -d$cd2), ];
d$short_name <- kableExtra::cell_spec(d$short_name, 
                                      color=ifelse(!is.na(d$D_p_corr) & d$D_p_corr < 0.05, "darkblue", ifelse(d$D_lrtp, "blue", ifelse(d$d2_gt20, "black", "gray"))),
                                      bold=d$ICCc1_0.75, italic=d$ICCc1_0.75_strict);
kable(d[, c("short_name", "domain", "type", "ICC_print", "genetic_model", "D_print", "CD_deltaAIC", "CD_p", "D_p_corr", "d2_print", "d2_sign")],
      escape=FALSE, row.names=FALSE,
      col.names=c("measure", "domain", "type", "*ICC*(*C*,1)", "genetic model", "*C*", "ΔAIC", "*p*", "*p*(Holm)", "*c*^2^", "*c*^2^>0"),
      digits   =c(NA,        NA,       NA,     NA,             NA,              NA,    2,      4,     4,           NA,       NA),
      caption=paste0("Measures with a significant *D* component, ordered by the decreasing strength of evidence for *D*, inter-rater agreement and estimate of *d*^2^. In *dark blue* measures with a significant *D* component after Holm's correction (",sum(!is.na(d$D_p_corr) & d$D_p_corr < 0.05),"), while in *blue* those only nominally significant (",sum(d$D_lrtp & !(!is.na(d$D_p_corr) & d$D_p_corr < 0.05)),"); in *bold* measures with *ICC(C,1)* > 0.75 (",sum(d$ICCc1_0.75),"), in *bold italic* mesures with the lower 95%CI of *ICC(C,1)* > 0.75 (",sum(d$ICCc1_0.75_strict),"); in gray those with *d*^2^ < 0.20 (",sum(!d$d2_gt20),"). Column *c*^2^ > 0 is TRUE if and only if 0 is not included in the 95% CI of *d*^2^ (this is a much less strict test than ΔAIC and LTR)."))  %>%
  kable_styling("striped", full_width=FALSE);
```


##### *E* and *e*^2^

```{r}
d <- ph_ace;
d$E_aic   <- (!is.na(d$E_deltaAIC) & d$E_deltaAIC > 2); # phenotypes with C significantly larger than 0 (i.e., Delta_AIC > 2)
d$E_lrtp  <- (!is.na(d$E_p) & d$E_p < 0.05); # phenotypes with E significantly larger than 0 (i.e., likelihood ratio test p < 0.05)
d$e2_gt50 <- (d$e2 >= 0.50); # phenotypes with e2 estimate > 50%
d$e2_gt20 <- (d$e2 >= 0.20); # phenotypes with e2 estimate > 20%
d$e2_sign <- (!is.na(d$e2_CiL) & d$e2_CiL > 0.00); # phenotypes with e2 estimate significantly different from 0
```

Relationship between the significance of *E* judged by AIC and LRT is perfect:
```{r}
pander(table(d$E_aic, d$E_lrtp)); # perfect
```

but that between AIC( (or, equivalently, LRT) and the inclusion of 0 within the 95%CI of *d*^2^ is not, with the latter being more liberal (i.e., finding more measures with a significant *d*^2^):
```{r}
pander(table(d$E_aic, d$e2_sign)); # 95%CI d^2 is less strict
```

```{r}
# Prepare for pretty printing:
d$E_print   <- sprintf("%.2f (%.2f, %.2f)", d$CD, ifelse(is.na(d$E_CiL),0,d$E_CiL), ifelse(is.na(d$E_CiH),1,d$E_CiH));
d$e2_print  <- sprintf("%.2f (%.2f, %.2f)", d$e2, ifelse(is.na(d$e2_CiL),0,d$e2_CiL), ifelse(is.na(d$e2_CiH),1,d$e2_CiH));
d$ICC_print <- sprintf("%.2f (%.2f, %.2f)", d$ICCc1, ifelse(is.na(d$ICCc1.CI_low),0,d$ICCc1.CI_low), ifelse(is.na(d$ICCc1.CI_high),1,d$ICCc1.CI_high));
d$E_p_corr  <- p.adjust(d$E_p, method="holm");

# Prepare for printing:
d <- d[ order(d$E_p_corr, !d$E_aic, !d$E_lrtp, !d$ICCc1_0.75_strict, !d$ICCc1_0.75, !d$e2_gt50, !d$e2_gt20, -d$e2), ];
d$short_name <- kableExtra::cell_spec(d$short_name, 
                                      color=ifelse(!is.na(d$E_p_corr) & d$E_p_corr < 0.05, "darkblue", ifelse(d$E_lrtp, "blue", ifelse(d$e2_gt20, "black", "gray"))),
                                      bold=d$ICCc1_0.75, italic=d$ICCc1_0.75_strict);
kable(d[, c("short_name", "domain", "type", "ICC_print", "genetic_model", "E_print", "E_deltaAIC", "E_p", "E_p_corr", "e2_print", "e2_sign")],
      escape=FALSE, row.names=FALSE,
      col.names=c("measure", "domain", "type", "*ICC*(*C*,1)", "genetic model", "*C*", "ΔAIC", "*p*", "*p*(Holm)", "*c*^2^", "*c*^2^>0"),
      digits   =c(NA,        NA,       NA,     NA,             NA,              NA,    2,      4,     4,           NA,       NA),
      caption=paste0("Measures with a significant *E* component, ordered by the decreasing strength of evidence for *E*, inter-rater agreement and estimate of *d*^2^. In *dark blue* measures with a significant *E* component after Holm's correction (",sum(!is.na(d$E_p_corr) & d$E_p_corr < 0.05),"), while in *blue* those only nominally significant (",sum(d$E_lrtp & !(!is.na(d$E_p_corr) & d$E_p_corr < 0.05)),"); in *bold* measures with *ICC(C,1)* > 0.75 (",sum(d$ICCc1_0.75),"), in *bold italic* mesures with the lower 95%CI of *ICC(C,1)* > 0.75 (",sum(d$ICCc1_0.75_strict),"); in gray those with *d*^2^ < 0.20 (",sum(!d$e2_gt20),"). Column *c*^2^ > 0 is TRUE if and only if 0 is not included in the 95% CI of *d*^2^ (this is a much less strict test than ΔAIC and LTR)."))  %>%
  kable_styling("striped", full_width=FALSE);
```



# Estimates of interest

Here we focus on the estimates of interest from a genetic point of view, namely the *narrow-sense heritability* *h*^2^, the *non-shared environment* *e*^2^, and the *shared environment* *c*^2^ and *familiality* *F*^2^ (for ACE) or the *dominance* *d*^2^ and *broad-sense heritability* *H*^2^ (for ADE), also taking the inter-rater agreement into account.
When it comes to statistical significance, we used the following:

- for the "simple" estimates *h*^2^, *c*^2^, *d*^2^ and *e*^2^, we use the corresponding *p*-values derived from model comparison because they are more conservative and allow multiple testing corrections,
- however, the familiality *familiality* *F*^2^ and the *broad-sense heritability* *H*^2^ are composed from two "atomic" components (*A* and *C*, and *A* and *D*, respectively), which makes model comparison difficult; in these cases, we check if 0 is included in the 95%CI of the composed estimate (but this method might be too liberal).

So, we do not include here the non-standardized components *A*, *C* or *D*, and *E* (please see above for the results concerning them).

Moreover, we exclude here the `r sum(measures_with_warnings$score >= 5)` measures with warning flag values ≥ 5.

```{r}
# Combine all the info in a single dataset:
d_combined <- data.frame(ph_ace[ , c("short_name", "domain", "type", 
                                     "genetic_model", "CD_meaning", "H2_meaning",
                                     "h2", "h2_CiL", "h2_CiH") ], 
                         "h2_gt20"=(ph_ace$h2 >= 0.20),
                         "h2_p"=ph_ace$A_p, "h2_p_adj"=p.adjust(ph_ace$A_p, method="holm"),
                         ph_ace[ , c("cd2", "cd2_CiL", "cd2_CiH") ], 
                         "cd2_p"=ph_ace$CD_p, "cd2_p_adj"=p.adjust(ph_ace$CD_p, method="holm"), 
                         ph_ace[ , c("e2", "e2_CiL", "e2_CiH") ], 
                         "e2_p"=ph_ace$E_p, "e2_p_adj"=p.adjust(ph_ace$E_p, method="holm"),  
                         ph_ace[ , c("H2", "H2_CiL", "H2_CiH") ], "H2_signif"=(!is.na(ph_ace$H2_CiL) & ph_ace$H2_CiL > 0),
                         ph_ace[ , c("rMZ", "rDZ", 
                                     "ICCc1", "ICCc1.CI_low", "ICCc1.CI_high", "ICCc1_0.75", "ICCc1_0.75_strict",
                                     "rreliability", "rreliability_CiL", "rreliability_CiH", "rreliability_0.75", "rreliability_0.75_strict")]);

# Remove measures with warning  >= 5:
d_combined <- d_combined[ !(d_combined$short_name %in% measures_with_warnings$measure[ measures_with_warnings$score >= 5 ]), ];

# Rename some columns:
names(d_combined)[ names(d_combined) == "ICCc1" ] <- "ICC";
names(d_combined)[ names(d_combined) == "ICCc1.CI_low" ] <- "ICC_CiL";
names(d_combined)[ names(d_combined) == "ICCc1.CI_high" ] <- "ICC_CiH";
names(d_combined)[ names(d_combined) == "ICCc1_0.75" ] <- "ICC_0.75";
names(d_combined)[ names(d_combined) == "ICCc1_0.75_strict" ] <- "ICC_0.75_strict";

names(d_combined)[ names(d_combined) == "rreliability" ] <- "agrGSEM";
names(d_combined)[ names(d_combined) == "rreliability_CiL" ] <- "agrGSEM_CiL";
names(d_combined)[ names(d_combined) == "rreliability_CiH" ] <- "agrGSEM_CiH";
names(d_combined)[ names(d_combined) == "rreliability_0.75" ] <- "agrGSEM_0.75";
names(d_combined)[ names(d_combined) == "rreliability_0.75_strict" ] <- "agrGSEM_0.75_strict";

# Fix non-estimated 95%CIs:
for(i in grep("_CiL", names(d_combined), fixed=TRUE)) d_combined[ is.na(d_combined[,i]), i ] <- 0.0;
for(i in grep("_CiH", names(d_combined), fixed=TRUE)) d_combined[ is.na(d_combined[,i]), i ] <- 1.0;

# Order by heritability:
d_combined <- d_combined[ order(d_combined$h2_p_adj, d_combined$h2_p, -d_combined$h2, -d_combined$ICC), ];
```


## Relationships between these estimates

```{r}
# Compute the correlations:
estim_corrs <- data.frame("measure1"=c("h2", "h2", "h2", "c2", "d2", "ICC", "ICC", "ICC", "ICC"), 
                          "measure2"=c("c2", "d2", "e2", "e2", "e2", "h2",  "c2",  "d2",  "e2"), 
                          "r"=NA, "r.p"=NA, "r.p.adj"=NA, "rho"=NA, "rho.p"=NA, "rho.p.adj"=NA);
# data for all, for c2 and for d2:
estim_d_all <- d_combined; estim_d_c2 <- d_combined[ d_combined$genetic_model == "ACE", ]; estim_d_d2 <- d_combined[ d_combined$genetic_model == "ADE", ];
# h2:
estim_corrs[ estim_corrs$measure1=="h2" & estim_corrs$measure2=="c2", c("r", "r.p", "rho", "rho.p") ] <- 
  c((r <- cor.test(estim_d_c2$h2, estim_d_c2$cd2, method="pearson"))$estimate, r$p.value, 
    (r <- cor.test(estim_d_c2$h2, estim_d_c2$cd2, method="spearman"))$estimate, r$p.value);
estim_corrs[ estim_corrs$measure1=="h2" & estim_corrs$measure2=="d2", c("r", "r.p", "rho", "rho.p") ] <- 
  c((r <- cor.test(estim_d_d2$h2, estim_d_d2$cd2, method="pearson"))$estimate, r$p.value, 
    (r <- cor.test(estim_d_d2$h2, estim_d_d2$cd2, method="spearman"))$estimate, r$p.value);
estim_corrs[ estim_corrs$measure1=="h2" & estim_corrs$measure2=="e2", c("r", "r.p", "rho", "rho.p") ] <- 
  c((r <- cor.test(estim_d_all$h2, estim_d_all$e2, method="pearson"))$estimate, r$p.value, 
    (r <- cor.test(estim_d_all$h2, estim_d_all$e2, method="spearman"))$estimate, r$p.value);
# c2:
estim_corrs[ estim_corrs$measure1=="c2" & estim_corrs$measure2=="e2", c("r", "r.p", "rho", "rho.p") ] <- 
  c((r <- cor.test(estim_d_c2$cd2, estim_d_c2$e2, method="pearson"))$estimate, r$p.value, 
    (r <- cor.test(estim_d_c2$cd2, estim_d_c2$e2, method="spearman"))$estimate, r$p.value);
# d2:
estim_corrs[ estim_corrs$measure1=="d2" & estim_corrs$measure2=="e2", c("r", "r.p", "rho", "rho.p") ] <- 
  c((r <- cor.test(estim_d_d2$cd2, estim_d_d2$e2, method="pearson"))$estimate, r$p.value, 
    (r <- cor.test(estim_d_d2$cd2, estim_d_d2$e2, method="spearman"))$estimate, r$p.value);
# ICC:
estim_corrs[ estim_corrs$measure1=="ICC" & estim_corrs$measure2=="h2", c("r", "r.p", "rho", "rho.p") ] <- 
  c((r <- cor.test(estim_d_all$ICC, estim_d_all$h2, method="pearson"))$estimate, r$p.value, 
    (r <- cor.test(estim_d_all$ICC, estim_d_all$h2, method="spearman"))$estimate, r$p.value);
estim_corrs[ estim_corrs$measure1=="ICC" & estim_corrs$measure2=="c2", c("r", "r.p", "rho", "rho.p") ] <- 
  c((r <- cor.test(estim_d_c2$ICC, estim_d_c2$cd2, method="pearson"))$estimate, r$p.value, 
    (r <- cor.test(estim_d_c2$ICC, estim_d_c2$cd2, method="spearman"))$estimate, r$p.value);
estim_corrs[ estim_corrs$measure1=="ICC" & estim_corrs$measure2=="d2", c("r", "r.p", "rho", "rho.p") ] <- 
  c((r <- cor.test(estim_d_d2$ICC, estim_d_d2$cd2, method="pearson"))$estimate, r$p.value, 
    (r <- cor.test(estim_d_d2$ICC, estim_d_d2$cd2, method="spearman"))$estimate, r$p.value);
estim_corrs[ estim_corrs$measure1=="ICC" & estim_corrs$measure2=="e2", c("r", "r.p", "rho", "rho.p") ] <- 
  c((r <- cor.test(estim_d_all$ICC, estim_d_all$e2, method="pearson"))$estimate, r$p.value, 
    (r <- cor.test(estim_d_all$ICC, estim_d_all$e2, method="spearman"))$estimate, r$p.value);
# Multiple testing adjustment:
estim_corrs$r.p.adj <- p.adjust(estim_corrs$r.p, method="bonferroni"); estim_corrs$rho.p.adj <- p.adjust(estim_corrs$rho.p, method="bonferroni");
# Save the for the paper:
save(estim_corrs, file="./results_for_paper/estim_corrs.RData", compress="xz", compression_level=9);

# Pretty print them:
tmp <- estim_corrs;
library(gtools);
tmp$r <- sprintf("%.2f (%.3g; %.3g%s)", tmp$r, tmp$r.p, tmp$r.p.adj, stars.pval(tmp$r.p.adj));
tmp$rho <- sprintf("%.2f (%.3g; %.3g%s)", tmp$rho, tmp$rho.p, tmp$rho.p.adj, stars.pval(tmp$rho.p.adj));
tmp <- tmp[,c("measure1", "measure2", "r", "rho")];
knitr::kable(tmp, 
             row.names=FALSE,
             col.names=c("measure1", "measure2", "Pearson's *r* (*p*; adjusted *p*)", "Spearman's *ρ* (*p*; adjusted *p*)"), 
             caption=capTab("Correlations between the estimates of interest, including a Bonferroni correction and significance stars.")) %>%
  kable_styling();
```


```{r fig.width=4*2, fig.height=4*2, fig.cap=capFig("Pairwise correlations between the estimates of interest.")}
estim_plots <- list(
  # h2:
  ggplot(estim_d_c2,  aes(x=h2, y=cd2)) + geom_point(alpha=0.5) + xlab(expression("h"^2)) + ylab(expression("c"^2)) + ggtitle(expression("h"^2~"vs"~"c"^2)) +
    geom_smooth(method="loess", color="red", alpha=0.5) + geom_smooth(method="lm", color="blue", alpha=0.5),
  ggplot(estim_d_d2,  aes(x=h2, y=cd2)) + geom_point(alpha=0.5) + xlab(expression("h"^2)) + ylab(expression("d"^2)) + ggtitle(expression("h"^2~"vs"~"d"^2)) + 
    geom_smooth(method="loess", color="red", alpha=0.5) + geom_smooth(method="lm", color="blue", alpha=0.5),
  ggplot(estim_d_all, aes(x=h2, y=e2))  + geom_point(alpha=0.5) + xlab(expression("h"^2)) + ylab(expression("e"^2)) + ggtitle(expression("h"^2~"vs"~"e"^2)) +
    geom_smooth(method="loess", color="red", alpha=0.5) + geom_smooth(method="lm", color="blue", alpha=0.5),
  ggplot(estim_d_all, aes(x=h2, y=ICC)) + geom_point(alpha=0.5) + xlab(expression("h"^2)) + ylab("ICC") +             ggtitle(expression("h"^2~"vs"~"ICC")) +
    geom_smooth(method="loess", color="red", alpha=0.5) + geom_smooth(method="lm", color="blue", alpha=0.5),
  # c2:
  ggplot() + theme_void(),
  ggplot() + theme_void(),
  ggplot(estim_d_c2, aes(x=cd2, y=e2))  + geom_point(alpha=0.5) + xlab(expression("c"^2)) + ylab(expression("e"^2)) + ggtitle(expression("c"^2~"vs"~"e"^2)) +
    geom_smooth(method="loess", color="red", alpha=0.5) + geom_smooth(method="lm", color="blue", alpha=0.5),
  ggplot(estim_d_c2, aes(x=cd2, y=ICC)) + geom_point(alpha=0.5) + xlab(expression("c"^2)) + ylab("ICC") +             ggtitle(expression("c"^2~"vs"~"ICC")) +
    geom_smooth(method="loess", color="red", alpha=0.5) + geom_smooth(method="lm", color="blue", alpha=0.5),
  # d2:
  ggplot() + theme_void(),
  ggplot() + theme_void(),
  ggplot(estim_d_d2, aes(x=cd2, y=e2))  + geom_point(alpha=0.5) + xlab(expression("d"^2)) + ylab(expression("e"^2)) + ggtitle(expression("d"^2~"vs"~"e"^2)) +
    geom_smooth(method="loess", color="red", alpha=0.5) + geom_smooth(method="lm", color="blue", alpha=0.5),
  ggplot(estim_d_d2, aes(x=cd2, y=ICC)) + geom_point(alpha=0.5) + xlab(expression("d"^2)) + ylab("ICC") +             ggtitle(expression("d"^2~"vs"~"ICC")) +
    geom_smooth(method="loess", color="red", alpha=0.5) + geom_smooth(method="lm", color="blue", alpha=0.5),
  # e2:
  ggplot() + theme_void(),
  ggplot() + theme_void(),
  ggplot() + theme_void(),
  ggplot(estim_d_all, aes(x=e2, y=ICC)) + geom_point(alpha=0.5) + xlab(expression("e"^2)) + ylab("ICC") +             ggtitle(expression("e"^2~"vs"~"ICC")) +
    geom_smooth(method="loess", color="red", alpha=0.5) + geom_smooth(method="lm", color="blue", alpha=0.5)
);
  
grid.arrange(grobs=estim_plots, ncol=4);
```
```{r results='hide'}
# Save to file:

# As TIFF:
tiff("../figures/figure_S02.tiff", width=4*2, height=4*2, units="in", res=600, compression="lzw");
grid.arrange(grobs=estim_plots, ncol=4);
dev.off(); 

# ... and as JPG:
jpeg("../figures/figure_S02.jpg", width=4*2, height=4*2, units="in", res=150, quality=85);
grid.arrange(grobs=estim_plots, ncol=4);
dev.off(); 
```

It is important to note the following:

- narrow-sense heritability *h*^2^ is very strongly and negatively correlated with the shared environment (*c*^2^) and the dominance (*d*^2^) effects, and less strongly and negatively with the error (*e*^2^);
- *c*^2^ and *d*^2^ are not correlated with *e*^2^;
- the inter-rater agreement (*ICC*(*C*,1)) is strongly and positively correlated with *h*^2^, strongly and negatively with *e*^2^, but not with *d*^2^ and *c*^2^, suggesting that measures where the raters disagree might result in artificially lowered heritability estimates as this disagreement goes into the error term.


## By domain and type

```{r fig.width=2*4, fig.height=2*4, fig.cap=capFig("By row, from top to bottom the estimates of interest (excluding *H*^2^/*F*^2^). Left column: by domain; right column: by type. Dashed black lines represent the important values of 0.0, 0.2, and 1.0.")}
d_combined_long <- gather(d_combined[,c("short_name", "domain", "type", "genetic_model", "h2", "cd2", "e2")], "estimate", "value", h2, cd2, e2);
d_combined_long$estimate[ d_combined_long$estimate == "cd2" & d_combined_long$genetic_model=="ACE" ] <- "c2";
d_combined_long$estimate[ d_combined_long$estimate == "cd2" & d_combined_long$genetic_model=="ADE" ] <- "d2";
d_combined_long$estimate <- factor(d_combined_long$estimate, levels=c("h2", "c2", "d2", "e2"));
grid.arrange(ggplot(d_combined_long, aes(y=value, x=domain, fill=estimate)) + ylab("estimate") +
               geom_boxplot() + geom_point() + geom_hline(yintercept=c(0,0.2,1.0), color="black", alpha=0.5, linetype="dashed") +
               theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position="bottom") + 
               facet_grid(estimate ~ .),
             ggplot(d_combined_long, aes(y=value, x=type, fill=estimate)) + ylab("estimate") +
               geom_boxplot() + geom_point() + geom_hline(yintercept=c(0,0.2,1.0), color="black", alpha=0.5, linetype="dashed") +
               theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position="bottom") + 
               facet_grid(estimate ~ .),
             ncol=2);
```
```{r results='hide'}
# Save the figure:

# As TIFF:
tiff(file="../figures/figure_S03.tiff", width=2*3, height=4*1.5, units="in", res=600, compression="lzw");
d_combined_long2 <- d_combined_long; d_combined_long2$domain[ d_combined_long2$domain == "cervical" ] <- "            cervical"; # kludge for plots having the same label size
levels(d_combined_long2$estimate) <- c(expression("h"^2), expression("c"^2), expression("d"^2), expression("e"^2));
grid.arrange(ggplot(d_combined_long2, aes(y=value, x=domain)) + ylab("estimate") +
               geom_boxplot(color="black") + geom_point(alpha=0.25, color="gray50") + geom_hline(yintercept=c(0,0.2,1.0), color="black", alpha=0.5, linetype="dashed") +
               theme_bw() + 
               theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position="none") + 
               facet_grid(estimate ~ ., labeller=label_parsed),
             ggplot(d_combined_long2, aes(y=value, x=type)) + ylab("estimate") +
               geom_boxplot(color="black") + geom_point(alpha=0.25, color="gray50") + geom_hline(yintercept=c(0,0.2,1.0), color="black", alpha=0.5, linetype="dashed") +
               theme_bw() + 
               theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position="none") + 
               facet_grid(estimate ~ ., labeller=label_parsed),
             ncol=2);
dev.off();

# ... and as JPG:
jpeg(file="../figures/figure_S03.jpg", width=2*3, height=4*1.5, units="in", res=150, quality=85);
d_combined_long2 <- d_combined_long; d_combined_long2$domain[ d_combined_long2$domain == "cervical" ] <- "            cervical"; # kludge for plots having the same label size
levels(d_combined_long2$estimate) <- c(expression("h"^2), expression("c"^2), expression("d"^2), expression("e"^2));
grid.arrange(ggplot(d_combined_long2, aes(y=value, x=domain)) + ylab("estimate") +
               geom_boxplot(color="black") + geom_point(alpha=0.25, color="gray50") + geom_hline(yintercept=c(0,0.2,1.0), color="black", alpha=0.5, linetype="dashed") +
               theme_bw() + 
               theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position="none") + 
               facet_grid(estimate ~ ., labeller=label_parsed),
             ggplot(d_combined_long2, aes(y=value, x=type)) + ylab("estimate") +
               geom_boxplot(color="black") + geom_point(alpha=0.25, color="gray50") + geom_hline(yintercept=c(0,0.2,1.0), color="black", alpha=0.5, linetype="dashed") +
               theme_bw() + 
               theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position="none") + 
               facet_grid(estimate ~ ., labeller=label_parsed),
             ncol=2);
dev.off();
```


### *h*^2^

ANOVA by domain and type (N.B. strictly speaking, we should use a *Beta* distribution, but for our purposes here a linear model should suffice):

```{r}
# Anovas with Tukey's HSD (N.B. strictly this should be a beta regression but for our purposes here it should be fine...)
anova_h2_d <- aov(h2 ~ domain, data=d_combined);
anova_h2_t <- aov(h2 ~ type, data=d_combined);
anova_h2_d_HSD <- TukeyHSD(anova_h2_d); colnames(anova_h2_d_HSD$domain)[4] <- "p.adj"; 
anova_h2_t_HSD <- TukeyHSD(anova_h2_t); colnames(anova_h2_t_HSD$type)[4] <- "p.adj"; 
```

- by **domain**:
```{r}
pander::pander(summary(anova_h2_d));
```

- by **type**:
```{r}
pander::pander(summary(anova_h2_t));
```

The pairwise significant differences after Tukey's HSD:

- by **domain** there are `r sum(anova_h2_d_HSD$domain[,"p.adj"] < 0.05)` significantly different pairs:
```{r}
thsd <- anova_h2_d_HSD$domain[ anova_h2_d_HSD$domain[,"p.adj"] < 0.05, , drop=FALSE]
if( nrow(thsd) > 0 )
{
  thsd <- as.data.frame(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE]); thsd$p.adj <- sprintf("%.3g",thsd$p.adj);
  knitr::kable(thsd, row.names=TRUE, digits=c(2, 2, 2, NA), caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>% kable_styling();
}
```

- by **type** there are `r sum(anova_h2_t_HSD$type[,"p.adj"] < 0.05)` significantly different pairs:
```{r}
thsd <- anova_h2_t_HSD$type[ anova_h2_t_HSD$type[,"p.adj"] < 0.05, , drop=FALSE]
if( nrow(thsd) > 0 )
{
  thsd <- as.data.frame(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE]); thsd$p.adj <- sprintf("%.3g",thsd$p.adj);
  knitr::kable(thsd, row.names=TRUE, digits=c(2, 2, 2, NA), caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>% kable_styling();
}
```


### *c*^2^

```{r}
# Anovas with Tukey's HSD (N.B. strictly this should be a beta regression but for our purposes here it should be fine...)
anova_c2_d <- aov(cd2 ~ domain, data=d_combined[ d_combined$genetic_model=="ACE", ]);
anova_c2_t <- aov(cd2 ~ type, data=d_combined[ d_combined$genetic_model=="ACE", ]);
anova_c2_d_HSD <- TukeyHSD(anova_c2_d); colnames(anova_c2_d_HSD$domain)[4] <- "p.adj"; 
anova_c2_t_HSD <- TukeyHSD(anova_c2_t); colnames(anova_c2_t_HSD$type)[4] <- "p.adj"; 
```

- by **domain**:
```{r}
pander::pander(summary(anova_c2_d));
```

- by **type**:
```{r}
pander::pander(summary(anova_c2_t));
```

The pairwise significant differences after Tukey's HSD:

- by **domain** there are `r sum(anova_c2_d_HSD$domain[,"p.adj"] < 0.05)` significantly different pairs:
```{r}
thsd <- anova_c2_d_HSD$domain[ anova_c2_d_HSD$domain[,"p.adj"] < 0.05, , drop=FALSE]
if( nrow(thsd) > 0 )
{
  thsd <- as.data.frame(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE]); thsd$p.adj <- sprintf("%.3g",thsd$p.adj);
  knitr::kable(thsd, row.names=TRUE, digits=c(2, 2, 2, NA), caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>% kable_styling();
}
```

- by **type** there are `r sum(anova_c2_t_HSD$type[,"p.adj"] < 0.05)` significantly different pairs:
```{r}
thsd <- anova_c2_t_HSD$type[ anova_c2_t_HSD$type[,"p.adj"] < 0.05, , drop=FALSE]
if( nrow(thsd) > 0 )
{
  thsd <- as.data.frame(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE]); thsd$p.adj <- sprintf("%.3g",thsd$p.adj);
  knitr::kable(thsd, row.names=TRUE, digits=c(2, 2, 2, NA), caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>% kable_styling();
}
```


### *d*^2^

```{r}
# Anovas with Tukey's HSD (N.B. strictly this should be a beta regression but for our purposes here it should be fine...)
anova_d2_d <- aov(cd2 ~ domain, data=d_combined[ d_combined$genetic_model=="ADE", ]);
anova_d2_t <- aov(cd2 ~ type, data=d_combined[ d_combined$genetic_model=="ADE", ]);
anova_d2_d_HSD <- TukeyHSD(anova_d2_d); colnames(anova_d2_d_HSD$domain)[4] <- "p.adj"; 
anova_d2_t_HSD <- TukeyHSD(anova_d2_t); colnames(anova_d2_t_HSD$type)[4] <- "p.adj"; 
```

- by **domain**:
```{r}
pander::pander(summary(anova_d2_d));
```

- by **type**:
```{r}
pander::pander(summary(anova_d2_t));
```

The pairwise significant differences after Tukey's HSD:

- by **domain** there are `r sum(anova_d2_d_HSD$domain[,"p.adj"] < 0.05)` significantly different pairs:
```{r}
thsd <- anova_d2_d_HSD$domain[ anova_d2_d_HSD$domain[,"p.adj"] < 0.05, , drop=FALSE]
if( nrow(thsd) > 0 )
{
  thsd <- as.data.frame(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE]); thsd$p.adj <- sprintf("%.3g",thsd$p.adj);
  knitr::kable(thsd, row.names=TRUE, digits=c(2, 2, 2, NA), caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>% kable_styling();
}
```

- by **type** there are `r sum(anova_d2_t_HSD$type[,"p.adj"] < 0.05)` significantly different pairs:
```{r}
thsd <- anova_d2_t_HSD$type[ anova_d2_t_HSD$type[,"p.adj"] < 0.05, , drop=FALSE]
if( nrow(thsd) > 0 )
{
  thsd <- as.data.frame(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE]); thsd$p.adj <- sprintf("%.3g",thsd$p.adj);
  knitr::kable(thsd, row.names=TRUE, digits=c(2, 2, 2, NA), caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>% kable_styling();
}
```


### *e*^2^

```{r}
# Anovas with Tukey's HSD (N.B. strictly this should be a beta regression but for our purposes here it should be fine...)
anova_e2_d <- aov(e2 ~ domain, data=d_combined);
anova_e2_t <- aov(e2 ~ type, data=d_combined);
anova_e2_d_HSD <- TukeyHSD(anova_e2_d); colnames(anova_e2_d_HSD$domain)[4] <- "p.adj"; 
anova_e2_t_HSD <- TukeyHSD(anova_e2_t); colnames(anova_e2_t_HSD$type)[4] <- "p.adj"; 
```

- by **domain**:
```{r}
pander::pander(summary(anova_e2_d));
```

- by **type**:
```{r}
pander::pander(summary(anova_e2_t));
```

The pairwise significant differences after Tukey's HSD:

- by **domain** there are `r sum(anova_e2_d_HSD$domain[,"p.adj"] < 0.05)` significantly different pairs:
```{r}
thsd <- anova_e2_d_HSD$domain[ anova_e2_d_HSD$domain[,"p.adj"] < 0.05, , drop=FALSE]
if( nrow(thsd) > 0 )
{
  thsd <- as.data.frame(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE]); thsd$p.adj <- sprintf("%.3g",thsd$p.adj);
  knitr::kable(thsd, row.names=TRUE, digits=c(2, 2, 2, NA), caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>% kable_styling();
}
```

- by **type** there are `r sum(anova_e2_t_HSD$type[,"p.adj"] < 0.05)` significantly different pairs:
```{r}
thsd <- anova_e2_t_HSD$type[ anova_e2_t_HSD$type[,"p.adj"] < 0.05, , drop=FALSE]
if( nrow(thsd) > 0 )
{
  thsd <- as.data.frame(thsd[order(abs(thsd[,"diff"]),decreasing=TRUE),,drop=FALSE]); thsd$p.adj <- sprintf("%.3g",thsd$p.adj);
  knitr::kable(thsd, row.names=TRUE, digits=c(2, 2, 2, NA), caption=capTab("Pairwise significant comparisons (Tukey's HSD)")) %>% kable_styling();
}
```



## Combined results

While our GSEM does model the inter-rater agreement (as *agr*(GSEM)), it cannot do so perfectly, in the sense that a low inter-rater agreement fundamentally induces noise in the estimates (moreover, the residual correlation between *ICC*(*C*,1) and the GSEM estimates strongly suggests that this statistical control is not perfect).
Therefore, we decided to weight the interpretation of the GSEM estimates by the generic inter-rater agreement *ICC*(*C*,1).

With these, we have several ways of ranking the PMs (not necessarily independent), given below with the notation we'll use throughout:

1. is the GSEM estimate statistically significantly greater than 0?
    1. is this *nominally* so at *&alpha;*-level 0.05? (denoted as "^★^")
    2. if so, does this survive *Holm's multiple testing correction* at the same *&alpha;*-level 0.05? (denoted as "^★c^")
  
2. is the GSEM estimate greater than a given threshold (here, 20%)?
    1. is the *point estimate* grater than this threshold? (denoted as "^>^")
    1. is the *lower limit of the 95%CI* grater than this threshold? (denoted as "^≫^")
  
2. is the inter-rater agreement greater than a given threshold (here, 75%)?
    1. is the *point estimate* grater than this threshold? (denoted as "^+^")
    1. is the *lower limit of the 95%CI* grater than this threshold? (denoted as "^++^")
    
Please note that there are logical relationships between some of these criteria:

- "^★c^" &Implies; "^★^"
- "^≫^" &Implies; "^>^"
- "^++^" &Implies; "^+^"

For each component (*h*^2^, *c*^2^ or *d*^2^, and *e*^2^), we combine these criteria to obtain a *ranking* of the measures from **0** (= best) to a maximum (= worst), which we then combine into *classes* from **I** (= strongest evidence) to **V** (= basically no evidence whatsoever). 


```{r results='hide'}
# The criteria:
d_combined <- cbind(d_combined,
                    # For h2:
                    "h2_star"  =(!is.na(d_combined$h2_p)     & d_combined$h2_p < 0.05),
                    "h2_star_c"=(!is.na(d_combined$h2_p_adj) & d_combined$h2_p_adj < 0.05),
                    "h2_gr"    =(!is.na(d_combined$h2)       & d_combined$h2 >= 0.20),
                    "h2_grgr"  =(!is.na(d_combined$h2_CiL)   & d_combined$h2_CiL >= 0.20),
                    # For c2:
                    "c2_star"  =ifelse(d_combined$genetic_model=="ACE", !is.na(d_combined$cd2_p)     & d_combined$cd2_p < 0.05,     NA),
                    "c2_star_c"=ifelse(d_combined$genetic_model=="ACE", !is.na(d_combined$cd2_p_adj) & d_combined$cd2_p_adj < 0.05, NA),
                    "c2_gr"    =ifelse(d_combined$genetic_model=="ACE", !is.na(d_combined$cd2)       & d_combined$cd2 >= 0.20,      NA),
                    "c2_grgr"  =ifelse(d_combined$genetic_model=="ACE", !is.na(d_combined$cd2_CiL)   & d_combined$cd2_CiL >= 0.20,  NA),
                    # For F2:
                    "F2_star"  =ifelse(d_combined$genetic_model=="ACE", d_combined$H2_signif,                                       NA),
                    "F2_star_c"=NA,
                    "F2_gr"    =ifelse(d_combined$genetic_model=="ACE", !is.na(d_combined$H2)        & d_combined$H2 >= 0.20,       NA),
                    "F2_grgr"  =ifelse(d_combined$genetic_model=="ACE", !is.na(d_combined$H2_CiL)    & d_combined$H2_CiL >= 0.20,   NA),
                    # For d2:
                    "d2_star"  =ifelse(d_combined$genetic_model=="ADE", !is.na(d_combined$cd2_p)     & d_combined$cd2_p < 0.05,     NA),
                    "d2_star_c"=ifelse(d_combined$genetic_model=="ADE", !is.na(d_combined$cd2_p_adj) & d_combined$cd2_p_adj < 0.05, NA),
                    "d2_gr"    =ifelse(d_combined$genetic_model=="ADE", !is.na(d_combined$cd2)       & d_combined$cd2 >= 0.20,      NA),
                    "d2_grgr"  =ifelse(d_combined$genetic_model=="ADE", !is.na(d_combined$cd2_CiL)   & d_combined$cd2_CiL >= 0.20,  NA),
                    # For H2:
                    "H2_star"  =ifelse(d_combined$genetic_model=="ADE", d_combined$H2_signif,                                       NA),
                    "H2_star_c"=NA,
                    "H2_gr"    =ifelse(d_combined$genetic_model=="ADE", !is.na(d_combined$H2)        & d_combined$H2 >= 0.20,       NA),
                    "H2_grgr"  =ifelse(d_combined$genetic_model=="ADE", !is.na(d_combined$H2_CiL)    & d_combined$H2_CiL >= 0.20,   NA),
                    # For ICC(C,1):
                    "ICC_plus"    =(!is.na(d_combined$ICC) & d_combined$ICC >= 0.75),
                    "ICC_plusplus"=(!is.na(d_combined$ICC_CiL)   & d_combined$ICC_CiL >= 0.75));

# Prepare the dataset for pretty printing:
d_combined_4print <- d_combined; 

d_combined_4print$h2_CI  <- sprintf("%.2f (%.2f, %.2f)", d_combined_4print$h2, d_combined_4print$h2_CiL, d_combined_4print$h2_CiH);
d_combined_4print$h2_pp  <- sprintf("%.3g (%.3g)", d_combined_4print$h2_p, d_combined_4print$h2_p_adj);
d_combined_4print$cd2_CI <- sprintf("%.2f (%.2f, %.2f)", d_combined_4print$cd2, d_combined_4print$cd2_CiL, d_combined_4print$cd2_CiH);
d_combined_4print$cd2_pp <- sprintf("%.3g (%.3g)", d_combined_4print$cd2_p, d_combined_4print$cd2_p_adj);
d_combined_4print$e2_CI  <- sprintf("%.2f (%.2f, %.2f)", d_combined_4print$e2, d_combined_4print$e2_CiL, d_combined_4print$e2_CiH);
d_combined_4print$e2_pp  <- sprintf("%.3g (%.3g)", d_combined_4print$e2_p, d_combined_4print$e2_p_adj);
d_combined_4print$ICC_CI <- sprintf("%.2f (%.2f, %.2f)", d_combined_4print$ICC, d_combined_4print$ICC_CiL, d_combined_4print$ICC_CiH);

d_combined_4print$h2_star_   <- ifelse(is.na(d_combined_4print$h2_star), "-", ifelse(d_combined_4print$h2_star, "Yes", "No"));
d_combined_4print$h2_star_c_ <- ifelse(is.na(d_combined_4print$h2_star_c), "-", ifelse(d_combined_4print$h2_star_c, "Yes", "No"));
d_combined_4print$h2_gr_     <- ifelse(is.na(d_combined_4print$h2_gr), "-", ifelse(d_combined_4print$h2_gr, "Yes", "No"));
d_combined_4print$h2_grgr_   <- ifelse(is.na(d_combined_4print$h2_grgr), "-", ifelse(d_combined_4print$h2_grgr, "Yes", "No"));

d_combined_4print$c2_star_   <- ifelse(is.na(d_combined_4print$c2_star), "-", ifelse(d_combined_4print$c2_star, "Yes", "No"));
d_combined_4print$c2_star_c_ <- ifelse(is.na(d_combined_4print$c2_star_c), "-", ifelse(d_combined_4print$c2_star_c, "Yes", "No"));
d_combined_4print$c2_gr_     <- ifelse(is.na(d_combined_4print$c2_gr), "-", ifelse(d_combined_4print$c2_gr, "Yes", "No"));
d_combined_4print$c2_grgr_   <- ifelse(is.na(d_combined_4print$c2_grgr), "-", ifelse(d_combined_4print$c2_grgr, "Yes", "No"));

d_combined_4print$F2_star_   <- ifelse(is.na(d_combined_4print$F2_star), "-", ifelse(d_combined_4print$F2_star, "Yes", "No"));
d_combined_4print$F2_star_c_ <- ifelse(is.na(d_combined_4print$F2_star_c), "-", ifelse(d_combined_4print$F2_star_c, "Yes", "No"));
d_combined_4print$F2_gr_     <- ifelse(is.na(d_combined_4print$F2_gr), "-", ifelse(d_combined_4print$F2_gr, "Yes", "No"));
d_combined_4print$F2_grgr_   <- ifelse(is.na(d_combined_4print$F2_grgr), "-", ifelse(d_combined_4print$F2_grgr, "Yes", "No"));

d_combined_4print$d2_star_   <- ifelse(is.na(d_combined_4print$d2_star), "-", ifelse(d_combined_4print$d2_star, "Yes", "No"));
d_combined_4print$d2_star_c_ <- ifelse(is.na(d_combined_4print$d2_star_c), "-", ifelse(d_combined_4print$d2_star_c, "Yes", "No"));
d_combined_4print$d2_gr_     <- ifelse(is.na(d_combined_4print$d2_gr), "-", ifelse(d_combined_4print$d2_gr, "Yes", "No"));
d_combined_4print$d2_grgr_   <- ifelse(is.na(d_combined_4print$d2_grgr), "-", ifelse(d_combined_4print$d2_grgr, "Yes", "No"));

d_combined_4print$H2_star_   <- ifelse(is.na(d_combined_4print$H2_star), "-", ifelse(d_combined_4print$H2_star, "Yes", "No"));
d_combined_4print$H2_star_c_ <- ifelse(is.na(d_combined_4print$H2_star_c), "-", ifelse(d_combined_4print$H2_star_c, "Yes", "No"));
d_combined_4print$H2_gr_     <- ifelse(is.na(d_combined_4print$H2_gr), "-", ifelse(d_combined_4print$H2_gr, "Yes", "No"));
d_combined_4print$H2_grgr_   <- ifelse(is.na(d_combined_4print$H2_grgr), "-", ifelse(d_combined_4print$H2_grgr, "Yes", "No"));

d_combined_4print$ICC_plus_     <- ifelse(is.na(d_combined_4print$ICC_plus), "-", ifelse(d_combined_4print$ICC_plus, "Yes", "No"));
d_combined_4print$ICC_plusplus_ <- ifelse(is.na(d_combined_4print$ICC_plusplus), "-", ifelse(d_combined_4print$ICC_plusplus, "Yes", "No"));
```


### Narrow-sense heritability, *h*^2^

Because there is a large positive correlation between *h*^2^ and the inter-rater agreement *ICC*(*C*,1) `r do.call(sprintf, c(fmt="(Pearson's *r*=%.2f, *p*=%.3g; Spearman's *&rho;*=%.2f, *p*=%.3g)", as.list(estim_corrs[ estim_corrs$measure1=="ICC" & estim_corrs$measure2=="h2", c("r", "r.p", "rho", "rho.p")])))`, we also consider this agreement in our ranking of the measures.

```{r}
# Unique criteria:
categories <- unique(d_combined[,c("h2_star_c", "h2_star", "h2_grgr", "h2_gr", "ICC_plusplus", "ICC_plus")]);
categories <- categories[ order(categories$h2_star_c, categories$h2_star, categories$h2_grgr, categories$h2_gr, categories$ICC_plusplus, categories$ICC_plus, decreasing=TRUE), ]; 
categories$ranking <- (1:nrow(categories))-1;
d_combined$h2_ranking <- vapply(1:nrow(d_combined), function(i) categories$ranking[ categories$h2_star_c      == d_combined$h2_star_c[i] & 
                                                                                      categories$h2_star      == d_combined$h2_star[i] &
                                                                                      categories$h2_grgr      == d_combined$h2_grgr[i] &
                                                                                      categories$h2_gr        == d_combined$h2_gr[i] &
                                                                                      categories$ICC_plusplus == d_combined$ICC_plusplus[i] &
                                                                                      categories$ICC_plus     == d_combined$ICC_plus[i] ],
                                numeric(1));
d_combined$h2_class <- ifelse(d_combined$h2_ranking %in% c(0,1), "I", 
                           ifelse(d_combined$h2_ranking %in% c(2,4), "II", 
                                  ifelse(d_combined$h2_ranking %in% c(3,5), "III", 
                                         ifelse(d_combined$h2_ranking %in% c(6,7), "IV", 
                                                "V"))));

tmp <- d_combined_4print;
tmp <- tmp[ order(!tmp$h2_star_c, !tmp$h2_star, !tmp$h2_grgr, !tmp$h2_gr, !tmp$ICC_plusplus, !tmp$ICC_plus, -tmp$h2, -tmp$ICC), ]; 
tmp$ranking <- vapply(1:nrow(tmp), function(i) categories$ranking[ categories$h2_star_c      == tmp$h2_star_c[i] & 
                                                                     categories$h2_star      == tmp$h2_star[i] &
                                                                     categories$h2_grgr      == tmp$h2_grgr[i] &
                                                                     categories$h2_gr        == tmp$h2_gr[i] &
                                                                     categories$ICC_plusplus == tmp$ICC_plusplus[i] &
                                                                     categories$ICC_plus     == tmp$ICC_plus[i] ],
                      numeric(1));
tmp$class <- ifelse(tmp$ranking %in% c(0,1), "I", 
                           ifelse(tmp$ranking %in% c(2,4), "II", 
                                  ifelse(tmp$ranking %in% c(3,5), "III", 
                                         ifelse(tmp$ranking %in% c(6,7), "IV", 
                                                "V"))));
tmp$class <- factor(tmp$class, levels=c("I", "II", "III", "IV", "V"));
tmp <- tmp[ order(tmp$class), ];
```

```{r}
categories$h2_star_   <- ifelse(is.na(categories$h2_star), "-", ifelse(categories$h2_star, "Yes", "No"));
categories$h2_star_c_ <- ifelse(is.na(categories$h2_star_c), "-", ifelse(categories$h2_star_c, "Yes", "No"));
categories$h2_gr_     <- ifelse(is.na(categories$h2_gr), "-", ifelse(categories$h2_gr, "Yes", "No"));
categories$h2_grgr_   <- ifelse(is.na(categories$h2_grgr), "-", ifelse(categories$h2_grgr, "Yes", "No"));

categories$ICC_plus_     <- ifelse(is.na(categories$ICC_plus), "-", ifelse(categories$ICC_plus, "Yes", "No"));
categories$ICC_plusplus_ <- ifelse(is.na(categories$ICC_plusplus), "-", ifelse(categories$ICC_plusplus, "Yes", "No"));

categories$count <- vapply(categories$ranking, function(i) sum(tmp$ranking == i), numeric(1));
categories$class <- ifelse(categories$ranking %in% c(0,1), "I", 
                           ifelse(categories$ranking %in% c(2,4), "II", 
                                  ifelse(categories$ranking %in% c(3,5), "III", 
                                         ifelse(categories$ranking %in% c(6,7), "IV", 
                                                "V"))));

# Save the for the paper:
categories_h2 <- categories;

categories$ranking <- kableExtra::cell_spec(categories$ranking, 
                                          color=ifelse(categories$class == "I", "darkblue", 
                                                       ifelse(categories$class == "V", "lightgray", 
                                                              ifelse(categories$class == "IV", "gray", 
                                                                   ifelse(categories$class == "II", "blue", 
                                                                          ifelse(categories$class == "III", "magenta", "black"))))),
                                          bold=(categories$class %in% c("I")),
                                          italic=(categories$class  %in% c("I","II")));
kable(categories[,c("ranking", "class", "count", "h2_star_c_", "h2_star_", "h2_grgr_", "h2_gr_", "ICC_plusplus_", "ICC_plus_")], 
      row.names=FALSE, escape=FALSE, 
      col.names=c("ranking", "class", "count",
                  "*h*^2★c^", 
                  "*h*^2★^", 
                  "*h*^2≫^", 
                  "*h*^2>^", 
                  "ICC^++^",
                  "ICC^+^"),
      caption=capTab("Ranking of measures ordered decreassingly by the strength of evidence they provide for high narrow-sense heritability *h*^2^, with the number of measures in each ranking (see below for the defintion of classes)."))  %>%
  kable_styling("striped", full_width=FALSE);
```

Ranking **0** gives the strongest evidence of high heritability of a reliably-measured phenotype, followed by ranking **1** &rarr; class **I**. 

Rankings **2** and **4** give evidence of relatively high heritability, coupled with good inter-rater agreement &rarr; class **II**. 

Rankings **3** and **5** give evidence of relatively high heritability, but lack this inter-rater agreement&rarr; class **III**. 

Rankings **6** and **7** give some circumstantial evidence of heritability, coupled or not with inter-rater agreement &rarr; class **IV**.

Rankings **8**, **9**, **10** and **11** basically give no evidence of heritability &rarr; class **V**.

```{r}
tmp <- tmp[ tmp$class != "V", ]; 
tmp$short_name <- kableExtra::cell_spec(tmp$short_name, 
                                          color=ifelse(tmp$class == "I", "darkblue", 
                                                       ifelse(tmp$class == "V", "lightgray", 
                                                              ifelse(tmp$class == "IV", "gray", 
                                                                   ifelse(tmp$class == "II", "blue", 
                                                                          ifelse(tmp$class == "III", "magenta", "black"))))),
                                          bold=(tmp$class %in% c("I")),
                                          italic=(tmp$class  %in% c("I","II")));
kable(tmp[c("short_name", "domain", "type", "genetic_model", "ranking", "class",
            "h2_CI", "h2_pp", "cd2_CI", "e2_CI", "ICC_CI", 
            "rMZ", "rDZ")], 
      row.names=FALSE, escape=FALSE, 
      col.names=c("measure", "domain", "type", "genetic model", "ranking", "class", 
                  "*h*^2^", "*p*", "*c*^2^ or *d*^2^", "*e*^2^", "ICC(C,1)",
                  "r~MZ~", "r~DZ~"),
      digits=c(NA, NA, NA, NA, 0, NA, NA, NA, NA, NA, NA, 2, 2),
      caption=capTab(paste0("The ",nrow(tmp)," measures with at least some evidence of heritability (class < V) ordered by class and *h*^2^, also showing the nominal *p*-value (and the Holm-corrected *p*-value). The precise meaning of *c*^2^ or *d*^2^ is disambiguated by the genetic model.")))  %>%
  kable_styling("striped", full_width=FALSE);
```


### Shared environment, *c*^2^

Because there is no correlation between *c*^2^ and the inter-rater agreement *ICC*(*C*,1) `r do.call(sprintf, c(fmt="(Pearson's *r*=%.2f, *p*=%.3g; Spearman's *&rho;*=%.2f, *p*=%.3g)", as.list(estim_corrs[ estim_corrs$measure1=="ICC" & estim_corrs$measure2=="c2", c("r", "r.p", "rho", "rho.p")])))`, we will not consider agreement in our ranking of the measures.

```{r}
# Unique criteria:
categories <- unique(d_combined[ d_combined$genetic_model=="ACE", c("c2_star_c", "c2_star", "c2_grgr", "c2_gr")]);
categories <- categories[ order(categories$c2_star_c, categories$c2_star, categories$c2_grgr, categories$c2_gr, decreasing=TRUE), ]; 
categories$ranking <- (1:nrow(categories)); # no ranking 0
d_combined$c2_ranking <- vapply(1:nrow(d_combined), function(i) 
  {
    if( d_combined$genetic_model[i] == "ACE" )
    {
      categories$ranking[ categories$c2_star_c      == d_combined$c2_star_c[i] & 
                          categories$c2_star      == d_combined$c2_star[i] &
                          categories$c2_grgr      == d_combined$c2_grgr[i] &
                          categories$c2_gr        == d_combined$c2_gr[i] ];
    } else
    {
      NA_integer_
    }
  },
  numeric(1));
d_combined$c2_class <- ifelse(is.na(d_combined$c2_ranking), NA_character_,
                              ifelse(d_combined$c2_ranking %in% c(1,2), "II", 
                                     ifelse(d_combined$c2_ranking %in% c(3), "IV", 
                                            "V")));

tmp <- d_combined_4print[ d_combined_4print$genetic_model=="ACE", ];
tmp <- tmp[ order(!tmp$c2_star_c, !tmp$c2_star, !tmp$c2_grgr, !tmp$c2_gr, !tmp$ICC_plusplus, !tmp$ICC_plus, -tmp$cd2, -tmp$ICC), ]; 
tmp$ranking <- vapply(1:nrow(tmp), function(i) categories$ranking[ categories$c2_star_c      == tmp$c2_star_c[i] & 
                                                                 categories$c2_star      == tmp$c2_star[i] &
                                                                 categories$c2_grgr      == tmp$c2_grgr[i] &
                                                                 categories$c2_gr        == tmp$c2_gr[i] ],
                    numeric(1));
tmp$class <- ifelse(tmp$ranking %in% c(1,2), "II", 
                    ifelse(tmp$ranking %in% c(3), "IV", 
                           "V"));
tmp$class <- factor(tmp$class, levels=c("II", "IV", "V"));
tmp <- tmp[ order(tmp$class), ];
```

```{r}
categories$c2_star_   <- ifelse(is.na(categories$c2_star), "-", ifelse(categories$c2_star, "Yes", "No")); 
categories$c2_star_c_ <- ifelse(is.na(categories$c2_star_c), "-", ifelse(categories$c2_star_c, "Yes", "No"));
categories$c2_gr_     <- ifelse(is.na(categories$c2_gr), "-", ifelse(categories$c2_gr, "Yes", "No"));
categories$c2_grgr_   <- ifelse(is.na(categories$c2_grgr), "-", ifelse(categories$c2_grgr, "Yes", "No"));

categories$count <- vapply(categories$ranking, function(i) sum(tmp$ranking == i), numeric(1));
categories$class <- ifelse(is.na(categories$ranking), NA_character_,
                              ifelse(categories$ranking %in% c(1,2), "II", 
                                     ifelse(categories$ranking %in% c(3), "IV", 
                                            "V")));

# Save the for the paper:
categories_c2 <- categories;

categories$ranking <- kableExtra::cell_spec(categories$ranking, 
                                          color=ifelse(categories$class == "I", "darkblue", 
                                                       ifelse(categories$class == "V", "lightgray", 
                                                              ifelse(categories$class == "IV", "gray", 
                                                                   ifelse(categories$class == "II", "blue", 
                                                                          ifelse(categories$class == "III", "magenta", "black"))))),
                                          bold=(categories$class %in% c("I")),
                                          italic=(categories$class  %in% c("I","II")));
kable(categories[,c("ranking", "class", "count", "c2_star_c_", "c2_star_", "c2_grgr_", "c2_gr_")], 
      row.names=FALSE, escape=FALSE, 
      col.names=c("ranking", "class", "count",
                  "*c*^2★c^", 
                  "*c*^2★^", 
                  "*c*^2≫^", 
                  "*c*^2>^"),
      caption=capTab("Rankings of measures ordered decreassingly by the strength of evidence they provide for high shared environmental effects *c*^2^, with the number of measures in each ranking."))  %>%
  kable_styling("striped", full_width=FALSE);
```

There is no equivalent of *h*^2^'s ranking **0**. 

Rankings **1** and **2** give evidence of a shared environmental effect &rarr; class **II**.

Ranking **3** gives marginal evidence of a shared environmental effect &rarr; class **IV**.

Ranking **4** basically gives no evidence of a shared environmental effect &rarr; class **V**.

```{r}
tmp <- tmp[ tmp$class != "V", ];  
tmp$short_name <- kableExtra::cell_spec(tmp$short_name,  
                                          color=ifelse(tmp$class == "I", "darkblue", 
                                                       ifelse(tmp$class == "V", "lightgray", 
                                                              ifelse(tmp$class == "IV", "gray", 
                                                                   ifelse(tmp$class == "II", "blue", 
                                                                          ifelse(tmp$class == "III", "magenta", "black"))))),
                                          bold=(tmp$class %in% c("I")),
                                          italic=(tmp$class  %in% c("I","II")));
kable(tmp[c("short_name", "domain", "type", "genetic_model", "ranking", "class",
            "h2_CI", "cd2_CI", "cd2_pp", "e2_CI", "ICC_CI", 
            "rMZ", "rDZ")], 
      row.names=FALSE, escape=FALSE, 
      col.names=c("measure", "domain", "type", "genetic model", "ranking", "class", 
                  "*h*^2^", "*c*^2^", "*p*", "*e*^2^", "ICC(C,1)",
                  "r~MZ~", "r~DZ~"),
      digits=c(NA, NA, NA, NA, 0, NA, NA, NA, NA, NA, NA, 2, 2),
      caption=capTab(paste0("The ",nrow(tmp)," measures with at least some evidence of shared environmental effects (class < V) ordered by ranking and *c*^2^, also showing the nominal *p*-value (and the Holm-corrected *p*-value).")))  %>%
  kable_styling("striped", full_width=FALSE);
```


### Dominance, *d*^2^

Because there is no correlation between *d*^2^ and the inter-rater agreement *ICC*(*C*,1) `r do.call(sprintf, c(fmt="(Pearson's *r*=%.2f, *p*=%.3g; Spearman's *&rho;*=%.2f, *p*=%.3g)", as.list(estim_corrs[ estim_corrs$measure1=="ICC" & estim_corrs$measure2=="d2", c("r", "r.p", "rho", "rho.p")])))`, we will not consider agreement in our ranking of the measures.

```{r}
# Unique criteria:
categories <- unique(d_combined[ d_combined$genetic_model=="ADE", c("d2_star_c", "d2_star", "d2_grgr", "d2_gr")]);
categories <- categories[ order(categories$d2_star_c, categories$d2_star, categories$d2_grgr, categories$d2_gr, decreasing=TRUE), ]; 
categories$ranking <- (1:nrow(categories)); # no ranking 0
d_combined$d2_ranking <- vapply(1:nrow(d_combined), function(i) 
  {
    if( d_combined$genetic_model[i] == "ADE" )
    {
      categories$ranking[ categories$d2_star_c      == d_combined$d2_star_c[i] & 
                          categories$d2_star      == d_combined$d2_star[i] &
                          categories$d2_grgr      == d_combined$d2_grgr[i] &
                          categories$d2_gr        == d_combined$d2_gr[i] ];
    } else
    {
      NA_integer_
    }
  },
  numeric(1));
d_combined$d2_class <- ifelse(is.na(d_combined$d2_ranking), NA_character_,
                              ifelse(d_combined$d2_ranking %in% c(1), "II", 
                                     ifelse(d_combined$d2_ranking %in% c(2,3), "IV", 
                                            "V")));

tmp <- d_combined_4print[ d_combined_4print$genetic_model=="ADE", ];
tmp <- tmp[ order(!tmp$d2_star_c, !tmp$d2_star, !tmp$d2_grgr, !tmp$d2_gr, !tmp$ICC_plusplus, !tmp$ICC_plus, -tmp$cd2, -tmp$ICC), ]; 
tmp$ranking <- vapply(1:nrow(tmp), function(i) categories$ranking[ categories$d2_star_c      == tmp$d2_star_c[i] & 
                                                                 categories$d2_star      == tmp$d2_star[i] &
                                                                 categories$d2_grgr      == tmp$d2_grgr[i] &
                                                                 categories$d2_gr        == tmp$d2_gr[i] ],
                    numeric(1));
tmp$class <- ifelse(tmp$ranking %in% c(1), "II", 
                    ifelse(tmp$ranking %in% c(2,3), "IV", 
                           "V"));
tmp$class <- factor(tmp$class, levels=c("II", "IV", "V"));
tmp <- tmp[ order(tmp$class), ]; 
```

```{r}
categories$d2_star_   <- ifelse(is.na(categories$d2_star), "-", ifelse(categories$d2_star, "Yes", "No")); 
categories$d2_star_c_ <- ifelse(is.na(categories$d2_star_c), "-", ifelse(categories$d2_star_c, "Yes", "No"));
categories$d2_gr_     <- ifelse(is.na(categories$d2_gr), "-", ifelse(categories$d2_gr, "Yes", "No"));
categories$d2_grgr_   <- ifelse(is.na(categories$d2_grgr), "-", ifelse(categories$d2_grgr, "Yes", "No"));

categories$count <- vapply(categories$ranking, function(i) sum(tmp$ranking == i), numeric(1));
categories$class <- ifelse(is.na(categories$ranking), NA_character_,
                              ifelse(categories$ranking %in% c(1), "II", 
                                     ifelse(categories$ranking %in% c(2,3), "IV", 
                                            "V")));

# Save the for the paper:
categories_d2 <- categories;

categories$ranking <- kableExtra::cell_spec(categories$ranking, 
                                          color=ifelse(categories$class == "I", "darkblue", 
                                                       ifelse(categories$class == "V", "lightgray", 
                                                              ifelse(categories$class == "IV", "gray", 
                                                                   ifelse(categories$class == "II", "blue", 
                                                                          ifelse(categories$class == "III", "magenta", "black"))))),
                                          bold=(categories$class %in% c("I")),
                                          italic=(categories$class  %in% c("I","II")));
kable(categories[,c("ranking", "class", "count", "d2_star_c_", "d2_star_", "d2_grgr_", "d2_gr_")], 
      row.names=FALSE, escape=FALSE, 
      col.names=c("ranking", "class", "count",
                  "*d*^2★c^", 
                  "*d*^2★^", 
                  "*d*^2≫^", 
                  "*d*^2>^"),
      caption=capTab("Rankings of measures ordered decreassingly by the strength of evidence they provide for high dominance effects *d*^2^, with the number of measures in each ranking."))  %>%
  kable_styling("striped", full_width=FALSE); 
```

There is no equivalent of *h*^2^'s ranking **0**. 

Ranking **1** gives evidence of a dimonance effect &rarr; class **II**.

Rankings **2** and **3** give marginal evidence of a dominance effect &rarr; class **IV**.

Ranking **4** basically gives no evidence of a dominance effect &rarr; class **V**.

```{r}
tmp <- tmp[ tmp$class != "V", ];
tmp$short_name <- kableExtra::cell_spec(tmp$short_name,  
                                          color=ifelse(tmp$class == "I", "darkblue", 
                                                       ifelse(tmp$class == "V", "lightgray", 
                                                              ifelse(tmp$class == "IV", "gray", 
                                                                   ifelse(tmp$class == "II", "blue", 
                                                                          ifelse(tmp$class == "III", "magenta", "black"))))),
                                          bold=(tmp$class %in% c("I")),
                                          italic=(tmp$class  %in% c("I","II")));
kable(tmp[c("short_name", "domain", "type", "genetic_model", "ranking", "class",
            "h2_CI", "cd2_CI", "cd2_pp", "e2_CI", "ICC_CI", 
            "rMZ", "rDZ")], 
      row.names=FALSE, escape=FALSE, 
      col.names=c("measure", "domain", "type", "genetic model", "ranking", "class", 
                  "*h*^2^", "*d*^2^", "*p*", "*e*^2^", "ICC(C,1)",
                  "r~MZ~", "r~DZ~"),
      digits=c(NA, NA, NA, NA, 0, NA, NA, NA, NA, NA, NA, 2, 2),
      caption=capTab(paste0("The ",nrow(tmp)," measures with at least some evidence of dominance effects (class < V) ordered by ranking and *d*^2^, also showing the nominal *p*-value (and the Holm-corrected *p*-value).")))  %>%
  kable_styling("striped", full_width=FALSE);
```





```{r echo=FALSE, results='hide'}
# Save final results to file:
write.csv(d_combined, "../data/final/heritability_results.csv", row.names=FALSE);

# Save the explanation of the final results:
cat(paste0('
# This document explains the content of the `final_heritability_results.csv` file.\n
\n
*N.B.* this document uses GitHub-flavoured Markdown, in particular \\<sup\\>x\\</sup\\> for superscript <sup>x</sup> and \\<sub\\>x\\</sub\\> for subscript <sub>x</sub>.
The columns are:\n
\n
## General:\n
- **short\\_name**, **domain** and **type**: phenotype info\n
\n
## For the genetic decomposition model:\n
- **genetic\\_model**, **CD\\_meaning** and **H2\\_meaning**: given that we cannot estimate simultaneously the *C* and *D* components, we must chose between the two using the heuristic [if *r*<sub>MZ</sub> < 2*r*<sub>DZ</sub> then we estimate *C* otherwise we estimate *D*]; this, in turn, determines the fitted genetic model (*ACE* or *ADE*), and the meaning of the "CD" (short for "C or D") parameter (*C* or *D*) and of "H2" (as familiality or broad-sense heritability);\n
- for each of **h2**, **cd2** and **e2**:
  + the point estimate (i.e., of *h*^2^, (*c*^2^ or *d*^2^), and *e*^2^, respectively)\n
  + **\\_CiL**, **\\_CiH**: the lower and higher (upper) bounds of the 95% confidence intervals (CIs) of the corresponding point estimate\n
  + **\\_p** and **\\_p_adj**: the results of the comparison between the model with the component and without it (the *p* is significant if including the component and excluding it are significantly different), as well as after Holm\'s multiple testing correction\n
  + **H2\\_signif**: for *H*^2^ and *F*^2^ respectively there is no model comparison and we check instead of 0 falls within the 95%CI or not to judge the significance of this component\n
\n
## Observed twin correlations:\n
- **rMZ** and **rDZ**: the phenotypic correlations between monozygotic *r*<sub>MZ</sub> and dizygotic *r*<sub>DZ</sub> twins\n
\n
## For inter-rater agreement ICC(C,1):\n
- **ICC**, **ICC\\_CiL** and **ICC\\_CiH**: the point estimate and 95%CI\n
- **ICC\\_0.75** and **ICC\\_0.75\\_strict**: if the ICC(C,1) is greater than 75% and if the low 95%CI is greater than 75%, respectively\n
\n
## For inter-rater agreement from the GSEM model agr(GSEM) we ive the same as for ICC(C,1) above\n
\n
## The strength of evidence: for each relevant component we report:\n
- **\\_star**: is the component significantly different from 0?\n
- **\\_star_c**: is the component significantly different from 0 after Holm\'s multiple testing correction?\n
- **\\_gr**: is the component greater than the agreed threshold?\n
- **\\_grgr**: is the lower 95%CI bound greater than the agreed threshold?\n
\n
## For inter-rater agreement ICC(C,1):\n
- **\\_plus**: is the agreement greater than the agreed threshold?\n
- **\\_plusplus**: is the lower 95%CI bound greater than the agreed threshold?\n
\n
## These are combined to produce classes of strength of evidence (please note that they mean different things for diferent components as described in the analysis report, but that the lower the number the greater the strength of evidence):\n
- **h2\\_class**, **c2\\_class**, and **d2\\_class**: roman numerals, the lower the better, with I providing very strong evidence and V no evidence at all\n
\n
      '), 
    file="../data/final/heritability_results.md", append=FALSE);

# Save ph_ace for the main paper:
save(ph_ace, file="./results_for_paper/ph_ace.RData", compress="xz", compression_level=9);
# And the classes:
save(categories_h2, categories_c2, categories_d2, file="./results_for_paper/classes_evidence.RData", compress="xz", compression_level=9);
```



# Appendices

## Appendix I: Checking with `lavaan`

```{r}
# Load the lavaan results:
d_openmx <- read.table("../data/intermediate/SEM_results.csv", header=TRUE, sep=",", quote='"');
if( !file.exists("../data/intermediate/lavaan_results.csv") ) source("./2_lavaan_model.R", echo=FALSE); # run the lavaan code first...
d_lavaan <- read.table("../data/intermediate/lavaan_results.csv", header=TRUE, sep=",", quote='"');
d_both <- merge(d_openmx, d_lavaan, by="phenotype_name_short", suffixes=c(".OM", ".LV"), all=TRUE);
# Remove the duplicates:
d_both <- d_both[ !(d_both$phenotype_name_short %in% c("LNEP", "ASCG", "SBAP", "LNCT")), ];
# Save for paper:
save(d_both, file="./results_for_paper/d_both.RData", compress="xz", compression_level=9);
```

As an extra check, we also implemented the genetic SEM model is `lavaan`. However, this re-implementation differs from the main one in `OpenMX` due to some limitations of `lavaan`, as described below (our implementation is based on the suggestions given in [Michel G Nivard's "Twin Strutural Equation Models in R & Lavaan" (6/21/2021)](https://rstudio-pubs-static.s3.amazonaws.com/798608_1dbfd131272d4dae8d44b1973b4fbcb6.html#Single_trait_twin_model_in_lavaan) and [A. Alexander Beaujean's "Latent Variable Models in Education" slides (Fall 2012)](https://users.ugent.be/~yrosseel/lavaan/AlexBeaujean.pdf)).

First, some notations: for a given PM, the data was organized as a matrix with columns: *Zygosity* ("MZ" or "DZ"), *T1R1*, *T1R2*, *T2R1*, *T2R2* (the z-scored measure in twin 1 by rater 1, in twin 1 by rater 2, etc.)and the covariates of interest *"T1sex*, *T1age*, *T1age2* (age^2^), *T1icv*, *T2sex*, *T2age*, *T2age2* and *T2icv* (all z-scored and arranged by twin).

Second, the covariates could not be included directly in the model, but were regressed out from the measure previous to fitting the SEM model. More precisely, for each of *T1R1*, *T1R2*, *T2R1*, *T2R2*, we performed an independent multiple regression *TiRj* ~ *"Tisex* + *Tiage* + *Tiage2* + *Tiicv* (where *i* &in; {1,2} is the twin, and *j* &in; {1,2} is the rater), and we stored the residuals of this regression in the variables *T1R1rez*, *T1R2rez*, *T2R1rez*, *T2R2rez* -- which we used in the SEM model.

Third, we implemented both the ACE and the ADE models, and we chose between them using Akaike's Information Criterion, AIC (i.e., we picked the one with the smaller AIC). These models were implemented as *grouped* models (the groups being the MZ and DZ twins) and we tried to be as similar to the `OpenMX` implementation as possible.
The `lavaan` code is given below (please note that we used the non-default optimizer `BFGS` because the default one had convergence issues for a few PMs; also, we used a robust method for estimating the standard errors -- please see the `lavaan` help for more info).

***ACE:***
```{r eval=FALSE, echo=TRUE}
ace.model  <- " # ACE model (using reziduals after controllng for covariates):
    
                # Raters:
                T1 =~ c(r1,r1)*T1R1rez + c(r2,r2)*T1R2rez # twin 1 is measured by both raters
                T2 =~ c(r1,r1)*T2R1rez + c(r2,r2)*T2R2rez # twin 2 is measured by both raters

                # Latents:
                A1 =~ NA*T1 + c(a,a)*T1 # A for twin 1
                A2 =~ NA*T2 + c(a,a)*T2 # A for twin 2 
                C1 =~ NA*T1 + c(c,c)*T1 # C for twin 1 
                C2 =~ NA*T2 + c(c,c)*T2 # C for twin 2 

                # Variances:
                A1 ~~ 1*A1 # A has variance 1
                A2 ~~ 1*A2 # A has variance 1
                C1 ~~ 1*C1 # C has variance 1
                C2 ~~ 1*C2 # C has variance 1
                    
                T1 ~~ c(e2,e2)*T1 # E is the residual variance of the phenotype
                T2 ~~ c(e2,e2)*T2 # E is the residual variance of the phenotype
                    
                # Covariances
                A1 ~~ c(1,.5)*A2 # for A, the correlation is 1 for MZ twins and 0.5 for DZ twins
                A1 ~~ 0*C1 + 0*C2 # A and C are uncorrelated
                A2 ~~ 0*C1 + 0*C2 # A and C are uncorrelated 
                C1 ~~ c(1,1)*C2 # C is correlated 1 regardless of twin status
                                # by lavaan default, E is uncorrelated with A and C, so no need to model it
              ";
ace.fit <- sem(ace.model, data=d, group="zyg", se="robust", optim.method="BFGS");
```

***ADE:***
```{r eval=FALSE, echo=TRUE}
ade.model  <- " # ADE model (using reziduals after controllng for covariates):
    
                # Raters:
                T1 =~ c(r1,r1)*T1R1rez + c(r2,r2)*T1R2rez # twin 1 is measured by both raters
                T2 =~ c(r1,r1)*T2R1rez + c(r2,r2)*T2R2rez # twin 2 is measured by both raters

                # Latents:
                A1 =~ NA*T1 + c(a,a)*T1 # A for twin 1
                A2 =~ NA*T2 + c(a,a)*T2 # A for twin 2 
                D1 =~ NA*T1 + c(d,d)*T1 # D for twin 1 
                D2 =~ NA*T2 + c(d,d)*T2 # D for twin 2 

                # Variances:
                A1 ~~ 1*A1 # A has variance 1
                A2 ~~ 1*A2 # A has variance 1
                D1 ~~ 1*D1 # D has variance 1
                D2 ~~ 1*D2 # D has variance 1
                    
                T1 ~~ c(e2,e2)*T1 # E is the residual variance of the phenotype
                T2 ~~ c(e2,e2)*T2 # E is the residual variance of the phenotype
                    
                # Covariances
                A1 ~~ c(1,.5)*A2 # for A, the correlation is 1 for MZ twins and 0.5 for DZ twins
                A1 ~~ 0*D1 + 0*D2 # A and D are uncorrelated
                A2 ~~ 0*D1 + 0*D2 # A and D are uncorrelated 
                D1 ~~ c(1,.25)*D2 # non-additive genetic effects D are correlated 1 for MZ twins and .25 for DZ
                                  # by lavaan default, E is uncorrelated with A and D, so no need to model it
              ";
ade.fit <- sem(ade.model, data=d, group="zyg", se="robust", optim.method="BFGS");
```

`lavaan` returns the standardized estimates with standard errors, 95%CIs and *p*-values, but for the important components (*A*, *C* and *D*) we also performed model comparison using AIC and the likelihood ratio test for nested models (as implemented by `lavTestLRT()`) between the "full" model (ACE or ADE, respectively) and the "reduced" model without the component of interest (AE and CE, or AE and DE, respectively).
With these, we obtained a list of all PMs with the preferred model (ACE or ADE), their standardized point estimates, standard errors, 95%CIs, *p*-values and (for *A*, *C* and *D*) the ΔAIC and χ^2^ LRT test, which we compared with their corresponding main `OpenMX` estimates.

### Genetic model

The choice between the ACE and DE genetic models is based on different approaches: the "*r*~MZ~ vs 2*r*~DZ~" heuristic for `OpenMX`, and formal ΔAIC model comparison for `lavaan`, but it turns out that they agree pretty well:

```{r}
pander(table(d_both$genetic_model.LV, d_both$genetic_model.OM));
```

For `r sprintf("%d (%.1f%%)", sum(d_both$genetic_model.LV == d_both$genetic_model.OM), sum(d_both$genetic_model.LV == d_both$genetic_model.OM)*100/nrow(d_both))` the chosen genetic model is the same, but for the remaining `r sprintf("%d (%.1f%%)", sum(d_both$genetic_model.LV != d_both$genetic_model.OM), sum(d_both$genetic_model.LV != d_both$genetic_model.OM)*100/nrow(d_both))` it isn't:

```{r}
tmp <- d_both[ d_both$genetic_model.LV != d_both$genetic_model.OM, c("phenotype_name_short", "genetic_model.OM", "genetic_model.LV", 
                                                                     "twin_corr_rMZ", "twin_corr_rDZ", "deltaAIC_ACE_ADE") ];
tmp$twin_corr_rMZ_2rDZ <- (tmp$twin_corr_rMZ - 2*tmp$twin_corr_rDZ);
tmp <- tmp[ order(tmp$genetic_model.OM, tmp$genetic_model.LV, tmp$phenotype_name_short), ];
knitr::kable(tmp[,c("phenotype_name_short", "genetic_model.OM", "twin_corr_rMZ_2rDZ", "genetic_model.LV", "deltaAIC_ACE_ADE")], row.names=FALSE,
             col.names=c("measure", "genetic model (`OpenMX`)", "*r*~MZ~ - 2*r*~DZ~", "genetic model (`lavaan`)", "ΔAIC(ACE, ADE)"),
             digits=   c(NA,        NA,                         2,                  NA,                         2),
             caption=capTab("The phenotypes where the genetic model chosen differs between `OpenMX` and `lavaan`, also showing the difference between *r*~MZ~ and 2*r*~DZ* (for `OpenMX`) and the ΔAIC between ACE and ADE (for `lavaan`).")) %>%
  kable_styling();
```

It can be seen that, in all cases, the `lavaan` ACE and ADE models are virtually indistinguishable (the ΔAIC(ACE, ADE) faisl to reach 2 AIC points), and that in some of these, the `OpenMX` latent *r*~MZ~ and 2*r*~DZ~ are also very close, suggesting that these differences in the genetic model are rather superficial.

### Narrow-sense heritability estimates, *a*^2^

There is a pretty good correlation between the narrow-sense heritability estimates from `OpenMX` (*h*^2^) and `lavaan` (*a*^2^), and the measures where the two pick different genetic models (ACE vs ADE) do not seem to be especially divergent (see also figure below): `r sprintf("Pearson's *r* = %.2f (*p* = %.3g) and Spearman's *&rho;* = %.2f (*p* = %.3g)", (r <- cor.test(d_both$h2, d_both$a2, method="pearson"))$estimate, r$p.value, (r <- cor.test(d_both$h2, d_both$a2, method="spearman"))$estimate, r$p.value)`.

```{r fig.width=6, fig.height=4, fig.cap=capFig("Relationship between naroow sense heritability estimates using `OpenMX` and `lavaan`, also highlighting the measures where the two fitted the same genetic model (or not).")}
ggplot(d_both, aes(x=h2, y=a2, color=(genetic_model.LV == genetic_model.OM))) + 
  xlab(expression("OpenMX ("*italic("h")^2*")")) + ylab(expression("lavaan ("*italic("a")^2*")")) +
  xlim(0,1) + ylim(0,1) +
  geom_point(alpha=0.50) + 
  scale_color_manual(values=c("TRUE"="blue", "FALSE"="red"), name="Same model?") +
  #geom_smooth(method="lm", color="black") +
  geom_smooth(method="lm") +
  NULL;
```

we linearly regressed the one on the other, as follows:

#### `lavaan` ~ `OpenMX`

```{r}
m <- lm(a2 ~ h2, data=d_both); ms <- summary(m);
```

This linear regressions has `r sprintf("an adjusted *R*^2^ = %.1f%%, intercept *α* = %.3f (±%.3f, *p* = %.3g) and slope *β* = %.3f (±%.3f, *p* = %.3g)", ms$adj.r.squared*100, ms$coefficients["(Intercept)", "Estimate"], 2*ms$coefficients["(Intercept)", "Std. Error"], ms$coefficients["(Intercept)", "Pr(>|t|)"], ms$coefficients["h2", "Estimate"], 2*ms$coefficients["h2", "Std. Error"], ms$coefficients["h2", "Pr(>|t|)"])`.

The most important outliers and influential points are:

```{r fig.width=3*3, fig.height=1*3, fig.cap=capFig("Identifyng outliers and influential points."), results='hide'}
par(mfrow=c(1,3));
qqPlot(m, main="Q-Q Plot");
outlierTest(m, cutoff=0.10);

cutoff <- 4/(nrow(d_both)-length(m$coefficients)-2);
plot(m, which=4, cook.levels=cutoff);
abline(h=cutoff, lty=2, col="red");

influencePlot(m, main="Influence Plot", sub="Circle size is proportional to Cook’s distance");
par(mfrow=c(1,1));
```
```{r}
# Show the outliers:
m_outliers <- d_both[ c(125, 142, 76, 14), c("phenotype_name_short", "h2", "h2_CiL", "h2_CiH", "A_p", "a2", "a2.CiL", "a2.CiH", "a2.p") ];
m_outliers$h2_CI <- sprintf("%.2f (%.2f, %.2f)", m_outliers$h2, m_outliers$h2_CiL, m_outliers$h2_CiH);
m_outliers$a2_CI <- sprintf("%.2f (%.2f, %.2f)", m_outliers$a2, m_outliers$a2.CiL, m_outliers$a2.CiH);
m_outliers <- m_outliers[ order(m_outliers$a2 - m_outliers$h2, decreasing=TRUE), ];
knitr::kable(m_outliers[,c("phenotype_name_short", "h2_CI", "A_p", "a2_CI", "a2.p")], row.names=FALSE,
             col.names=c("measure", "`OpenMX`", "*p*", "`lavaan`", "*p*"),
             digits=   c(NA,        NA,         3,     NA,         3),
             caption=capTab("The outlier phenotypes ordered by decreasing difference between `lavaan` and `OpenMX` estimates.")) %>%
  kable_styling();
```

#### `OpenMX` ~ `lavaan`

```{r}
m <- lm(h2 ~ a2, data=d_both); ms <- summary(m);
```

This linear regressions has `r sprintf("an adjusted *R*^2^ = %.1f%%, intercept *α* = %.3f (±%.3f, *p* = %.3g) and slope *β* = %.3f (±%.3f, *p* = %.3g)", ms$adj.r.squared*100, ms$coefficients["(Intercept)", "Estimate"], 2*ms$coefficients["(Intercept)", "Std. Error"], ms$coefficients["(Intercept)", "Pr(>|t|)"], ms$coefficients["a2", "Estimate"], 2*ms$coefficients["a2", "Std. Error"], ms$coefficients["a2", "Pr(>|t|)"])`.

The most important outliers and influential points are:

```{r fig.width=3*3, fig.height=1*3, fig.cap=capFig("Identifyng outliers and influential points."), results='hide'}
par(mfrow=c(1,3));
qqPlot(m, main="Q-Q Plot");
outlierTest(m, cutoff=0.10);

cutoff <- 4/(nrow(d_both)-length(m$coefficients)-2);
plot(m, which=4, cook.levels=cutoff);
abline(h=cutoff, lty=2, col="red");

influencePlot(m, main="Influence Plot", sub="Circle size is proportional to Cook’s distance");
par(mfrow=c(1,1));
```
```{r}
# Show the outliers:
m_outliers <- d_both[ c(125, 142, 73, 16, 13, 138), c("phenotype_name_short", "h2", "h2_CiL", "h2_CiH", "A_p", "a2", "a2.CiL", "a2.CiH", "a2.p") ];
m_outliers$h2_CI <- sprintf("%.2f (%.2f, %.2f)", m_outliers$h2, m_outliers$h2_CiL, m_outliers$h2_CiH);
m_outliers$a2_CI <- sprintf("%.2f (%.2f, %.2f)", m_outliers$a2, m_outliers$a2.CiL, m_outliers$a2.CiH);
m_outliers <- m_outliers[ order(m_outliers$a2 - m_outliers$h2, decreasing=TRUE), ];
knitr::kable(m_outliers[,c("phenotype_name_short", "h2_CI", "A_p", "a2_CI", "a2.p")], row.names=FALSE,
             col.names=c("measure", "`OpenMX`", "*p*", "`lavaan`", "*p*"),
             digits=   c(NA,        NA,         3,     NA,         3),
             caption=capTab("The outlier phenotypes ordered by decreasing difference between `lavaan` and `OpenMX` estimates.")) %>%
  kable_styling();
```


### Conslusions `OpenMX` vs `lavaan`

Thus, it is comforting that two such different implementations support each other. However, given the limitations of our `lavaan` implementation, we will use the `OpenMX` results throughout.


## Appendix II: Session information

```{r warning=FALSE, results='asis'}
if( require(benchmarkme) )
{
  # CPU:
  cpu_info <- benchmarkme::get_cpu();
  if( is.null(cpu_info) || is.na(cpu_info) )
  {
    cat("**CPU:** unknown.\n\n");
  } else
  {
    if( !is.null(cpu_info$model_name) && !is.na(cpu_info$model_name) )
    {
      cat(paste0("**CPU:** ",cpu_info$model_name));
      if( !is.null(cpu_info$no_of_cores) && !is.na(cpu_info$no_of_cores) )
      {
        cat(paste0(" (",cpu_info$no_of_cores," threads)"));
      }
      cat("\n\n");
    } else
    {
      cat("**CPU:** unknown.\n\n");
    }
  }
  
  # RAM:
  ram_info <- benchmarkme::get_ram();
  if( is.null(ram_info) || is.na(ram_info) )
  {
    cat("**RAM (memory):** unknown.\n\n");
  } else
  {
    cat("**RAM (memory):** "); print(ram_info); cat("\n");
  }
} else
{
  cat("**RAM (memory):** cannot get info (try installing package 'benchmarkme').\n\n");
}
```

```{r results='asis'}
# OS:
sysinf <- Sys.info();
if (!is.null(sysinf))
{
  os <- sysinf['sysname'];
  if (os == 'Darwin') os <- "macOS";
} else 
{ ## mystery machine
  os <- .Platform$OS.type;
  if (grepl("^darwin", R.version$os)) os <- "macOS";
  if (grepl("linux-gnu", R.version$os)) os <- "Linux";
}
if( tolower(os) == "linux" )
{
  # Try to get the distro name as well:
  os_distro <- system("lsb_release -a", intern=TRUE, ignore.stderr=TRUE);
  os_distro <- paste(vapply(strsplit(os_distro, "\t", fixed=TRUE), function(x) if(length(x) > 1){ x[2] }else{ "" }, character(1)), collapse=" / ");
} else
{
  os_distro <- "";
}
cat(paste0("**OS:** ", "*",os,"*", ifelse(os_distro != "", paste0(" (",os_distro, ")"),""), "\n"));
```


```{r}
# (Re-)load all the used libraries in all the scripts:
## 1_data_preparation.R:
library(car);
library(dplyr);
library(lsr);
library(effsize);
library(moments);
library(corrplot);
library(mets);
library(MASS);
## 2_OpenMx_model.R:
library(stringr);
library(dplyr);
library(parallel);
library(doParallel);
library(foreach);
library(psych);
library(OpenMx);
## 2_lavaan_model.R:
library(stringr);
library(foreach);
library(dplyr);
library(psych);
library(lavaan);
library(lavaanPlot);
## 3_analysis.Rmd:
library(car);
library(dplyr);
library(grid);
library(ggplot2);
library(gridExtra);
library(reshape2);
library(irr);
library(parallel);
library(knitr);
library(kableExtra);
library(pander);
library(moments);
library(tidyr);
library(Hmisc);
library(DiagrammeR);
library(BlandAltmanLeh); # Bland–Altman plots
library(gtools);
library(benchmarkme);

# Session info:
pander::pander(sessionInfo());
```
 

